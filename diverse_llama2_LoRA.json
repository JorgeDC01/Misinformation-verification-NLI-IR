[
    {
        "id_experiment": "experiment_Llama-3.2-1B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-1B-bnb-4bit",
        "best_experiment": {
            "id": 1,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-1B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.07\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 4,
                "lora_alpha": 16,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3007763426507537,
                        "accuracy": 0.5954190975700788
                    },
                    {
                        "epoch": 2,
                        "loss": 0.8453645179020101,
                        "accuracy": 0.7121613923428998
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5956442368090452,
                        "accuracy": 0.7793820103325673
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5015703517587939,
                        "accuracy": 0.8081992653269688
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4707325690954774,
                        "accuracy": 0.8169603394425128
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4350266959798995,
                        "accuracy": 0.8295715716895515
                    },
                    {
                        "epoch": 7,
                        "loss": 0.41249460191582915,
                        "accuracy": 0.8379594161903078
                    },
                    {
                        "epoch": 8,
                        "loss": 0.39868532113693467,
                        "accuracy": 0.8408470347889289
                    },
                    {
                        "epoch": 9,
                        "loss": 0.3805477583228643,
                        "accuracy": 0.8483705580764924
                    },
                    {
                        "epoch": 10,
                        "loss": 0.36609806846733667,
                        "accuracy": 0.8530653937572436
                    },
                    {
                        "epoch": 11,
                        "loss": 0.33715452261306533,
                        "accuracy": 0.8637122596106626
                    },
                    {
                        "epoch": 12,
                        "loss": 0.32722204773869346,
                        "accuracy": 0.8669534641601352
                    },
                    {
                        "epoch": 13,
                        "loss": 0.31372438363693467,
                        "accuracy": 0.8716286561769502
                    },
                    {
                        "epoch": 14,
                        "loss": 0.3016694802135678,
                        "accuracy": 0.876893158111851
                    },
                    {
                        "epoch": 15,
                        "loss": 0.2924510246545226,
                        "accuracy": 0.879878995030153
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.2678006329113924,
                        "accuracy": 0.4279,
                        "precision": 0.3973068773231589,
                        "recall": 0.4279,
                        "f1_score": 0.3263953205963696
                    },
                    {
                        "epoch": 2,
                        "loss": 1.0076641613924051,
                        "accuracy": 0.6199,
                        "precision": 0.7351109674159413,
                        "recall": 0.6199,
                        "f1_score": 0.6096844810324661
                    },
                    {
                        "epoch": 3,
                        "loss": 1.0864319620253164,
                        "accuracy": 0.5991,
                        "precision": 0.7279141028860893,
                        "recall": 0.5991,
                        "f1_score": 0.5920126625276979
                    },
                    {
                        "epoch": 4,
                        "loss": 0.8107199367088608,
                        "accuracy": 0.6761,
                        "precision": 0.743429469843816,
                        "recall": 0.6761,
                        "f1_score": 0.6735497455556919
                    },
                    {
                        "epoch": 5,
                        "loss": 0.9178698575949367,
                        "accuracy": 0.6611,
                        "precision": 0.7766067828617985,
                        "recall": 0.6611,
                        "f1_score": 0.6524130680052628
                    },
                    {
                        "epoch": 6,
                        "loss": 0.6993423655063291,
                        "accuracy": 0.7277,
                        "precision": 0.7833307725022354,
                        "recall": 0.7277,
                        "f1_score": 0.7187691831395846
                    },
                    {
                        "epoch": 7,
                        "loss": 0.8138844936708861,
                        "accuracy": 0.6858,
                        "precision": 0.7557341106813763,
                        "recall": 0.6858,
                        "f1_score": 0.6843015336977325
                    },
                    {
                        "epoch": 8,
                        "loss": 0.7482199367088608,
                        "accuracy": 0.7027,
                        "precision": 0.7614677521573603,
                        "recall": 0.7027,
                        "f1_score": 0.7009381549981097
                    },
                    {
                        "epoch": 9,
                        "loss": 0.7927956882911392,
                        "accuracy": 0.6987,
                        "precision": 0.746330161302617,
                        "recall": 0.6987,
                        "f1_score": 0.6992988446766368
                    },
                    {
                        "epoch": 10,
                        "loss": 0.7582575158227848,
                        "accuracy": 0.7241,
                        "precision": 0.7805700509891246,
                        "recall": 0.7241,
                        "f1_score": 0.718988786258642
                    },
                    {
                        "epoch": 11,
                        "loss": 0.7075009889240507,
                        "accuracy": 0.7505,
                        "precision": 0.7659109106168349,
                        "recall": 0.7505,
                        "f1_score": 0.7492979045099583
                    },
                    {
                        "epoch": 12,
                        "loss": 0.7722013449367089,
                        "accuracy": 0.7347,
                        "precision": 0.7662869080862803,
                        "recall": 0.7347,
                        "f1_score": 0.733057628758638
                    },
                    {
                        "epoch": 13,
                        "loss": 0.7598150712025317,
                        "accuracy": 0.7551,
                        "precision": 0.777837406956966,
                        "recall": 0.7551,
                        "f1_score": 0.7487876015248743
                    },
                    {
                        "epoch": 14,
                        "loss": 0.9343354430379747,
                        "accuracy": 0.7305,
                        "precision": 0.7713857759689545,
                        "recall": 0.7305,
                        "f1_score": 0.7258501382368182
                    },
                    {
                        "epoch": 15,
                        "loss": 0.8655557753164557,
                        "accuracy": 0.7408,
                        "precision": 0.7704844806452443,
                        "recall": 0.7408,
                        "f1_score": 0.7353435556679297
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7332466493298659,
                "precision": 0.7436809189685984,
                "recall": 0.7332466493298659,
                "f1_score": 0.7321963135993986
            },
            "confusion_matrix": [
                [
                    2557,
                    588,
                    188
                ],
                [
                    1286,
                    1877,
                    170
                ],
                [
                    315,
                    120,
                    2897
                ]
            ],
            "best_epoch": 11,
            "time_train": 39.36393165588379
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7332466493298659,
            "accuracy_std": 0.0,
            "precision_mean": 0.7436809189685984,
            "precision_std": 0.0,
            "recall_mean": 0.7332466493298659,
            "recall_std": 0.0,
            "f1_score_mean": 0.7321963135993986,
            "f1_score_std": 0.0,
            "time_train_mean": 39.36393165588379,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-1B-bnb-4bit)_LoRA_best_model_1.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-3B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-3B-bnb-4bit",
        "best_experiment": {
            "id": 3,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-3B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.07\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 16,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.4850227701005025,
                        "accuracy": 0.5107745496690043
                    },
                    {
                        "epoch": 2,
                        "loss": 1.4780150753768844,
                        "accuracy": 0.5598051348537529
                    },
                    {
                        "epoch": 3,
                        "loss": 1.4905877041457287,
                        "accuracy": 0.5956548215373132
                    },
                    {
                        "epoch": 4,
                        "loss": 1.399733040201005,
                        "accuracy": 0.6130787514487203
                    },
                    {
                        "epoch": 5,
                        "loss": 1.2431297110552764,
                        "accuracy": 0.6461783251812128
                    },
                    {
                        "epoch": 6,
                        "loss": 1.198114596419598,
                        "accuracy": 0.6593199363545289
                    },
                    {
                        "epoch": 7,
                        "loss": 0.9963538395100503,
                        "accuracy": 0.6410120415659929
                    },
                    {
                        "epoch": 8,
                        "loss": 1.3058947079145728,
                        "accuracy": 0.6236863299742668
                    },
                    {
                        "epoch": 9,
                        "loss": 1.2181267666457287,
                        "accuracy": 0.6628557958630443
                    },
                    {
                        "epoch": 10,
                        "loss": 0.9303401774497487,
                        "accuracy": 0.7042449957766123
                    },
                    {
                        "epoch": 11,
                        "loss": 0.7365734924623115,
                        "accuracy": 0.7513308582316773
                    },
                    {
                        "epoch": 12,
                        "loss": 0.6784704773869347,
                        "accuracy": 0.7636867228475456
                    },
                    {
                        "epoch": 13,
                        "loss": 0.7138230213567839,
                        "accuracy": 0.7399178894847467
                    },
                    {
                        "epoch": 14,
                        "loss": 0.9152059123743719,
                        "accuracy": 0.6180682420885143
                    },
                    {
                        "epoch": 15,
                        "loss": 0.9908428863065326,
                        "accuracy": 0.5817667511344216
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.0592365506329113,
                        "accuracy": 0.3985,
                        "precision": 0.3981925893768296,
                        "recall": 0.3985,
                        "f1_score": 0.34122529136738655
                    },
                    {
                        "epoch": 2,
                        "loss": 1.3241693037974684,
                        "accuracy": 0.4516,
                        "precision": 0.4885886615914038,
                        "recall": 0.4516,
                        "f1_score": 0.36279164453589335
                    },
                    {
                        "epoch": 3,
                        "loss": 1.3188785601265822,
                        "accuracy": 0.5772,
                        "precision": 0.622717885012949,
                        "recall": 0.5772,
                        "f1_score": 0.5640219237197334
                    },
                    {
                        "epoch": 4,
                        "loss": 1.2369956487341771,
                        "accuracy": 0.569,
                        "precision": 0.6404443353554523,
                        "recall": 0.569,
                        "f1_score": 0.5518344822696004
                    },
                    {
                        "epoch": 5,
                        "loss": 1.2427808544303798,
                        "accuracy": 0.5247,
                        "precision": 0.5992157465620155,
                        "recall": 0.5247,
                        "f1_score": 0.5109321178611894
                    },
                    {
                        "epoch": 6,
                        "loss": 1.7174149525316456,
                        "accuracy": 0.5752,
                        "precision": 0.588446997072438,
                        "recall": 0.5752,
                        "f1_score": 0.5681143216698883
                    },
                    {
                        "epoch": 7,
                        "loss": 1.0683840981012658,
                        "accuracy": 0.5456,
                        "precision": 0.6355032678722614,
                        "recall": 0.5456,
                        "f1_score": 0.5282365887992482
                    },
                    {
                        "epoch": 8,
                        "loss": 1.1974881329113924,
                        "accuracy": 0.5003,
                        "precision": 0.6397213540732313,
                        "recall": 0.5003,
                        "f1_score": 0.47639297371267914
                    },
                    {
                        "epoch": 9,
                        "loss": 1.4449663765822784,
                        "accuracy": 0.4857,
                        "precision": 0.6881806472347318,
                        "recall": 0.4857,
                        "f1_score": 0.43161377209250057
                    },
                    {
                        "epoch": 10,
                        "loss": 1.071153085443038,
                        "accuracy": 0.5738,
                        "precision": 0.7365592125207048,
                        "recall": 0.5738,
                        "f1_score": 0.5564730231523346
                    },
                    {
                        "epoch": 11,
                        "loss": 0.9753757911392406,
                        "accuracy": 0.6743,
                        "precision": 0.7756012219355191,
                        "recall": 0.6743,
                        "f1_score": 0.6451617634928378
                    },
                    {
                        "epoch": 12,
                        "loss": 2.0236352848101267,
                        "accuracy": 0.4892,
                        "precision": 0.656713177694584,
                        "recall": 0.4892,
                        "f1_score": 0.4599502193181289
                    },
                    {
                        "epoch": 13,
                        "loss": 1.3554193037974684,
                        "accuracy": 0.4025,
                        "precision": 0.4097935956488778,
                        "recall": 0.4025,
                        "f1_score": 0.29216123607924477
                    },
                    {
                        "epoch": 14,
                        "loss": 3.0585443037974684,
                        "accuracy": 0.4324,
                        "precision": 0.581622712235939,
                        "recall": 0.4324,
                        "f1_score": 0.35493625948224866
                    },
                    {
                        "epoch": 15,
                        "loss": 2.835245253164557,
                        "accuracy": 0.4296,
                        "precision": 0.5578121728906759,
                        "recall": 0.4296,
                        "f1_score": 0.36770307430466026
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.6569313862772554,
                "precision": 0.75658012377836,
                "recall": 0.6569313862772554,
                "f1_score": 0.622764670292271
            },
            "confusion_matrix": [
                [
                    2943,
                    31,
                    359
                ],
                [
                    2121,
                    830,
                    382
                ],
                [
                    527,
                    10,
                    2795
                ]
            ],
            "best_epoch": 11,
            "time_train": 65.85765964984894
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.6569313862772554,
            "accuracy_std": 0.0,
            "precision_mean": 0.75658012377836,
            "precision_std": 0.0,
            "recall_mean": 0.6569313862772554,
            "recall_std": 0.0,
            "f1_score_mean": 0.622764670292271,
            "f1_score_std": 0.0,
            "time_train_mean": 65.85765964984894,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-3B-bnb-4bit)_LoRA_best_model_3.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-3B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-3B-bnb-4bit",
        "best_experiment": {
            "id": 4,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-3B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 32,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.1896494189698492,
                        "accuracy": 0.5800184650441
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7280347047738693,
                        "accuracy": 0.7433555306735813
                    },
                    {
                        "epoch": 3,
                        "loss": 1.403128925879397,
                        "accuracy": 0.6285579586304437
                    },
                    {
                        "epoch": 4,
                        "loss": 2.6780631673994977,
                        "accuracy": 0.6651344608796432
                    },
                    {
                        "epoch": 5,
                        "loss": 1.384657663316583,
                        "accuracy": 0.716856228023651
                    },
                    {
                        "epoch": 6,
                        "loss": 1.019634304334171,
                        "accuracy": 0.7363230989844226
                    },
                    {
                        "epoch": 7,
                        "loss": 1.2922473696608041,
                        "accuracy": 0.708900544129491
                    },
                    {
                        "epoch": 8,
                        "loss": 2.423680904522613,
                        "accuracy": 0.6917909128410631
                    },
                    {
                        "epoch": 9,
                        "loss": 7.3461938599246235,
                        "accuracy": 0.5511226353939537
                    },
                    {
                        "epoch": 10,
                        "loss": 0.8063952575376885,
                        "accuracy": 0.7571453827567918
                    },
                    {
                        "epoch": 11,
                        "loss": 0.4852828596105528,
                        "accuracy": 0.8208104975740075
                    },
                    {
                        "epoch": 12,
                        "loss": 0.48306228407663315,
                        "accuracy": 0.8209872905494333
                    },
                    {
                        "epoch": 13,
                        "loss": 0.4784542831344221,
                        "accuracy": 0.824641012041566
                    },
                    {
                        "epoch": 14,
                        "loss": 0.4586408605527638,
                        "accuracy": 0.8285893884927417
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.7851068037974684,
                        "accuracy": 0.3742,
                        "precision": 0.4640439600912374,
                        "recall": 0.3742,
                        "f1_score": 0.3251863766008118
                    },
                    {
                        "epoch": 2,
                        "loss": 3.7834256329113924,
                        "accuracy": 0.373,
                        "precision": 0.4105017985952063,
                        "recall": 0.373,
                        "f1_score": 0.24384694900734735
                    },
                    {
                        "epoch": 3,
                        "loss": 5.750197784810126,
                        "accuracy": 0.4552,
                        "precision": 0.34334344,
                        "recall": 0.4552,
                        "f1_score": 0.36381256118619204
                    },
                    {
                        "epoch": 4,
                        "loss": 8.989715189873417,
                        "accuracy": 0.4521,
                        "precision": 0.38922085181471583,
                        "recall": 0.4521,
                        "f1_score": 0.35715358584381224
                    },
                    {
                        "epoch": 5,
                        "loss": 6.956882911392405,
                        "accuracy": 0.4566,
                        "precision": 0.30331261254091796,
                        "recall": 0.4566,
                        "f1_score": 0.364078857611299
                    },
                    {
                        "epoch": 6,
                        "loss": 6.954113924050633,
                        "accuracy": 0.3622,
                        "precision": 0.274975360149474,
                        "recall": 0.3622,
                        "f1_score": 0.23168365830438778
                    },
                    {
                        "epoch": 7,
                        "loss": 12.00870253164557,
                        "accuracy": 0.3369,
                        "precision": 0.2944016389506411,
                        "recall": 0.3369,
                        "f1_score": 0.17518233877931677
                    },
                    {
                        "epoch": 8,
                        "loss": 40.2246835443038,
                        "accuracy": 0.3674,
                        "precision": 0.2761117247886047,
                        "recall": 0.3674,
                        "f1_score": 0.2430974354752127
                    },
                    {
                        "epoch": 9,
                        "loss": 4.24189082278481,
                        "accuracy": 0.4469,
                        "precision": 0.4910405636335314,
                        "recall": 0.4469,
                        "f1_score": 0.3887286866428407
                    },
                    {
                        "epoch": 10,
                        "loss": 3.8037974683544302,
                        "accuracy": 0.4327,
                        "precision": 0.41409486406754187,
                        "recall": 0.4327,
                        "f1_score": 0.3326457845356428
                    },
                    {
                        "epoch": 11,
                        "loss": 2.691950158227848,
                        "accuracy": 0.4432,
                        "precision": 0.7029125747316449,
                        "recall": 0.4432,
                        "f1_score": 0.346302242155426
                    },
                    {
                        "epoch": 12,
                        "loss": 3.5231408227848102,
                        "accuracy": 0.4615,
                        "precision": 0.6075028402427746,
                        "recall": 0.4615,
                        "f1_score": 0.3743475621816611
                    },
                    {
                        "epoch": 13,
                        "loss": 4.0909810126582276,
                        "accuracy": 0.4624,
                        "precision": 0.5905726524789269,
                        "recall": 0.4624,
                        "f1_score": 0.37101162965568296
                    },
                    {
                        "epoch": 14,
                        "loss": 2.3643196202531644,
                        "accuracy": 0.4477,
                        "precision": 0.5987463272428234,
                        "recall": 0.4477,
                        "f1_score": 0.3590182347785882
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4379875975195039,
                "precision": 0.4697866164832106,
                "recall": 0.4379875975195039,
                "f1_score": 0.37736116836232647
            },
            "confusion_matrix": [
                [
                    2881,
                    210,
                    242
                ],
                [
                    1850,
                    1309,
                    174
                ],
                [
                    2834,
                    309,
                    189
                ]
            ],
            "best_epoch": 9,
            "time_train": 61.241414507230125
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4379875975195039,
            "accuracy_std": 0.0,
            "precision_mean": 0.4697866164832106,
            "precision_std": 0.0,
            "recall_mean": 0.4379875975195039,
            "recall_std": 0.0,
            "f1_score_mean": 0.37736116836232647,
            "f1_score_std": 0.0,
            "time_train_mean": 61.241414507230125,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-3B-bnb-4bit)_LoRA_best_model_4.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-3B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-3B-bnb-4bit",
        "best_experiment": {
            "id": 5,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-3B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 32,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.4768569409547738,
                        "accuracy": 0.5452098925491583
                    },
                    {
                        "epoch": 2,
                        "loss": 1.7128415515075377,
                        "accuracy": 0.6185004026951106
                    },
                    {
                        "epoch": 3,
                        "loss": 1.0462223225502512,
                        "accuracy": 0.6890997308818041
                    },
                    {
                        "epoch": 4,
                        "loss": 0.564453125,
                        "accuracy": 0.7984560080146149
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4854889682788945,
                        "accuracy": 0.8167246154752784
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4523251020728643,
                        "accuracy": 0.8277054236156128
                    },
                    {
                        "epoch": 7,
                        "loss": 0.43607196136934673,
                        "accuracy": 0.8312019957962559
                    },
                    {
                        "epoch": 8,
                        "loss": 0.43492854899497485,
                        "accuracy": 0.8301412379437012
                    },
                    {
                        "epoch": 9,
                        "loss": 0.42428941582914576,
                        "accuracy": 0.8330288565423223
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4156230370603015,
                        "accuracy": 0.8352485905671125
                    },
                    {
                        "epoch": 11,
                        "loss": 0.4076485945351759,
                        "accuracy": 0.8387058754198833
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 4.544897151898734,
                        "accuracy": 0.4434,
                        "precision": 0.3628492021979584,
                        "recall": 0.4434,
                        "f1_score": 0.34904794322462823
                    },
                    {
                        "epoch": 2,
                        "loss": 6.025712025316456,
                        "accuracy": 0.4145,
                        "precision": 0.4178382238974214,
                        "recall": 0.4145,
                        "f1_score": 0.3083020447872544
                    },
                    {
                        "epoch": 3,
                        "loss": 0.8548753955696202,
                        "accuracy": 0.6622,
                        "precision": 0.7271439302684028,
                        "recall": 0.6622,
                        "f1_score": 0.6613242513817218
                    },
                    {
                        "epoch": 4,
                        "loss": 0.616767207278481,
                        "accuracy": 0.7398,
                        "precision": 0.7639042799176535,
                        "recall": 0.7398,
                        "f1_score": 0.7310448465403597
                    },
                    {
                        "epoch": 5,
                        "loss": 0.7316307357594937,
                        "accuracy": 0.7216,
                        "precision": 0.7813894977027072,
                        "recall": 0.7216,
                        "f1_score": 0.708675059583059
                    },
                    {
                        "epoch": 6,
                        "loss": 0.6061362737341772,
                        "accuracy": 0.7643,
                        "precision": 0.7725840523632694,
                        "recall": 0.7643,
                        "f1_score": 0.7578662895503739
                    },
                    {
                        "epoch": 7,
                        "loss": 0.8354183148734177,
                        "accuracy": 0.7341,
                        "precision": 0.7959211122071294,
                        "recall": 0.7341,
                        "f1_score": 0.7176206729702858
                    },
                    {
                        "epoch": 8,
                        "loss": 0.9404173259493671,
                        "accuracy": 0.7188,
                        "precision": 0.8000898406775986,
                        "recall": 0.7188,
                        "f1_score": 0.7011007746667115
                    },
                    {
                        "epoch": 9,
                        "loss": 0.6253214003164557,
                        "accuracy": 0.7599,
                        "precision": 0.7968858097572529,
                        "recall": 0.7599,
                        "f1_score": 0.7483080374253157
                    },
                    {
                        "epoch": 10,
                        "loss": 1.2909909018987342,
                        "accuracy": 0.6947,
                        "precision": 0.7500337265973438,
                        "recall": 0.6947,
                        "f1_score": 0.6946616312507312
                    },
                    {
                        "epoch": 11,
                        "loss": 2.3860759493670884,
                        "accuracy": 0.5816,
                        "precision": 0.7659651383013291,
                        "recall": 0.5816,
                        "f1_score": 0.5600300718522152
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7491498299659932,
                "precision": 0.756692155356922,
                "recall": 0.7491498299659932,
                "f1_score": 0.7421303080273558
            },
            "confusion_matrix": [
                [
                    2608,
                    462,
                    263
                ],
                [
                    1336,
                    1754,
                    243
                ],
                [
                    148,
                    56,
                    3128
                ]
            ],
            "best_epoch": 6,
            "time_train": 48.257619909445445
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7491498299659932,
            "accuracy_std": 0.0,
            "precision_mean": 0.756692155356922,
            "precision_std": 0.0,
            "recall_mean": 0.7491498299659932,
            "recall_std": 0.0,
            "f1_score_mean": 0.7421303080273558,
            "f1_score_std": 0.0,
            "time_train_mean": 48.257619909445445,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-3B-bnb-4bit)_LoRA_best_model_5.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-3B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-3B-bnb-4bit",
        "best_experiment": {
            "id": 6,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-3B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.1\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 16,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.4072020257537687,
                        "accuracy": 0.5349558999744632
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1959111966080402,
                        "accuracy": 0.5658750270100379
                    },
                    {
                        "epoch": 3,
                        "loss": 1.1319880653266332,
                        "accuracy": 0.57862376490463
                    },
                    {
                        "epoch": 4,
                        "loss": 1.026813756281407,
                        "accuracy": 0.6384780089182234
                    },
                    {
                        "epoch": 5,
                        "loss": 0.8068908998115578,
                        "accuracy": 0.7175437562614179
                    },
                    {
                        "epoch": 6,
                        "loss": 0.5308966708542714,
                        "accuracy": 0.8045651874987723
                    },
                    {
                        "epoch": 7,
                        "loss": 0.5065267744974874,
                        "accuracy": 0.8170192704343214
                    },
                    {
                        "epoch": 8,
                        "loss": 0.4891891096105528,
                        "accuracy": 0.8226373583200739
                    },
                    {
                        "epoch": 9,
                        "loss": 0.4847037923994975,
                        "accuracy": 0.8204176242952835
                    },
                    {
                        "epoch": 10,
                        "loss": 0.48442898084170855,
                        "accuracy": 0.8201426130001768
                    },
                    {
                        "epoch": 11,
                        "loss": 0.4553774733040201,
                        "accuracy": 0.8280393659025281
                    },
                    {
                        "epoch": 12,
                        "loss": 0.45104919126884424,
                        "accuracy": 0.8312216394601921
                    },
                    {
                        "epoch": 13,
                        "loss": 0.4568055119346734,
                        "accuracy": 0.8283929518533797
                    },
                    {
                        "epoch": 14,
                        "loss": 0.4552523358982412,
                        "accuracy": 0.826232148820398
                    },
                    {
                        "epoch": 15,
                        "loss": 0.44449788002512564,
                        "accuracy": 0.8304555365666804
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.6833465189873418,
                        "accuracy": 0.3329,
                        "precision": 0.29824036479714067,
                        "recall": 0.3329,
                        "f1_score": 0.16792738967886728
                    },
                    {
                        "epoch": 2,
                        "loss": 2.8156645569620253,
                        "accuracy": 0.3427,
                        "precision": 0.28623132756635944,
                        "recall": 0.3427,
                        "f1_score": 0.19174347513966228
                    },
                    {
                        "epoch": 3,
                        "loss": 3.371242088607595,
                        "accuracy": 0.4134,
                        "precision": 0.3459001700810426,
                        "recall": 0.4134,
                        "f1_score": 0.3173399342625811
                    },
                    {
                        "epoch": 4,
                        "loss": 2.4601463607594938,
                        "accuracy": 0.4368,
                        "precision": 0.36149093779060404,
                        "recall": 0.4368,
                        "f1_score": 0.34372486832206317
                    },
                    {
                        "epoch": 5,
                        "loss": 3.2869857594936707,
                        "accuracy": 0.4263,
                        "precision": 0.28524245873838877,
                        "recall": 0.4263,
                        "f1_score": 0.34057875400099236
                    },
                    {
                        "epoch": 6,
                        "loss": 4.102848101265823,
                        "accuracy": 0.4502,
                        "precision": 0.3353439998640773,
                        "recall": 0.4502,
                        "f1_score": 0.3526958388478007
                    },
                    {
                        "epoch": 7,
                        "loss": 5.842958860759493,
                        "accuracy": 0.4384,
                        "precision": 0.39222152805109606,
                        "recall": 0.4384,
                        "f1_score": 0.33848652682623515
                    },
                    {
                        "epoch": 8,
                        "loss": 5.316257911392405,
                        "accuracy": 0.4584,
                        "precision": 0.3156760033341494,
                        "recall": 0.4584,
                        "f1_score": 0.36331284079455406
                    },
                    {
                        "epoch": 9,
                        "loss": 6.094541139240507,
                        "accuracy": 0.4473,
                        "precision": 0.37671126517396447,
                        "recall": 0.4473,
                        "f1_score": 0.3486401186429969
                    },
                    {
                        "epoch": 10,
                        "loss": 5.473299050632911,
                        "accuracy": 0.4534,
                        "precision": 0.3558541353383459,
                        "recall": 0.4534,
                        "f1_score": 0.3549065884635738
                    },
                    {
                        "epoch": 11,
                        "loss": 6.033623417721519,
                        "accuracy": 0.4539,
                        "precision": 0.35505660728548544,
                        "recall": 0.4539,
                        "f1_score": 0.355091808030444
                    },
                    {
                        "epoch": 12,
                        "loss": 4.938291139240507,
                        "accuracy": 0.4605,
                        "precision": 0.3316589990418524,
                        "recall": 0.4605,
                        "f1_score": 0.3628888810762121
                    },
                    {
                        "epoch": 13,
                        "loss": 5.550039556962025,
                        "accuracy": 0.4605,
                        "precision": 0.3070302571059773,
                        "recall": 0.4605,
                        "f1_score": 0.3682328790695374
                    },
                    {
                        "epoch": 14,
                        "loss": 5.087223101265823,
                        "accuracy": 0.4573,
                        "precision": 0.35044425689268044,
                        "recall": 0.4573,
                        "f1_score": 0.35890814873540455
                    },
                    {
                        "epoch": 15,
                        "loss": 5.1623813291139244,
                        "accuracy": 0.4571,
                        "precision": 0.34668369767004326,
                        "recall": 0.4571,
                        "f1_score": 0.35896202991125625
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.45399079815963195,
                "precision": 0.3027513197983426,
                "recall": 0.45399079815963195,
                "f1_score": 0.3630500757327381
            },
            "confusion_matrix": [
                [
                    2371,
                    962,
                    0
                ],
                [
                    1165,
                    2168,
                    0
                ],
                [
                    1707,
                    1625,
                    0
                ]
            ],
            "best_epoch": 13,
            "time_train": 65.90123765865961
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.45399079815963195,
            "accuracy_std": 0.0,
            "precision_mean": 0.3027513197983426,
            "precision_std": 0.0,
            "recall_mean": 0.45399079815963195,
            "recall_std": 0.0,
            "f1_score_mean": 0.3630500757327381,
            "f1_score_std": 0.0,
            "time_train_mean": 65.90123765865961,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-3B-bnb-4bit)_LoRA_best_model_6.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-3B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-3B-bnb-4bit",
        "best_experiment": {
            "id": 7,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-3B-bnb-4bit - AdamW, lr=0.003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 16,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.0288846576633166,
                        "accuracy": 0.6204058380969218
                    },
                    {
                        "epoch": 2,
                        "loss": 0.5625392587939698,
                        "accuracy": 0.7875341308660891
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5079891645728644,
                        "accuracy": 0.8102225627123971
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5510855056532663,
                        "accuracy": 0.7878484294890683
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5545942603643216,
                        "accuracy": 0.7853536841691713
                    },
                    {
                        "epoch": 6,
                        "loss": 0.5493433966708543,
                        "accuracy": 0.7972577445145068
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 0.987589003164557,
                        "accuracy": 0.6009,
                        "precision": 0.7409703480166702,
                        "recall": 0.6009,
                        "f1_score": 0.5888995305965292
                    },
                    {
                        "epoch": 2,
                        "loss": 1.2633010284810127,
                        "accuracy": 0.5308,
                        "precision": 0.6808438513184779,
                        "recall": 0.5308,
                        "f1_score": 0.4957180917922382
                    },
                    {
                        "epoch": 3,
                        "loss": 1.229628164556962,
                        "accuracy": 0.4733,
                        "precision": 0.7121518028789334,
                        "recall": 0.4733,
                        "f1_score": 0.3988397895219052
                    },
                    {
                        "epoch": 4,
                        "loss": 1.0594837816455696,
                        "accuracy": 0.5628,
                        "precision": 0.6908588331922464,
                        "recall": 0.5628,
                        "f1_score": 0.5430152355792326
                    },
                    {
                        "epoch": 5,
                        "loss": 1.0305577531645569,
                        "accuracy": 0.5157,
                        "precision": 0.7200486442431384,
                        "recall": 0.5157,
                        "f1_score": 0.47793972175094424
                    },
                    {
                        "epoch": 6,
                        "loss": 0.8581882911392406,
                        "accuracy": 0.5956,
                        "precision": 0.7444912552747199,
                        "recall": 0.5956,
                        "f1_score": 0.5836463041438519
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.5819163832766553,
                "precision": 0.7163483733897107,
                "recall": 0.5819163832766553,
                "f1_score": 0.5688608805335725
            },
            "confusion_matrix": [
                [
                    3128,
                    84,
                    121
                ],
                [
                    2095,
                    1164,
                    74
                ],
                [
                    1607,
                    199,
                    1526
                ]
            ],
            "best_epoch": 1,
            "time_train": 25.81686147848765
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.5819163832766553,
            "accuracy_std": 0.0,
            "precision_mean": 0.7163483733897107,
            "precision_std": 0.0,
            "recall_mean": 0.5819163832766553,
            "recall_std": 0.0,
            "f1_score_mean": 0.5688608805335725,
            "f1_score_std": 0.0,
            "time_train_mean": 25.81686147848765,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-3B-bnb-4bit)_LoRA_best_model_7.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-3B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-3B-bnb-4bit",
        "best_experiment": {
            "id": 8,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-3B-bnb-4bit - AdamW, lr=3e-05, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 3e-05\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 3e-05,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 16,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.6828183888190955,
                        "accuracy": 0.4819965820024751
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1868031564070352,
                        "accuracy": 0.5672107961576993
                    },
                    {
                        "epoch": 3,
                        "loss": 1.3398290279522613,
                        "accuracy": 0.6011354037755122
                    },
                    {
                        "epoch": 4,
                        "loss": 1.8731793734296482,
                        "accuracy": 0.6017050700296619
                    },
                    {
                        "epoch": 5,
                        "loss": 1.436503808103015,
                        "accuracy": 0.6341171155243877
                    },
                    {
                        "epoch": 6,
                        "loss": 1.0963361730527639,
                        "accuracy": 0.6587895574282515
                    },
                    {
                        "epoch": 7,
                        "loss": 0.8518520336055276,
                        "accuracy": 0.7041271337929951
                    },
                    {
                        "epoch": 8,
                        "loss": 0.7250952025753769,
                        "accuracy": 0.7431787376981555
                    },
                    {
                        "epoch": 9,
                        "loss": 0.7406367776381909,
                        "accuracy": 0.7518415934940185
                    },
                    {
                        "epoch": 10,
                        "loss": 0.7948286353643216,
                        "accuracy": 0.7310389533855854
                    },
                    {
                        "epoch": 11,
                        "loss": 1.0462026931532664,
                        "accuracy": 0.6714597206670988
                    },
                    {
                        "epoch": 12,
                        "loss": 1.1792163944723617,
                        "accuracy": 0.6314455772290648
                    },
                    {
                        "epoch": 13,
                        "loss": 1.024605449120603,
                        "accuracy": 0.6280472233681026
                    },
                    {
                        "epoch": 14,
                        "loss": 1.0311911118090453,
                        "accuracy": 0.6293437051878916
                    },
                    {
                        "epoch": 15,
                        "loss": 1.0523417870603016,
                        "accuracy": 0.6349225057457717
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.5529074367088607,
                        "accuracy": 0.376,
                        "precision": 0.39143142045320256,
                        "recall": 0.376,
                        "f1_score": 0.34041786409322994
                    },
                    {
                        "epoch": 2,
                        "loss": 2.7185522151898733,
                        "accuracy": 0.3782,
                        "precision": 0.5045355846698405,
                        "recall": 0.3782,
                        "f1_score": 0.2575178234905141
                    },
                    {
                        "epoch": 3,
                        "loss": 3.538370253164557,
                        "accuracy": 0.4082,
                        "precision": 0.3983601099055939,
                        "recall": 0.4082,
                        "f1_score": 0.29939379727679327
                    },
                    {
                        "epoch": 4,
                        "loss": 4.1979825949367084,
                        "accuracy": 0.4402,
                        "precision": 0.3768894183484362,
                        "recall": 0.4402,
                        "f1_score": 0.343190256136281
                    },
                    {
                        "epoch": 5,
                        "loss": 7.511867088607595,
                        "accuracy": 0.4357,
                        "precision": 0.38912886128136503,
                        "recall": 0.4357,
                        "f1_score": 0.3373593783233847
                    },
                    {
                        "epoch": 6,
                        "loss": 9.274525316455696,
                        "accuracy": 0.4466,
                        "precision": 0.306067168,
                        "recall": 0.4466,
                        "f1_score": 0.3575522875089893
                    },
                    {
                        "epoch": 7,
                        "loss": 11.672863924050633,
                        "accuracy": 0.4411,
                        "precision": 0.29420547709921147,
                        "recall": 0.4411,
                        "f1_score": 0.35296733571091815
                    },
                    {
                        "epoch": 8,
                        "loss": 14.806962025316455,
                        "accuracy": 0.4448,
                        "precision": 0.38684227293971024,
                        "recall": 0.4448,
                        "f1_score": 0.3489976216734571
                    },
                    {
                        "epoch": 9,
                        "loss": 16.382911392405063,
                        "accuracy": 0.451,
                        "precision": 0.3682509759735311,
                        "recall": 0.451,
                        "f1_score": 0.3576779043280182
                    },
                    {
                        "epoch": 10,
                        "loss": 9.719145569620252,
                        "accuracy": 0.4454,
                        "precision": 0.37759173397364787,
                        "recall": 0.4454,
                        "f1_score": 0.3497743159529319
                    },
                    {
                        "epoch": 11,
                        "loss": 6.756329113924051,
                        "accuracy": 0.4436,
                        "precision": 0.6067204559748179,
                        "recall": 0.4436,
                        "f1_score": 0.3491562648354968
                    },
                    {
                        "epoch": 12,
                        "loss": 1.7747231012658229,
                        "accuracy": 0.4866,
                        "precision": 0.5467092478889808,
                        "recall": 0.4866,
                        "f1_score": 0.4532215650833962
                    },
                    {
                        "epoch": 13,
                        "loss": 1.1667325949367089,
                        "accuracy": 0.5613,
                        "precision": 0.6058011483615277,
                        "recall": 0.5613,
                        "f1_score": 0.5512969559833468
                    },
                    {
                        "epoch": 14,
                        "loss": 1.2656744462025316,
                        "accuracy": 0.5575,
                        "precision": 0.6157137424530572,
                        "recall": 0.5575,
                        "f1_score": 0.541540563380375
                    },
                    {
                        "epoch": 15,
                        "loss": 1.3369264240506329,
                        "accuracy": 0.5803,
                        "precision": 0.6574481662503664,
                        "recall": 0.5803,
                        "f1_score": 0.5543821357927816
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.5769153830766153,
                "precision": 0.6556105203526384,
                "recall": 0.5769153830766153,
                "f1_score": 0.5508673046470789
            },
            "confusion_matrix": [
                [
                    2196,
                    60,
                    1077
                ],
                [
                    1507,
                    883,
                    943
                ],
                [
                    587,
                    56,
                    2689
                ]
            ],
            "best_epoch": 15,
            "time_train": 66.00264426469803
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.5769153830766153,
            "accuracy_std": 0.0,
            "precision_mean": 0.6556105203526384,
            "precision_std": 0.0,
            "recall_mean": 0.5769153830766153,
            "recall_std": 0.0,
            "f1_score_mean": 0.5508673046470789,
            "f1_score_std": 0.0,
            "time_train_mean": 66.00264426469803,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-3B-bnb-4bit)_LoRA_best_model_8.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-3B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-3B-bnb-4bit",
        "best_experiment": {
            "id": 9,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-3B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.5, 0.55)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.07\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 16,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2455735709798994,
                        "accuracy": 0.5752646983715403
                    },
                    {
                        "epoch": 2,
                        "loss": 0.659434869660804,
                        "accuracy": 0.7464002985836918
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5293950219849246,
                        "accuracy": 0.8083760583023946
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5078861102386935,
                        "accuracy": 0.8139352151963384
                    },
                    {
                        "epoch": 5,
                        "loss": 0.47938913316582915,
                        "accuracy": 0.8233838175496494
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4592101130653266,
                        "accuracy": 0.8284911701730607
                    },
                    {
                        "epoch": 7,
                        "loss": 0.4548082207914573,
                        "accuracy": 0.8302590999273184
                    },
                    {
                        "epoch": 8,
                        "loss": 0.44831579773869346,
                        "accuracy": 0.8327931325750879
                    },
                    {
                        "epoch": 9,
                        "loss": 0.44583758636934673,
                        "accuracy": 0.8315948690749798
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4453615734924623,
                        "accuracy": 0.8308287661814682
                    },
                    {
                        "epoch": 11,
                        "loss": 0.4328527402638191,
                        "accuracy": 0.833500304476791
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.9331487341772151,
                        "accuracy": 0.3839,
                        "precision": 0.5817540700980455,
                        "recall": 0.3839,
                        "f1_score": 0.2793302564096681
                    },
                    {
                        "epoch": 2,
                        "loss": 3.0741693037974684,
                        "accuracy": 0.415,
                        "precision": 0.41129957083777935,
                        "recall": 0.415,
                        "f1_score": 0.3093950387372105
                    },
                    {
                        "epoch": 3,
                        "loss": 2.934038765822785,
                        "accuracy": 0.444,
                        "precision": 0.3909655638664687,
                        "recall": 0.444,
                        "f1_score": 0.3481963399787273
                    },
                    {
                        "epoch": 4,
                        "loss": 3.363726265822785,
                        "accuracy": 0.4285,
                        "precision": 0.4161804355777337,
                        "recall": 0.4285,
                        "f1_score": 0.3271300931147025
                    },
                    {
                        "epoch": 5,
                        "loss": 3.5892009493670884,
                        "accuracy": 0.4338,
                        "precision": 0.4162418291605936,
                        "recall": 0.4338,
                        "f1_score": 0.33404612046818766
                    },
                    {
                        "epoch": 6,
                        "loss": 3.115506329113924,
                        "accuracy": 0.4544,
                        "precision": 0.3784518123277222,
                        "recall": 0.4544,
                        "f1_score": 0.3611273885294419
                    },
                    {
                        "epoch": 7,
                        "loss": 3.1038370253164556,
                        "accuracy": 0.4507,
                        "precision": 0.38890640196912785,
                        "recall": 0.4507,
                        "f1_score": 0.35627697325144014
                    },
                    {
                        "epoch": 8,
                        "loss": 3.1854232594936707,
                        "accuracy": 0.4529,
                        "precision": 0.38595810923745494,
                        "recall": 0.4529,
                        "f1_score": 0.3586354328595517
                    },
                    {
                        "epoch": 9,
                        "loss": 3.4576740506329116,
                        "accuracy": 0.4498,
                        "precision": 0.39602917426175716,
                        "recall": 0.4498,
                        "f1_score": 0.3545180301829577
                    },
                    {
                        "epoch": 10,
                        "loss": 3.5035601265822787,
                        "accuracy": 0.4469,
                        "precision": 0.4010447638813079,
                        "recall": 0.4469,
                        "f1_score": 0.3504976861145801
                    },
                    {
                        "epoch": 11,
                        "loss": 3.982001582278481,
                        "accuracy": 0.442,
                        "precision": 0.40789987211747264,
                        "recall": 0.442,
                        "f1_score": 0.3441469045116178
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.44998999799959993,
                "precision": 0.37034443622926644,
                "recall": 0.44998999799959993,
                "f1_score": 0.35733359577902024
            },
            "confusion_matrix": [
                [
                    3127,
                    206,
                    0
                ],
                [
                    1961,
                    1372,
                    0
                ],
                [
                    3018,
                    314,
                    0
                ]
            ],
            "best_epoch": 6,
            "time_train": 48.077357625961305
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.44998999799959993,
            "accuracy_std": 0.0,
            "precision_mean": 0.37034443622926644,
            "precision_std": 0.0,
            "recall_mean": 0.44998999799959993,
            "recall_std": 0.0,
            "f1_score_mean": 0.35733359577902024,
            "f1_score_std": 0.0,
            "time_train_mean": 48.077357625961305,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-3B-bnb-4bit)_LoRA_best_model_9.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-3B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-3B-bnb-4bit",
        "best_experiment": {
            "id": 10,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-3B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.7, 0.75)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 16,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2714941896984924,
                        "accuracy": 0.5822578427328265
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7585682317839196,
                        "accuracy": 0.7203135128764218
                    },
                    {
                        "epoch": 3,
                        "loss": 0.4978702104271357,
                        "accuracy": 0.8142691574832538
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4587807200062814,
                        "accuracy": 0.8306519732060423
                    },
                    {
                        "epoch": 5,
                        "loss": 0.44210309359296485,
                        "accuracy": 0.8312019957962559
                    },
                    {
                        "epoch": 6,
                        "loss": 0.416609414258794,
                        "accuracy": 0.8384112204608404
                    },
                    {
                        "epoch": 7,
                        "loss": 0.412830755339196,
                        "accuracy": 0.8394523346494588
                    },
                    {
                        "epoch": 8,
                        "loss": 0.40750628140703515,
                        "accuracy": 0.8403952305183963
                    },
                    {
                        "epoch": 9,
                        "loss": 0.3984669440954774,
                        "accuracy": 0.8429292631661658
                    },
                    {
                        "epoch": 10,
                        "loss": 0.3919720673680904,
                        "accuracy": 0.8444418252892529
                    },
                    {
                        "epoch": 11,
                        "loss": 0.38083483825376885,
                        "accuracy": 0.848134834109258
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 2.9393789556962027,
                        "accuracy": 0.4279,
                        "precision": 0.3395974119779398,
                        "recall": 0.4279,
                        "f1_score": 0.3324302154718373
                    },
                    {
                        "epoch": 2,
                        "loss": 3.6149129746835444,
                        "accuracy": 0.4362,
                        "precision": 0.4054668747682454,
                        "recall": 0.4362,
                        "f1_score": 0.3367787373614336
                    },
                    {
                        "epoch": 3,
                        "loss": 2.5449960443037973,
                        "accuracy": 0.4394,
                        "precision": 0.40362025833561194,
                        "recall": 0.4394,
                        "f1_score": 0.3409171121945992
                    },
                    {
                        "epoch": 4,
                        "loss": 3.0096914556962027,
                        "accuracy": 0.454,
                        "precision": 0.3816451410075198,
                        "recall": 0.454,
                        "f1_score": 0.35880697149308305
                    },
                    {
                        "epoch": 5,
                        "loss": 2.6560522151898733,
                        "accuracy": 0.4429,
                        "precision": 0.40382472098671934,
                        "recall": 0.4429,
                        "f1_score": 0.34486171373394897
                    },
                    {
                        "epoch": 6,
                        "loss": 2.8150712025316458,
                        "accuracy": 0.4695,
                        "precision": 0.34900218797674015,
                        "recall": 0.4695,
                        "f1_score": 0.3756219427748376
                    },
                    {
                        "epoch": 7,
                        "loss": 3.0314477848101267,
                        "accuracy": 0.4455,
                        "precision": 0.39793441916541905,
                        "recall": 0.4455,
                        "f1_score": 0.3482517247669815
                    },
                    {
                        "epoch": 8,
                        "loss": 2.9735957278481013,
                        "accuracy": 0.4632,
                        "precision": 0.3582942033365571,
                        "recall": 0.4632,
                        "f1_score": 0.3684484754864099
                    },
                    {
                        "epoch": 9,
                        "loss": 3.0474683544303796,
                        "accuracy": 0.4547,
                        "precision": 0.3835361194189911,
                        "recall": 0.4547,
                        "f1_score": 0.35928053024349366
                    },
                    {
                        "epoch": 10,
                        "loss": 3.0343156645569622,
                        "accuracy": 0.4529,
                        "precision": 0.38688855100349584,
                        "recall": 0.4529,
                        "f1_score": 0.3565427467429729
                    },
                    {
                        "epoch": 11,
                        "loss": 3.1186708860759493,
                        "accuracy": 0.4618,
                        "precision": 0.37121886167634716,
                        "recall": 0.4618,
                        "f1_score": 0.3664559585251597
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4639927985597119,
                "precision": 0.3413854543069828,
                "recall": 0.4639927985597119,
                "f1_score": 0.37002582240870147
            },
            "confusion_matrix": [
                [
                    2990,
                    343,
                    0
                ],
                [
                    1684,
                    1649,
                    0
                ],
                [
                    2645,
                    687,
                    0
                ]
            ],
            "best_epoch": 6,
            "time_train": 48.49191049337387
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4639927985597119,
            "accuracy_std": 0.0,
            "precision_mean": 0.3413854543069828,
            "precision_std": 0.0,
            "recall_mean": 0.4639927985597119,
            "recall_std": 0.0,
            "f1_score_mean": 0.37002582240870147,
            "f1_score_std": 0.0,
            "time_train_mean": 48.49191049337387,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-3B-bnb-4bit)_LoRA_best_model_10.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-3B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-3B-bnb-4bit",
        "best_experiment": {
            "id": 11,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-3B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.5, 0.55)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 16,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.7434977622487438,
                        "accuracy": 0.5616319955998192
                    },
                    {
                        "epoch": 2,
                        "loss": 1.7326868718592965,
                        "accuracy": 0.6170074842359597
                    },
                    {
                        "epoch": 3,
                        "loss": 1.2902108197236182,
                        "accuracy": 0.6686703203881588
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6967258165829145,
                        "accuracy": 0.7714263264384073
                    },
                    {
                        "epoch": 5,
                        "loss": 0.49699670226130654,
                        "accuracy": 0.8133655489421887
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4930757302135678,
                        "accuracy": 0.8168424774588956
                    },
                    {
                        "epoch": 7,
                        "loss": 0.4471184045226131,
                        "accuracy": 0.8272536193450802
                    },
                    {
                        "epoch": 8,
                        "loss": 0.44146023084170855,
                        "accuracy": 0.8276661362877404
                    },
                    {
                        "epoch": 9,
                        "loss": 0.41501452575376885,
                        "accuracy": 0.8361129117803052
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4053495014133166,
                        "accuracy": 0.83898088671499
                    },
                    {
                        "epoch": 11,
                        "loss": 0.3755643451633166,
                        "accuracy": 0.8476633861747893
                    },
                    {
                        "epoch": 12,
                        "loss": 0.36274880260678394,
                        "accuracy": 0.8527903824621368
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 2.5670490506329116,
                        "accuracy": 0.4391,
                        "precision": 0.5816675030833146,
                        "recall": 0.4391,
                        "f1_score": 0.3475775728903818
                    },
                    {
                        "epoch": 2,
                        "loss": 3.9517405063291138,
                        "accuracy": 0.4458,
                        "precision": 0.3918937903940272,
                        "recall": 0.4458,
                        "f1_score": 0.35077431622726946
                    },
                    {
                        "epoch": 3,
                        "loss": 1.5901898734177216,
                        "accuracy": 0.4587,
                        "precision": 0.6308216806087997,
                        "recall": 0.4587,
                        "f1_score": 0.37155118118447106
                    },
                    {
                        "epoch": 4,
                        "loss": 0.9196993670886076,
                        "accuracy": 0.6608,
                        "precision": 0.7635342532500359,
                        "recall": 0.6608,
                        "f1_score": 0.6486662193636208
                    },
                    {
                        "epoch": 5,
                        "loss": 1.0049446202531647,
                        "accuracy": 0.6086,
                        "precision": 0.7502979438686418,
                        "recall": 0.6086,
                        "f1_score": 0.5986052392780037
                    },
                    {
                        "epoch": 6,
                        "loss": 0.6424050632911392,
                        "accuracy": 0.7456,
                        "precision": 0.8004816615475209,
                        "recall": 0.7456,
                        "f1_score": 0.7175569567561196
                    },
                    {
                        "epoch": 7,
                        "loss": 0.5808692642405063,
                        "accuracy": 0.747,
                        "precision": 0.805002775460824,
                        "recall": 0.747,
                        "f1_score": 0.7241145160815681
                    },
                    {
                        "epoch": 8,
                        "loss": 0.9035304588607594,
                        "accuracy": 0.6988,
                        "precision": 0.7987168022555731,
                        "recall": 0.6988,
                        "f1_score": 0.6774859898217199
                    },
                    {
                        "epoch": 9,
                        "loss": 0.6711580300632911,
                        "accuracy": 0.7224,
                        "precision": 0.7946862998327142,
                        "recall": 0.7224,
                        "f1_score": 0.7070692405437096
                    },
                    {
                        "epoch": 10,
                        "loss": 0.8228837025316456,
                        "accuracy": 0.7044,
                        "precision": 0.8002800458062007,
                        "recall": 0.7044,
                        "f1_score": 0.6840983226893513
                    },
                    {
                        "epoch": 11,
                        "loss": 1.092068829113924,
                        "accuracy": 0.6855,
                        "precision": 0.7976239661667489,
                        "recall": 0.6855,
                        "f1_score": 0.6597926298167206
                    },
                    {
                        "epoch": 12,
                        "loss": 1.3127966772151898,
                        "accuracy": 0.6171,
                        "precision": 0.7806061866741553,
                        "recall": 0.6171,
                        "f1_score": 0.5934063917799122
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7310462092418484,
                "precision": 0.7915537391151101,
                "recall": 0.7310462092418484,
                "f1_score": 0.7069298852087278
            },
            "confusion_matrix": [
                [
                    3011,
                    99,
                    223
                ],
                [
                    1950,
                    1155,
                    228
                ],
                [
                    180,
                    9,
                    3143
                ]
            ],
            "best_epoch": 7,
            "time_train": 53.21388320128123
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7310462092418484,
            "accuracy_std": 0.0,
            "precision_mean": 0.7915537391151101,
            "precision_std": 0.0,
            "recall_mean": 0.7310462092418484,
            "recall_std": 0.0,
            "f1_score_mean": 0.7069298852087278,
            "f1_score_std": 0.0,
            "time_train_mean": 53.21388320128123,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-3B-bnb-4bit)_LoRA_best_model_11.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-3B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-3B-bnb-4bit",
        "best_experiment": {
            "id": 12,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-3B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.99, 0.99)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.07\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 16,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.442790122487437,
                        "accuracy": 0.5093209185377257
                    },
                    {
                        "epoch": 2,
                        "loss": 0.9925997173366834,
                        "accuracy": 0.6120179935961656
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6988163473618091,
                        "accuracy": 0.7579311293142397
                    },
                    {
                        "epoch": 4,
                        "loss": 0.7857107804648241,
                        "accuracy": 0.7189581000648241
                    },
                    {
                        "epoch": 5,
                        "loss": 0.6352710819723618,
                        "accuracy": 0.7750604042666038
                    },
                    {
                        "epoch": 6,
                        "loss": 0.6333130496231156,
                        "accuracy": 0.7723299349794723
                    },
                    {
                        "epoch": 7,
                        "loss": 0.624003808103015,
                        "accuracy": 0.7699923389710649
                    },
                    {
                        "epoch": 8,
                        "loss": 0.7015939070351759,
                        "accuracy": 0.7518808808218909
                    },
                    {
                        "epoch": 9,
                        "loss": 0.7189757380653267,
                        "accuracy": 0.7288388630247313
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.8512658227848102,
                        "accuracy": 0.3487,
                        "precision": 0.5121234693435466,
                        "recall": 0.3487,
                        "f1_score": 0.2685881601703261
                    },
                    {
                        "epoch": 2,
                        "loss": 1.576740506329114,
                        "accuracy": 0.388,
                        "precision": 0.5548032097899056,
                        "recall": 0.388,
                        "f1_score": 0.2719412409356364
                    },
                    {
                        "epoch": 3,
                        "loss": 2.523338607594937,
                        "accuracy": 0.4209,
                        "precision": 0.4726241068180856,
                        "recall": 0.4209,
                        "f1_score": 0.317524232352207
                    },
                    {
                        "epoch": 4,
                        "loss": 2.6201542721518987,
                        "accuracy": 0.4448,
                        "precision": 0.39850846383708705,
                        "recall": 0.4448,
                        "f1_score": 0.35027639021538387
                    },
                    {
                        "epoch": 5,
                        "loss": 2.3584849683544302,
                        "accuracy": 0.4349,
                        "precision": 0.7065318176117866,
                        "recall": 0.4349,
                        "f1_score": 0.33649195969469886
                    },
                    {
                        "epoch": 6,
                        "loss": 3.4857594936708862,
                        "accuracy": 0.4366,
                        "precision": 0.41151714890122204,
                        "recall": 0.4366,
                        "f1_score": 0.3387110866969152
                    },
                    {
                        "epoch": 7,
                        "loss": 3.3109177215189876,
                        "accuracy": 0.417,
                        "precision": 0.4176605544095964,
                        "recall": 0.417,
                        "f1_score": 0.31161427830471966
                    },
                    {
                        "epoch": 8,
                        "loss": 3.8585838607594938,
                        "accuracy": 0.421,
                        "precision": 0.4180586895535553,
                        "recall": 0.421,
                        "f1_score": 0.31716916739649015
                    },
                    {
                        "epoch": 9,
                        "loss": 3.2357594936708862,
                        "accuracy": 0.4394,
                        "precision": 0.4080931281752109,
                        "recall": 0.4394,
                        "f1_score": 0.341076500766141
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4385877175435087,
                "precision": 0.39123213334079,
                "recall": 0.4385877175435087,
                "f1_score": 0.34285334771242704
            },
            "confusion_matrix": [
                [
                    3220,
                    113,
                    0
                ],
                [
                    2168,
                    1165,
                    0
                ],
                [
                    3147,
                    185,
                    0
                ]
            ],
            "best_epoch": 4,
            "time_train": 39.70907981395722
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4385877175435087,
            "accuracy_std": 0.0,
            "precision_mean": 0.39123213334079,
            "precision_std": 0.0,
            "recall_mean": 0.4385877175435087,
            "recall_std": 0.0,
            "f1_score_mean": 0.34285334771242704,
            "f1_score_std": 0.0,
            "time_train_mean": 39.70907981395722,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-3B-bnb-4bit)_LoRA_best_model_12.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-3B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-3B-bnb-4bit",
        "best_experiment": {
            "id": 13,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-3B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.99)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.01\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 4,
                "lora_alpha": 16,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.0303470477386936,
                        "accuracy": 0.6491445184355786
                    },
                    {
                        "epoch": 2,
                        "loss": 0.5153649104899497,
                        "accuracy": 0.8148977547292121
                    },
                    {
                        "epoch": 3,
                        "loss": 0.45998547424623115,
                        "accuracy": 0.8286090321566779
                    },
                    {
                        "epoch": 4,
                        "loss": 0.43426114949748745,
                        "accuracy": 0.833303867837429
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4201427057160804,
                        "accuracy": 0.8358379004851985
                    },
                    {
                        "epoch": 6,
                        "loss": 0.40455451083542715,
                        "accuracy": 0.8398844952560551
                    },
                    {
                        "epoch": 7,
                        "loss": 0.39537531407035176,
                        "accuracy": 0.844343606969572
                    },
                    {
                        "epoch": 8,
                        "loss": 0.38362466630025127,
                        "accuracy": 0.8456008014614886
                    },
                    {
                        "epoch": 9,
                        "loss": 0.3752429137876884,
                        "accuracy": 0.8491955919618127
                    },
                    {
                        "epoch": 10,
                        "loss": 0.3677150400439699,
                        "accuracy": 0.8511206710275601
                    },
                    {
                        "epoch": 11,
                        "loss": 0.3483948060615578,
                        "accuracy": 0.8580548843970377
                    },
                    {
                        "epoch": 12,
                        "loss": 0.3388205676821608,
                        "accuracy": 0.8610996523071484
                    },
                    {
                        "epoch": 13,
                        "loss": 0.3308976523241206,
                        "accuracy": 0.8644390751763019
                    },
                    {
                        "epoch": 14,
                        "loss": 0.3231636699120603,
                        "accuracy": 0.8668945331683265
                    },
                    {
                        "epoch": 15,
                        "loss": 0.31312077967964824,
                        "accuracy": 0.8698803700866286
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.2834256329113924,
                        "accuracy": 0.4313,
                        "precision": 0.40598759143785285,
                        "recall": 0.4313,
                        "f1_score": 0.3305325319483146
                    },
                    {
                        "epoch": 2,
                        "loss": 2.5333267405063293,
                        "accuracy": 0.4571,
                        "precision": 0.3695307853256165,
                        "recall": 0.4571,
                        "f1_score": 0.36387131110648946
                    },
                    {
                        "epoch": 3,
                        "loss": 3.2323971518987342,
                        "accuracy": 0.4572,
                        "precision": 0.38275259793593547,
                        "recall": 0.4572,
                        "f1_score": 0.36262727871972794
                    },
                    {
                        "epoch": 4,
                        "loss": 3.3552215189873418,
                        "accuracy": 0.4545,
                        "precision": 0.3900918895701993,
                        "recall": 0.4545,
                        "f1_score": 0.3590608161211479
                    },
                    {
                        "epoch": 5,
                        "loss": 2.9428401898734178,
                        "accuracy": 0.4625,
                        "precision": 0.36933941219040867,
                        "recall": 0.4625,
                        "f1_score": 0.3681853920233077
                    },
                    {
                        "epoch": 6,
                        "loss": 3.2608781645569622,
                        "accuracy": 0.4511,
                        "precision": 0.3904569821428571,
                        "recall": 0.4511,
                        "f1_score": 0.35449753252520105
                    },
                    {
                        "epoch": 7,
                        "loss": 3.4272151898734178,
                        "accuracy": 0.4682,
                        "precision": 0.36177721591465883,
                        "recall": 0.4682,
                        "f1_score": 0.37261209358526276
                    },
                    {
                        "epoch": 8,
                        "loss": 3.2145965189873418,
                        "accuracy": 0.4595,
                        "precision": 0.374515667497308,
                        "recall": 0.4595,
                        "f1_score": 0.3640298695774361
                    },
                    {
                        "epoch": 9,
                        "loss": 3.173655063291139,
                        "accuracy": 0.4524,
                        "precision": 0.3880930909248505,
                        "recall": 0.4524,
                        "f1_score": 0.3568287771680147
                    },
                    {
                        "epoch": 10,
                        "loss": 3.3955696202531644,
                        "accuracy": 0.4773,
                        "precision": 0.3436599848539488,
                        "recall": 0.4773,
                        "f1_score": 0.381674750719265
                    },
                    {
                        "epoch": 11,
                        "loss": 3.6734572784810124,
                        "accuracy": 0.4751,
                        "precision": 0.35075916722434286,
                        "recall": 0.4751,
                        "f1_score": 0.3795601074785268
                    },
                    {
                        "epoch": 12,
                        "loss": 3.446993670886076,
                        "accuracy": 0.4775,
                        "precision": 0.34539128944999886,
                        "recall": 0.4775,
                        "f1_score": 0.3815635220167995
                    },
                    {
                        "epoch": 13,
                        "loss": 3.6821598101265822,
                        "accuracy": 0.4681,
                        "precision": 0.365566814502581,
                        "recall": 0.4681,
                        "f1_score": 0.3726759229351667
                    },
                    {
                        "epoch": 14,
                        "loss": 3.4361155063291138,
                        "accuracy": 0.4631,
                        "precision": 0.3644417366718326,
                        "recall": 0.4631,
                        "f1_score": 0.36738235127168495
                    },
                    {
                        "epoch": 15,
                        "loss": 4.077333860759493,
                        "accuracy": 0.4613,
                        "precision": 0.37442234971514726,
                        "recall": 0.4613,
                        "f1_score": 0.3648066710431227
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.46739347869573916,
                "precision": 0.33848163740608,
                "recall": 0.46739347869573916,
                "f1_score": 0.3719479568464993
            },
            "confusion_matrix": [
                [
                    2998,
                    335,
                    0
                ],
                [
                    1658,
                    1675,
                    0
                ],
                [
                    2546,
                    786,
                    0
                ]
            ],
            "best_epoch": 10,
            "time_train": 65.34551813602448
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.46739347869573916,
            "accuracy_std": 0.0,
            "precision_mean": 0.33848163740608,
            "precision_std": 0.0,
            "recall_mean": 0.46739347869573916,
            "recall_std": 0.0,
            "f1_score_mean": 0.3719479568464993,
            "f1_score_std": 0.0,
            "time_train_mean": 65.34551813602448,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-3B-bnb-4bit)_LoRA_best_model_13.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 7,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 32,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2340952810929648,
                        "accuracy": 0.6298347967862966
                    },
                    {
                        "epoch": 2,
                        "loss": 0.608609453517588,
                        "accuracy": 0.7711709588072367
                    },
                    {
                        "epoch": 3,
                        "loss": 0.4762925957914573,
                        "accuracy": 0.8224016343528395
                    },
                    {
                        "epoch": 4,
                        "loss": 0.46036334013819097,
                        "accuracy": 0.8254071149350777
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4478790436557789,
                        "accuracy": 0.8281572278861453
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4167198296168342,
                        "accuracy": 0.8384112204608404
                    },
                    {
                        "epoch": 7,
                        "loss": 0.40151931532663315,
                        "accuracy": 0.8417309996660577
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 2.974881329113924,
                        "accuracy": 0.4379,
                        "precision": 0.38804004252539004,
                        "recall": 0.4379,
                        "f1_score": 0.33947755862042334
                    },
                    {
                        "epoch": 2,
                        "loss": 2.652788765822785,
                        "accuracy": 0.4548,
                        "precision": 0.36663998396547465,
                        "recall": 0.4548,
                        "f1_score": 0.3580597946377575
                    },
                    {
                        "epoch": 3,
                        "loss": 2.878461234177215,
                        "accuracy": 0.4608,
                        "precision": 0.37551549208717433,
                        "recall": 0.4608,
                        "f1_score": 0.36490969023156633
                    },
                    {
                        "epoch": 4,
                        "loss": 2.6733583860759493,
                        "accuracy": 0.4527,
                        "precision": 0.39117466169616455,
                        "recall": 0.4527,
                        "f1_score": 0.35564543275106913
                    },
                    {
                        "epoch": 5,
                        "loss": 2.4708267405063293,
                        "accuracy": 0.467,
                        "precision": 0.35436645802650957,
                        "recall": 0.467,
                        "f1_score": 0.369730722350755
                    },
                    {
                        "epoch": 6,
                        "loss": 3.0684335443037973,
                        "accuracy": 0.4492,
                        "precision": 0.39891379974147284,
                        "recall": 0.4492,
                        "f1_score": 0.3515092916570604
                    },
                    {
                        "epoch": 7,
                        "loss": 2.904469936708861,
                        "accuracy": 0.4516,
                        "precision": 0.39320537534173394,
                        "recall": 0.4516,
                        "f1_score": 0.3542308741724329
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4596919383876775,
                "precision": 0.35042025872322186,
                "recall": 0.4596919383876775,
                "f1_score": 0.3635335673063662
            },
            "confusion_matrix": [
                [
                    3120,
                    213,
                    0
                ],
                [
                    1857,
                    1476,
                    0
                ],
                [
                    2739,
                    593,
                    0
                ]
            ],
            "best_epoch": 5,
            "time_train": 55.036313406626384
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4596919383876775,
            "accuracy_std": 0.0,
            "precision_mean": 0.35042025872322186,
            "precision_std": 0.0,
            "recall_mean": 0.4596919383876775,
            "recall_std": 0.0,
            "f1_score_mean": 0.3635335673063662,
            "f1_score_std": 0.0,
            "time_train_mean": 55.036313406626384,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_7.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 8,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.07\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 16,
                "lora_alpha": 32,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2520267352386936,
                        "accuracy": 0.6412477655332273
                    },
                    {
                        "epoch": 2,
                        "loss": 0.645571608040201,
                        "accuracy": 0.7610937592079675
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5306365813442211,
                        "accuracy": 0.8041526705561122
                    },
                    {
                        "epoch": 4,
                        "loss": 0.47511973932160806,
                        "accuracy": 0.8164103168522993
                    },
                    {
                        "epoch": 5,
                        "loss": 0.44555296011306533,
                        "accuracy": 0.8281965152140177
                    },
                    {
                        "epoch": 6,
                        "loss": 0.41877600895100503,
                        "accuracy": 0.8358575441491347
                    },
                    {
                        "epoch": 7,
                        "loss": 0.4090373743718593,
                        "accuracy": 0.838175496493606
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 4.415150316455696,
                        "accuracy": 0.4497,
                        "precision": 0.3018355845903442,
                        "recall": 0.4497,
                        "f1_score": 0.36001253541722555
                    },
                    {
                        "epoch": 2,
                        "loss": 5.909810126582278,
                        "accuracy": 0.4447,
                        "precision": 0.39211675229423315,
                        "recall": 0.4447,
                        "f1_score": 0.3471242424509776
                    },
                    {
                        "epoch": 3,
                        "loss": 5.800039556962025,
                        "accuracy": 0.441,
                        "precision": 0.40309513334375713,
                        "recall": 0.441,
                        "f1_score": 0.34242602374954406
                    },
                    {
                        "epoch": 4,
                        "loss": 4.254746835443038,
                        "accuracy": 0.4677,
                        "precision": 0.32953535286234653,
                        "recall": 0.4677,
                        "f1_score": 0.3739653279031327
                    },
                    {
                        "epoch": 5,
                        "loss": 4.844738924050633,
                        "accuracy": 0.4523,
                        "precision": 0.38953272597810806,
                        "recall": 0.4523,
                        "f1_score": 0.35635645251123704
                    },
                    {
                        "epoch": 6,
                        "loss": 4.654272151898734,
                        "accuracy": 0.4583,
                        "precision": 0.37889490872624,
                        "recall": 0.4583,
                        "f1_score": 0.3630175911754659
                    },
                    {
                        "epoch": 7,
                        "loss": 4.879746835443038,
                        "accuracy": 0.4543,
                        "precision": 0.38721360790536513,
                        "recall": 0.4543,
                        "f1_score": 0.3574217518638724
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4624924984996999,
                "precision": 0.32385910419520963,
                "recall": 0.4624924984996999,
                "f1_score": 0.36982342641294436
            },
            "confusion_matrix": [
                [
                    2785,
                    548,
                    0
                ],
                [
                    1494,
                    1839,
                    0
                ],
                [
                    2404,
                    928,
                    0
                ]
            ],
            "best_epoch": 4,
            "time_train": 53.452452369530995
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4624924984996999,
            "accuracy_std": 0.0,
            "precision_mean": 0.32385910419520963,
            "precision_std": 0.0,
            "recall_mean": 0.4624924984996999,
            "recall_std": 0.0,
            "f1_score_mean": 0.36982342641294436,
            "f1_score_std": 0.0,
            "time_train_mean": 53.452452369530995,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_8.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 9,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 32,
                "lora_alpha": 64,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3092464274497488,
                        "accuracy": 0.6270650401712927
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7118208228643216,
                        "accuracy": 0.7384642583534681
                    },
                    {
                        "epoch": 3,
                        "loss": 0.49444978800251255,
                        "accuracy": 0.8116172628518671
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4566092179648241,
                        "accuracy": 0.827135757361463
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4331177371231156,
                        "accuracy": 0.8307501915257234
                    },
                    {
                        "epoch": 6,
                        "loss": 0.40594083699748745,
                        "accuracy": 0.837487968255839
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.452136075949367,
                        "accuracy": 0.4508,
                        "precision": 0.3413774987178828,
                        "recall": 0.4508,
                        "f1_score": 0.3598344585561752
                    },
                    {
                        "epoch": 2,
                        "loss": 3.1081882911392404,
                        "accuracy": 0.452,
                        "precision": 0.35813468588642483,
                        "recall": 0.452,
                        "f1_score": 0.35795925408314117
                    },
                    {
                        "epoch": 3,
                        "loss": 2.9798259493670884,
                        "accuracy": 0.4481,
                        "precision": 0.3881902719017294,
                        "recall": 0.4481,
                        "f1_score": 0.35214363875442284
                    },
                    {
                        "epoch": 4,
                        "loss": 2.851463607594937,
                        "accuracy": 0.4442,
                        "precision": 0.3983227264039924,
                        "recall": 0.4442,
                        "f1_score": 0.34718562325045466
                    },
                    {
                        "epoch": 5,
                        "loss": 3.4305775316455698,
                        "accuracy": 0.4419,
                        "precision": 0.41094945961137747,
                        "recall": 0.4419,
                        "f1_score": 0.3439927768101097
                    },
                    {
                        "epoch": 6,
                        "loss": 3.5741693037974684,
                        "accuracy": 0.4422,
                        "precision": 0.4117581463760238,
                        "recall": 0.4422,
                        "f1_score": 0.3446954966039455
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.44588917783556714,
                "precision": 0.33597410922800397,
                "recall": 0.44588917783556714,
                "f1_score": 0.3560779521509324
            },
            "confusion_matrix": [
                [
                    2911,
                    422,
                    0
                ],
                [
                    1786,
                    1547,
                    0
                ],
                [
                    2805,
                    527,
                    0
                ]
            ],
            "best_epoch": 1,
            "time_train": 45.76943492094676
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.44588917783556714,
            "accuracy_std": 0.0,
            "precision_mean": 0.33597410922800397,
            "precision_std": 0.0,
            "recall_mean": 0.44588917783556714,
            "recall_std": 0.0,
            "f1_score_mean": 0.3560779521509324,
            "f1_score_std": 0.0,
            "time_train_mean": 45.76943492094676,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_9.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 10,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.001\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 32,
                "lora_alpha": 64,
                "lora_dropout": 0.3
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3231195037688441,
                        "accuracy": 0.6259060639990571
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6563972204773869,
                        "accuracy": 0.7570275207731746
                    },
                    {
                        "epoch": 3,
                        "loss": 0.4827359453517588,
                        "accuracy": 0.8170585577621938
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4606087076005025,
                        "accuracy": 0.823049875262734
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4493586094535176,
                        "accuracy": 0.8259964248531636
                    },
                    {
                        "epoch": 6,
                        "loss": 0.40627208307160806,
                        "accuracy": 0.8384505077887128
                    },
                    {
                        "epoch": 7,
                        "loss": 0.3942196333228643,
                        "accuracy": 0.8436757223957413
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.5897943037974684,
                        "accuracy": 0.4481,
                        "precision": 0.362699269005848,
                        "recall": 0.4481,
                        "f1_score": 0.35300120351223635
                    },
                    {
                        "epoch": 2,
                        "loss": 3.719738924050633,
                        "accuracy": 0.4403,
                        "precision": 0.40504145347704645,
                        "recall": 0.4403,
                        "f1_score": 0.3419220320820607
                    },
                    {
                        "epoch": 3,
                        "loss": 2.8265427215189876,
                        "accuracy": 0.4449,
                        "precision": 0.39588843741660584,
                        "recall": 0.4449,
                        "f1_score": 0.3473424292990578
                    },
                    {
                        "epoch": 4,
                        "loss": 2.6289556962025316,
                        "accuracy": 0.444,
                        "precision": 0.4050417196938427,
                        "recall": 0.444,
                        "f1_score": 0.34646437306468486
                    },
                    {
                        "epoch": 5,
                        "loss": 3.2859968354430378,
                        "accuracy": 0.4477,
                        "precision": 0.39893672716698725,
                        "recall": 0.4477,
                        "f1_score": 0.3511006118703163
                    },
                    {
                        "epoch": 6,
                        "loss": 2.8807357594936707,
                        "accuracy": 0.4532,
                        "precision": 0.3874412693290305,
                        "recall": 0.4532,
                        "f1_score": 0.35753995682050255
                    },
                    {
                        "epoch": 7,
                        "loss": 3.2268591772151898,
                        "accuracy": 0.442,
                        "precision": 0.3991984872880674,
                        "recall": 0.442,
                        "f1_score": 0.3431440687581965
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.44718943788757753,
                "precision": 0.3792495037406147,
                "recall": 0.44718943788757753,
                "f1_score": 0.35140267079282556
            },
            "confusion_matrix": [
                [
                    3211,
                    122,
                    0
                ],
                [
                    2073,
                    1260,
                    0
                ],
                [
                    3038,
                    294,
                    0
                ]
            ],
            "best_epoch": 6,
            "time_train": 54.29196624358495
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.44718943788757753,
            "accuracy_std": 0.0,
            "precision_mean": 0.3792495037406147,
            "precision_std": 0.0,
            "recall_mean": 0.44718943788757753,
            "recall_std": 0.0,
            "f1_score_mean": 0.35140267079282556,
            "f1_score_std": 0.0,
            "time_train_mean": 54.29196624358495,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_10.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 100,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0001, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0001,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 4,
                "lora_alpha": 16,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3026362280150754,
                        "accuracy": 0.6221934115151158
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6385590059673367,
                        "accuracy": 0.7633134932327578
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5122315679962312,
                        "accuracy": 0.8099671950812265
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4778384108040201,
                        "accuracy": 0.8166263971555975
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4608295383165829,
                        "accuracy": 0.8226766456479463
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4360817760678392,
                        "accuracy": 0.8293554913862534
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 4.656052215189874,
                        "accuracy": 0.4414,
                        "precision": 0.35868186471325025,
                        "recall": 0.4414,
                        "f1_score": 0.3478320123681737
                    },
                    {
                        "epoch": 2,
                        "loss": 5.1077927215189876,
                        "accuracy": 0.4344,
                        "precision": 0.4076460990965576,
                        "recall": 0.4344,
                        "f1_score": 0.3349918303563297
                    },
                    {
                        "epoch": 3,
                        "loss": 4.748615506329114,
                        "accuracy": 0.4325,
                        "precision": 0.4117201980048644,
                        "recall": 0.4325,
                        "f1_score": 0.332276263855499
                    },
                    {
                        "epoch": 4,
                        "loss": 4.302215189873418,
                        "accuracy": 0.4566,
                        "precision": 0.36590296732627703,
                        "recall": 0.4566,
                        "f1_score": 0.36339408743578744
                    },
                    {
                        "epoch": 5,
                        "loss": 4.0352056962025316,
                        "accuracy": 0.459,
                        "precision": 0.3605069080972501,
                        "recall": 0.459,
                        "f1_score": 0.36595873147093105
                    },
                    {
                        "epoch": 6,
                        "loss": 3.8761867088607596,
                        "accuracy": 0.4625,
                        "precision": 0.3609834014985694,
                        "recall": 0.4625,
                        "f1_score": 0.3699642791712124
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4546909381876375,
                "precision": 0.35391364960927224,
                "recall": 0.4546909381876375,
                "f1_score": 0.36244518157643774
            },
            "confusion_matrix": [
                [
                    3048,
                    285,
                    0
                ],
                [
                    1835,
                    1498,
                    0
                ],
                [
                    2875,
                    457,
                    0
                ]
            ],
            "best_epoch": 6,
            "time_train": 47.44738093217214
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4546909381876375,
            "accuracy_std": 0.0,
            "precision_mean": 0.35391364960927224,
            "precision_std": 0.0,
            "recall_mean": 0.4546909381876375,
            "recall_std": 0.0,
            "f1_score_mean": 0.36244518157643774,
            "f1_score_std": 0.0,
            "time_train_mean": 47.44738093217214,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_100.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 101,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0001, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0001,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 32,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3129514761306533,
                        "accuracy": 0.6100339835386096
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7435811871859297,
                        "accuracy": 0.7216296383601469
                    },
                    {
                        "epoch": 3,
                        "loss": 0.550015703517588,
                        "accuracy": 0.7953719527766319
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4851847126256281,
                        "accuracy": 0.8165478224998527
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4627826633165829,
                        "accuracy": 0.8210658652051781
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4332453282035176,
                        "accuracy": 0.8335788791325358
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.7753164556962027,
                        "accuracy": 0.3808,
                        "precision": 0.4073237456368999,
                        "recall": 0.3808,
                        "f1_score": 0.25715035539727027
                    },
                    {
                        "epoch": 2,
                        "loss": 3.9046677215189876,
                        "accuracy": 0.4441,
                        "precision": 0.39432144997266266,
                        "recall": 0.4441,
                        "f1_score": 0.3470000730847474
                    },
                    {
                        "epoch": 3,
                        "loss": 4.740704113924051,
                        "accuracy": 0.4502,
                        "precision": 0.3903576308763659,
                        "recall": 0.4502,
                        "f1_score": 0.35350254731786496
                    },
                    {
                        "epoch": 4,
                        "loss": 3.5498417721518987,
                        "accuracy": 0.4577,
                        "precision": 0.3778430650870988,
                        "recall": 0.4577,
                        "f1_score": 0.36337771661441004
                    },
                    {
                        "epoch": 5,
                        "loss": 3.2581091772151898,
                        "accuracy": 0.4622,
                        "precision": 0.36904168991466624,
                        "recall": 0.4622,
                        "f1_score": 0.3676296551495193
                    },
                    {
                        "epoch": 6,
                        "loss": 3.6077927215189876,
                        "accuracy": 0.4436,
                        "precision": 0.41040786529247525,
                        "recall": 0.4436,
                        "f1_score": 0.3458198248286249
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.44968993798759754,
                "precision": 0.36255981733724896,
                "recall": 0.44968993798759754,
                "f1_score": 0.35566004970143766
            },
            "confusion_matrix": [
                [
                    3130,
                    203,
                    0
                ],
                [
                    1967,
                    1366,
                    0
                ],
                [
                    2945,
                    387,
                    0
                ]
            ],
            "best_epoch": 5,
            "time_train": 48.438758714993796
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.44968993798759754,
            "accuracy_std": 0.0,
            "precision_mean": 0.36255981733724896,
            "precision_std": 0.0,
            "recall_mean": 0.44968993798759754,
            "recall_std": 0.0,
            "f1_score_mean": 0.35566004970143766,
            "f1_score_std": 0.0,
            "time_train_mean": 48.438758714993796,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_101.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 102,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 16,
                "lora_alpha": 32,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3893539965452262,
                        "accuracy": 0.6206415620641562
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6540024340452262,
                        "accuracy": 0.756673934822323
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5244140625,
                        "accuracy": 0.8021293731706838
                    },
                    {
                        "epoch": 4,
                        "loss": 0.48027736337939697,
                        "accuracy": 0.8171567760818748
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4543960034547739,
                        "accuracy": 0.825642838902312
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4240440483668342,
                        "accuracy": 0.8331074311980671
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 4.4044699367088604,
                        "accuracy": 0.4383,
                        "precision": 0.3871342720710841,
                        "recall": 0.4383,
                        "f1_score": 0.33984273920062885
                    },
                    {
                        "epoch": 2,
                        "loss": 6.322784810126582,
                        "accuracy": 0.4267,
                        "precision": 0.41154401089153636,
                        "recall": 0.4267,
                        "f1_score": 0.32448722513722533
                    },
                    {
                        "epoch": 3,
                        "loss": 6.231012658227848,
                        "accuracy": 0.4374,
                        "precision": 0.4044710371033011,
                        "recall": 0.4374,
                        "f1_score": 0.33868124533993604
                    },
                    {
                        "epoch": 4,
                        "loss": 5.216376582278481,
                        "accuracy": 0.4487,
                        "precision": 0.3934965496989925,
                        "recall": 0.4487,
                        "f1_score": 0.35152628366319044
                    },
                    {
                        "epoch": 5,
                        "loss": 5.090585443037975,
                        "accuracy": 0.4493,
                        "precision": 0.3974356113049792,
                        "recall": 0.4493,
                        "f1_score": 0.3523599761798357
                    },
                    {
                        "epoch": 6,
                        "loss": 5.085838607594937,
                        "accuracy": 0.4558,
                        "precision": 0.3843194285714286,
                        "recall": 0.4558,
                        "f1_score": 0.3604855371208312
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4468893778755751,
                "precision": 0.3703671805785866,
                "recall": 0.4468893778755751,
                "f1_score": 0.3520448264278128
            },
            "confusion_matrix": [
                [
                    3170,
                    163,
                    0
                ],
                [
                    2035,
                    1298,
                    0
                ],
                [
                    3002,
                    330,
                    0
                ]
            ],
            "best_epoch": 6,
            "time_train": 46.723782642682394
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4468893778755751,
            "accuracy_std": 0.0,
            "precision_mean": 0.3703671805785866,
            "precision_std": 0.0,
            "recall_mean": 0.4468893778755751,
            "recall_std": 0.0,
            "f1_score_mean": 0.3520448264278128,
            "f1_score_std": 0.0,
            "time_train_mean": 46.723782642682394,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_102.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 103,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 32,
                "lora_alpha": 64,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.214333385678392,
                        "accuracy": 0.6210344353428802
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6545177057160804,
                        "accuracy": 0.7552792346828531
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5002846262562815,
                        "accuracy": 0.8107332979747383
                    },
                    {
                        "epoch": 4,
                        "loss": 0.46281701476130654,
                        "accuracy": 0.8270375390417821
                    },
                    {
                        "epoch": 5,
                        "loss": 0.43209455480527637,
                        "accuracy": 0.8327145579193431
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4029498076319096,
                        "accuracy": 0.8396094839609484
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.5541930379746836,
                        "accuracy": 0.439,
                        "precision": 0.3847216589465102,
                        "recall": 0.439,
                        "f1_score": 0.3416226443781767
                    },
                    {
                        "epoch": 2,
                        "loss": 3.709849683544304,
                        "accuracy": 0.4165,
                        "precision": 0.4153266268953892,
                        "recall": 0.4165,
                        "f1_score": 0.31063744918774844
                    },
                    {
                        "epoch": 3,
                        "loss": 3.5253164556962027,
                        "accuracy": 0.4541,
                        "precision": 0.36659153517479204,
                        "recall": 0.4541,
                        "f1_score": 0.35930575846490537
                    },
                    {
                        "epoch": 4,
                        "loss": 3.293117088607595,
                        "accuracy": 0.441,
                        "precision": 0.40532782484099145,
                        "recall": 0.441,
                        "f1_score": 0.34237929714935356
                    },
                    {
                        "epoch": 5,
                        "loss": 3.4329509493670884,
                        "accuracy": 0.4461,
                        "precision": 0.39822496877294233,
                        "recall": 0.4461,
                        "f1_score": 0.34933538364655947
                    },
                    {
                        "epoch": 6,
                        "loss": 3.6006724683544302,
                        "accuracy": 0.439,
                        "precision": 0.4074901820969906,
                        "recall": 0.439,
                        "f1_score": 0.34060898223248814
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4473894778955791,
                "precision": 0.3609494142918654,
                "recall": 0.4473894778955791,
                "f1_score": 0.3534078558283679
            },
            "confusion_matrix": [
                [
                    3124,
                    209,
                    0
                ],
                [
                    1984,
                    1349,
                    0
                ],
                [
                    2949,
                    383,
                    0
                ]
            ],
            "best_epoch": 3,
            "time_train": 46.389659543832146
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4473894778955791,
            "accuracy_std": 0.0,
            "precision_mean": 0.3609494142918654,
            "precision_std": 0.0,
            "recall_mean": 0.4473894778955791,
            "recall_std": 0.0,
            "f1_score_mean": 0.3534078558283679,
            "f1_score_std": 0.0,
            "time_train_mean": 46.389659543832146,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_103.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 104,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0001, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0.07\n)",
                "learning_rate": 0.0001,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 16,
                "lora_alpha": 16,
                "lora_dropout": 0
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.7551281799623115,
                        "accuracy": 0.5698430471251498
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7743453596105527,
                        "accuracy": 0.7070540397194884
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6416849874371859,
                        "accuracy": 0.766220755495315
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5310929648241206,
                        "accuracy": 0.8002239377688727
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4972911432160804,
                        "accuracy": 0.8152513406800637
                    },
                    {
                        "epoch": 6,
                        "loss": 0.46171776853015073,
                        "accuracy": 0.8258196318777379
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.4171281645569622,
                        "accuracy": 0.4178,
                        "precision": 0.36948778213852584,
                        "recall": 0.4178,
                        "f1_score": 0.3170969622321325
                    },
                    {
                        "epoch": 2,
                        "loss": 5.1020569620253164,
                        "accuracy": 0.4344,
                        "precision": 0.3868875428954605,
                        "recall": 0.4344,
                        "f1_score": 0.33600354145663897
                    },
                    {
                        "epoch": 3,
                        "loss": 6.331487341772152,
                        "accuracy": 0.4303,
                        "precision": 0.40270867443805025,
                        "recall": 0.4303,
                        "f1_score": 0.32945519447943944
                    },
                    {
                        "epoch": 4,
                        "loss": 6.452729430379747,
                        "accuracy": 0.4508,
                        "precision": 0.3681546338461539,
                        "recall": 0.4508,
                        "f1_score": 0.3558207545409281
                    },
                    {
                        "epoch": 5,
                        "loss": 6.504351265822785,
                        "accuracy": 0.4596,
                        "precision": 0.3478898418173593,
                        "recall": 0.4596,
                        "f1_score": 0.36650235789852087
                    },
                    {
                        "epoch": 6,
                        "loss": 7.167325949367089,
                        "accuracy": 0.4504,
                        "precision": 0.3841907972999995,
                        "recall": 0.4504,
                        "f1_score": 0.354449529129444
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4505901180236047,
                "precision": 0.33987372310164465,
                "recall": 0.4505901180236047,
                "f1_score": 0.3587852309115051
            },
            "confusion_matrix": [
                [
                    2974,
                    359,
                    0
                ],
                [
                    1802,
                    1531,
                    0
                ],
                [
                    2775,
                    557,
                    0
                ]
            ],
            "best_epoch": 5,
            "time_train": 35.338960480690005
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4505901180236047,
            "accuracy_std": 0.0,
            "precision_mean": 0.33987372310164465,
            "precision_std": 0.0,
            "recall_mean": 0.4505901180236047,
            "recall_std": 0.0,
            "f1_score_mean": 0.3587852309115051,
            "f1_score_std": 0.0,
            "time_train_mean": 35.338960480690005,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_104.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 105,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=5e-05, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 5e-05\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 5e-05,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 32,
                "lora_alpha": 64,
                "lora_dropout": 0.3
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3321980998743719,
                        "accuracy": 0.5965780737423144
                    },
                    {
                        "epoch": 2,
                        "loss": 0.8128631438442211,
                        "accuracy": 0.6929302453493625
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6644305511934674,
                        "accuracy": 0.7456538393541163
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5339146906407035,
                        "accuracy": 0.8002632250967451
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4788149733040201,
                        "accuracy": 0.8200247510165596
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4396199748743719,
                        "accuracy": 0.8314770070913626
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 2.739418512658228,
                        "accuracy": 0.419,
                        "precision": 0.3545657236652987,
                        "recall": 0.419,
                        "f1_score": 0.3176369909336794
                    },
                    {
                        "epoch": 2,
                        "loss": 4.302610759493671,
                        "accuracy": 0.4123,
                        "precision": 0.40048980278216506,
                        "recall": 0.4123,
                        "f1_score": 0.30520098077476215
                    },
                    {
                        "epoch": 3,
                        "loss": 4.772151898734177,
                        "accuracy": 0.4332,
                        "precision": 0.40068989346131567,
                        "recall": 0.4332,
                        "f1_score": 0.33284823285225096
                    },
                    {
                        "epoch": 4,
                        "loss": 4.6054193037974684,
                        "accuracy": 0.4402,
                        "precision": 0.39476450514881734,
                        "recall": 0.4402,
                        "f1_score": 0.34130468607768566
                    },
                    {
                        "epoch": 5,
                        "loss": 4.7796677215189876,
                        "accuracy": 0.4367,
                        "precision": 0.40675668015720895,
                        "recall": 0.4367,
                        "f1_score": 0.3374312936829851
                    },
                    {
                        "epoch": 6,
                        "loss": 4.78935917721519,
                        "accuracy": 0.4398,
                        "precision": 0.4032869724973538,
                        "recall": 0.4398,
                        "f1_score": 0.3414251771613253
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4330866173234647,
                "precision": 0.39277773906088903,
                "recall": 0.4330866173234647,
                "f1_score": 0.3338966561725254
            },
            "confusion_matrix": [
                [
                    3262,
                    71,
                    0
                ],
                [
                    2265,
                    1068,
                    0
                ],
                [
                    3139,
                    193,
                    0
                ]
            ],
            "best_epoch": 6,
            "time_train": 47.98487828969955
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4330866173234647,
            "accuracy_std": 0.0,
            "precision_mean": 0.39277773906088903,
            "precision_std": 0.0,
            "recall_mean": 0.4330866173234647,
            "recall_std": 0.0,
            "f1_score_mean": 0.3338966561725254,
            "f1_score_std": 0.0,
            "time_train_mean": 47.98487828969955,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_105.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 106,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 0.001\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 16,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.399605449120603,
                        "accuracy": 0.6060266760956253
                    },
                    {
                        "epoch": 2,
                        "loss": 0.713803391959799,
                        "accuracy": 0.7275620248688786
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5273388426507538,
                        "accuracy": 0.809318954171332
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4806159704773869,
                        "accuracy": 0.8195336594181547
                    },
                    {
                        "epoch": 5,
                        "loss": 0.46252257380653267,
                        "accuracy": 0.8237570471644371
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4271994739321608,
                        "accuracy": 0.8349342919441334
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.6149129746835444,
                        "accuracy": 0.4312,
                        "precision": 0.38793651854642275,
                        "recall": 0.4312,
                        "f1_score": 0.33194569028465737
                    },
                    {
                        "epoch": 2,
                        "loss": 4.481210443037975,
                        "accuracy": 0.4443,
                        "precision": 0.39759849055438945,
                        "recall": 0.4443,
                        "f1_score": 0.34746877466257153
                    },
                    {
                        "epoch": 3,
                        "loss": 4.7147943037974684,
                        "accuracy": 0.4409,
                        "precision": 0.4050047528670001,
                        "recall": 0.4409,
                        "f1_score": 0.3426949237566806
                    },
                    {
                        "epoch": 4,
                        "loss": 4.014636075949367,
                        "accuracy": 0.4479,
                        "precision": 0.3976852914847311,
                        "recall": 0.4479,
                        "f1_score": 0.351603935469999
                    },
                    {
                        "epoch": 5,
                        "loss": 3.8902294303797467,
                        "accuracy": 0.4567,
                        "precision": 0.38193116874019195,
                        "recall": 0.4567,
                        "f1_score": 0.3622461204803369
                    },
                    {
                        "epoch": 6,
                        "loss": 4.312895569620253,
                        "accuracy": 0.441,
                        "precision": 0.4094454563064277,
                        "recall": 0.441,
                        "f1_score": 0.34264214002245263
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4460892178435687,
                "precision": 0.3733143928929649,
                "recall": 0.4460892178435687,
                "f1_score": 0.35152729711938396
            },
            "confusion_matrix": [
                [
                    3172,
                    161,
                    0
                ],
                [
                    2045,
                    1288,
                    0
                ],
                [
                    3029,
                    303,
                    0
                ]
            ],
            "best_epoch": 5,
            "time_train": 47.302474979559584
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4460892178435687,
            "accuracy_std": 0.0,
            "precision_mean": 0.3733143928929649,
            "precision_std": 0.0,
            "recall_mean": 0.4460892178435687,
            "recall_std": 0.0,
            "f1_score_mean": 0.35152729711938396,
            "f1_score_std": 0.0,
            "time_train_mean": 47.302474979559584,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_106.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 107,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 16,
                "lora_alpha": 32,
                "lora_dropout": 0.3
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2716266881281406,
                        "accuracy": 0.621721963580647
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6516714431532663,
                        "accuracy": 0.7520773174612528
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5223137170226131,
                        "accuracy": 0.8039169465888778
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4705362751256281,
                        "accuracy": 0.8208104975740075
                    },
                    {
                        "epoch": 5,
                        "loss": 0.45699689855527637,
                        "accuracy": 0.8256624825662483
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4305561008165829,
                        "accuracy": 0.8329306382226412
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.8392009493670884,
                        "accuracy": 0.4533,
                        "precision": 0.31474245300725895,
                        "recall": 0.4533,
                        "f1_score": 0.36276169682190057
                    },
                    {
                        "epoch": 2,
                        "loss": 5.5508306962025316,
                        "accuracy": 0.4353,
                        "precision": 0.40234552919906535,
                        "recall": 0.4353,
                        "f1_score": 0.3355461217256647
                    },
                    {
                        "epoch": 3,
                        "loss": 5.506329113924051,
                        "accuracy": 0.4344,
                        "precision": 0.4079699265237622,
                        "recall": 0.4344,
                        "f1_score": 0.3345962583142301
                    },
                    {
                        "epoch": 4,
                        "loss": 4.9794303797468356,
                        "accuracy": 0.4446,
                        "precision": 0.4025178837209302,
                        "recall": 0.4446,
                        "f1_score": 0.3465127428197109
                    },
                    {
                        "epoch": 5,
                        "loss": 4.8219936708860756,
                        "accuracy": 0.4505,
                        "precision": 0.39382797186814866,
                        "recall": 0.4505,
                        "f1_score": 0.35367809604277717
                    },
                    {
                        "epoch": 6,
                        "loss": 4.535799050632911,
                        "accuracy": 0.4572,
                        "precision": 0.38694283125991485,
                        "recall": 0.4572,
                        "f1_score": 0.3618448559697442
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4450890178035607,
                "precision": 0.3101334290923296,
                "recall": 0.4450890178035607,
                "f1_score": 0.3568050439070521
            },
            "confusion_matrix": [
                [
                    2611,
                    722,
                    0
                ],
                [
                    1494,
                    1839,
                    0
                ],
                [
                    2427,
                    905,
                    0
                ]
            ],
            "best_epoch": 1,
            "time_train": 45.21972080866496
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4450890178035607,
            "accuracy_std": 0.0,
            "precision_mean": 0.3101334290923296,
            "precision_std": 0.0,
            "recall_mean": 0.4450890178035607,
            "recall_std": 0.0,
            "f1_score_mean": 0.3568050439070521,
            "f1_score_std": 0.0,
            "time_train_mean": 45.21972080866496,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_107.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 108,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0001, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0001,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 32,
                "lora_alpha": 128,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3561852229899498,
                        "accuracy": 0.6179110927770247
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6654954459798995,
                        "accuracy": 0.7535702359204038
                    },
                    {
                        "epoch": 3,
                        "loss": 0.4904012248743719,
                        "accuracy": 0.8139155715324022
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4471085898241206,
                        "accuracy": 0.8272536193450802
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4323497369660804,
                        "accuracy": 0.831810949378278
                    },
                    {
                        "epoch": 6,
                        "loss": 0.39230331344221103,
                        "accuracy": 0.84275247019074
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.5882120253164556,
                        "accuracy": 0.4424,
                        "precision": 0.38554021353393697,
                        "recall": 0.4424,
                        "f1_score": 0.3459528304639131
                    },
                    {
                        "epoch": 2,
                        "loss": 2.991198575949367,
                        "accuracy": 0.4427,
                        "precision": 0.39171124449763756,
                        "recall": 0.4427,
                        "f1_score": 0.34573561703604017
                    },
                    {
                        "epoch": 3,
                        "loss": 2.9274129746835444,
                        "accuracy": 0.4501,
                        "precision": 0.36419359649122807,
                        "recall": 0.4501,
                        "f1_score": 0.35451269666398116
                    },
                    {
                        "epoch": 4,
                        "loss": 2.9343354430379747,
                        "accuracy": 0.4568,
                        "precision": 0.3685254878388306,
                        "recall": 0.4568,
                        "f1_score": 0.3615795318693798
                    },
                    {
                        "epoch": 5,
                        "loss": 3.0882120253164556,
                        "accuracy": 0.4422,
                        "precision": 0.4070197674095171,
                        "recall": 0.4422,
                        "f1_score": 0.34422959988373814
                    },
                    {
                        "epoch": 6,
                        "loss": 3.298655063291139,
                        "accuracy": 0.445,
                        "precision": 0.39840381297620353,
                        "recall": 0.445,
                        "f1_score": 0.34798257860626647
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.45119023804760955,
                "precision": 0.3643186251294577,
                "recall": 0.45119023804760955,
                "f1_score": 0.35576790015913645
            },
            "confusion_matrix": [
                [
                    3165,
                    168,
                    0
                ],
                [
                    1987,
                    1346,
                    0
                ],
                [
                    2926,
                    406,
                    0
                ]
            ],
            "best_epoch": 4,
            "time_train": 47.10823839505513
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.45119023804760955,
            "accuracy_std": 0.0,
            "precision_mean": 0.3643186251294577,
            "precision_std": 0.0,
            "recall_mean": 0.45119023804760955,
            "recall_std": 0.0,
            "f1_score_mean": 0.35576790015913645,
            "f1_score_std": 0.0,
            "time_train_mean": 47.10823839505513,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_108.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 109,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=5e-05, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 5e-05\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 5e-05,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2610071843592965,
                        "accuracy": 0.6124108668748895
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7424083307160804,
                        "accuracy": 0.727110220598346
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5471988850502513,
                        "accuracy": 0.7949005048421631
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4867550643844221,
                        "accuracy": 0.8158602942620857
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4460387876884422,
                        "accuracy": 0.8286876068124227
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4099206972361809,
                        "accuracy": 0.8402773685347791
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.356606012658228,
                        "accuracy": 0.4016,
                        "precision": 0.40417885430489675,
                        "recall": 0.4016,
                        "f1_score": 0.2896283225112689
                    },
                    {
                        "epoch": 2,
                        "loss": 3.8295094936708862,
                        "accuracy": 0.4419,
                        "precision": 0.3875586995403761,
                        "recall": 0.4419,
                        "f1_score": 0.3433197856662132
                    },
                    {
                        "epoch": 3,
                        "loss": 4.332278481012659,
                        "accuracy": 0.4481,
                        "precision": 0.374865943328062,
                        "recall": 0.4481,
                        "f1_score": 0.3505439410429563
                    },
                    {
                        "epoch": 4,
                        "loss": 4.501186708860759,
                        "accuracy": 0.444,
                        "precision": 0.39306041522265156,
                        "recall": 0.444,
                        "f1_score": 0.3456955585157755
                    },
                    {
                        "epoch": 5,
                        "loss": 4.17939082278481,
                        "accuracy": 0.4578,
                        "precision": 0.3733341206921352,
                        "recall": 0.4578,
                        "f1_score": 0.3619549725231181
                    },
                    {
                        "epoch": 6,
                        "loss": 4.160403481012659,
                        "accuracy": 0.4556,
                        "precision": 0.3804789938271253,
                        "recall": 0.4556,
                        "f1_score": 0.3593665055964516
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.44898979795959193,
                "precision": 0.3643072152057175,
                "recall": 0.44898979795959193,
                "f1_score": 0.3531588467344675
            },
            "confusion_matrix": [
                [
                    3173,
                    160,
                    0
                ],
                [
                    2017,
                    1316,
                    0
                ],
                [
                    2934,
                    398,
                    0
                ]
            ],
            "best_epoch": 5,
            "time_train": 34.99803174336751
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.44898979795959193,
            "accuracy_std": 0.0,
            "precision_mean": 0.3643072152057175,
            "precision_std": 0.0,
            "recall_mean": 0.44898979795959193,
            "recall_std": 0.0,
            "f1_score_mean": 0.3531588467344675,
            "f1_score_std": 0.0,
            "time_train_mean": 34.99803174336751,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_109.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 110,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 0.001\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 4,
                "lora_alpha": 16,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3107824277638191,
                        "accuracy": 0.6257882020154399
                    },
                    {
                        "epoch": 2,
                        "loss": 0.5923464981155779,
                        "accuracy": 0.7797159526194826
                    },
                    {
                        "epoch": 3,
                        "loss": 0.49215314855527637,
                        "accuracy": 0.8146030997701691
                    },
                    {
                        "epoch": 4,
                        "loss": 0.47085525282663315,
                        "accuracy": 0.8191800734673031
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4525680158605528,
                        "accuracy": 0.8248767360088004
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4250991284547739,
                        "accuracy": 0.8336574537882806
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 4.764438291139241,
                        "accuracy": 0.4435,
                        "precision": 0.36623642319782906,
                        "recall": 0.4435,
                        "f1_score": 0.349900148161473
                    },
                    {
                        "epoch": 2,
                        "loss": 4.938488924050633,
                        "accuracy": 0.4257,
                        "precision": 0.4149420433063888,
                        "recall": 0.4257,
                        "f1_score": 0.3232086321096911
                    },
                    {
                        "epoch": 3,
                        "loss": 4.104825949367089,
                        "accuracy": 0.447,
                        "precision": 0.3959886126157423,
                        "recall": 0.447,
                        "f1_score": 0.35081940758744384
                    },
                    {
                        "epoch": 4,
                        "loss": 4.1724683544303796,
                        "accuracy": 0.4451,
                        "precision": 0.40464867201791305,
                        "recall": 0.4451,
                        "f1_score": 0.34814633556457875
                    },
                    {
                        "epoch": 5,
                        "loss": 3.730617088607595,
                        "accuracy": 0.4594,
                        "precision": 0.3708416315942402,
                        "recall": 0.4594,
                        "f1_score": 0.3653741024777304
                    },
                    {
                        "epoch": 6,
                        "loss": 3.3146756329113924,
                        "accuracy": 0.462,
                        "precision": 0.3733965326101253,
                        "recall": 0.462,
                        "f1_score": 0.36831953079139756
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.45179035807161433,
                "precision": 0.3620054773742631,
                "recall": 0.45179035807161433,
                "f1_score": 0.35809063228012566
            },
            "confusion_matrix": [
                [
                    3120,
                    213,
                    0
                ],
                [
                    1936,
                    1397,
                    0
                ],
                [
                    2933,
                    399,
                    0
                ]
            ],
            "best_epoch": 6,
            "time_train": 47.094736929734545
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.45179035807161433,
            "accuracy_std": 0.0,
            "precision_mean": 0.3620054773742631,
            "precision_std": 0.0,
            "recall_mean": 0.45179035807161433,
            "recall_std": 0.0,
            "f1_score_mean": 0.35809063228012566,
            "f1_score_std": 0.0,
            "time_train_mean": 47.094736929734545,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_110.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 111,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 16,
                "lora_alpha": 64,
                "lora_dropout": 0.3
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.365680943781407,
                        "accuracy": 0.6195415168837292
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6590717258165829,
                        "accuracy": 0.7658868132083997
                    },
                    {
                        "epoch": 3,
                        "loss": 0.4819998429648241,
                        "accuracy": 0.8173925000491091
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4545726680276382,
                        "accuracy": 0.8242284950989058
                    },
                    {
                        "epoch": 5,
                        "loss": 0.453125,
                        "accuracy": 0.8255839079105035
                    },
                    {
                        "epoch": 6,
                        "loss": 0.420643255339196,
                        "accuracy": 0.8348753609523248
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.4420490506329116,
                        "accuracy": 0.425,
                        "precision": 0.4115015931960158,
                        "recall": 0.425,
                        "f1_score": 0.32190779766635624
                    },
                    {
                        "epoch": 2,
                        "loss": 3.0007911392405062,
                        "accuracy": 0.4542,
                        "precision": 0.3841729866198933,
                        "recall": 0.4542,
                        "f1_score": 0.3579405458839486
                    },
                    {
                        "epoch": 3,
                        "loss": 3.1236155063291138,
                        "accuracy": 0.4404,
                        "precision": 0.41018355015492636,
                        "recall": 0.4404,
                        "f1_score": 0.34219888156493633
                    },
                    {
                        "epoch": 4,
                        "loss": 2.9232594936708862,
                        "accuracy": 0.4687,
                        "precision": 0.3482157768153481,
                        "recall": 0.4687,
                        "f1_score": 0.374242197474612
                    },
                    {
                        "epoch": 5,
                        "loss": 3.0700158227848102,
                        "accuracy": 0.4578,
                        "precision": 0.38248165665197614,
                        "recall": 0.4578,
                        "f1_score": 0.36284722117006984
                    },
                    {
                        "epoch": 6,
                        "loss": 3.7015427215189876,
                        "accuracy": 0.4444,
                        "precision": 0.4081230510512408,
                        "recall": 0.4444,
                        "f1_score": 0.3465972250686341
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.46209241848369675,
                "precision": 0.3394506938445535,
                "recall": 0.46209241848369675,
                "f1_score": 0.36838384125362494
            },
            "confusion_matrix": [
                [
                    2978,
                    355,
                    0
                ],
                [
                    1691,
                    1642,
                    0
                ],
                [
                    2641,
                    691,
                    0
                ]
            ],
            "best_epoch": 4,
            "time_train": 46.59495871067047
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.46209241848369675,
            "accuracy_std": 0.0,
            "precision_mean": 0.3394506938445535,
            "precision_std": 0.0,
            "recall_mean": 0.46209241848369675,
            "recall_std": 0.0,
            "f1_score_mean": 0.36838384125362494,
            "f1_score_std": 0.0,
            "time_train_mean": 46.59495871067047,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_111.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 112,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0001, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0.001\n)",
                "learning_rate": 0.0001,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 32,
                "lora_alpha": 128,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3470232019472361,
                        "accuracy": 0.6239220539415011
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6211330087939698,
                        "accuracy": 0.7656314455772291
                    },
                    {
                        "epoch": 3,
                        "loss": 0.47891802763819097,
                        "accuracy": 0.818669338204962
                    },
                    {
                        "epoch": 4,
                        "loss": 0.44999411118090454,
                        "accuracy": 0.8261142868367808
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4195489164572864,
                        "accuracy": 0.8351307285834954
                    },
                    {
                        "epoch": 6,
                        "loss": 0.38317073649497485,
                        "accuracy": 0.8470740762567034
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.4984177215189876,
                        "accuracy": 0.4443,
                        "precision": 0.38433976761895,
                        "recall": 0.4443,
                        "f1_score": 0.3489476393765277
                    },
                    {
                        "epoch": 2,
                        "loss": 4.078322784810126,
                        "accuracy": 0.4327,
                        "precision": 0.40338940914300236,
                        "recall": 0.4327,
                        "f1_score": 0.3321165646599632
                    },
                    {
                        "epoch": 3,
                        "loss": 4.2015427215189876,
                        "accuracy": 0.4544,
                        "precision": 0.3671674048792514,
                        "recall": 0.4544,
                        "f1_score": 0.36062218708609806
                    },
                    {
                        "epoch": 4,
                        "loss": 3.8439477848101267,
                        "accuracy": 0.449,
                        "precision": 0.38819688122344226,
                        "recall": 0.449,
                        "f1_score": 0.3532373111236657
                    },
                    {
                        "epoch": 5,
                        "loss": 3.6291534810126582,
                        "accuracy": 0.4411,
                        "precision": 0.4034493631566253,
                        "recall": 0.4411,
                        "f1_score": 0.34297476864176113
                    },
                    {
                        "epoch": 6,
                        "loss": 3.6782041139240507,
                        "accuracy": 0.4427,
                        "precision": 0.39974347067039107,
                        "recall": 0.4427,
                        "f1_score": 0.345045382246932
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.44998999799959993,
                "precision": 0.36535618570128536,
                "recall": 0.44998999799959993,
                "f1_score": 0.35597539216515256
            },
            "confusion_matrix": [
                [
                    3139,
                    194,
                    0
                ],
                [
                    1973,
                    1360,
                    0
                ],
                [
                    2963,
                    369,
                    0
                ]
            ],
            "best_epoch": 3,
            "time_train": 46.5011463880539
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.44998999799959993,
            "accuracy_std": 0.0,
            "precision_mean": 0.36535618570128536,
            "precision_std": 0.0,
            "recall_mean": 0.44998999799959993,
            "recall_std": 0.0,
            "f1_score_mean": 0.35597539216515256,
            "f1_score_std": 0.0,
            "time_train_mean": 46.5011463880539,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_112.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 113,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.5467768530150754,
                        "accuracy": 0.5765808238552654
                    },
                    {
                        "epoch": 2,
                        "loss": 0.8887258558417085,
                        "accuracy": 0.6842870332174357
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6962203596105527,
                        "accuracy": 0.7392696485748522
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6651077653894473,
                        "accuracy": 0.770306637594044
                    },
                    {
                        "epoch": 5,
                        "loss": 0.6558745877826633,
                        "accuracy": 0.7760622311273498
                    },
                    {
                        "epoch": 6,
                        "loss": 0.5474884186557789,
                        "accuracy": 0.801854361875577
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.2812994462025316,
                        "accuracy": 0.5065,
                        "precision": 0.595303687546899,
                        "recall": 0.5065,
                        "f1_score": 0.49233468821738424
                    },
                    {
                        "epoch": 2,
                        "loss": 1.7072784810126582,
                        "accuracy": 0.4842,
                        "precision": 0.6784660925742445,
                        "recall": 0.4842,
                        "f1_score": 0.4384172361941303
                    },
                    {
                        "epoch": 3,
                        "loss": 2.5446993670886076,
                        "accuracy": 0.447,
                        "precision": 0.680548003025346,
                        "recall": 0.447,
                        "f1_score": 0.35673948067557065
                    },
                    {
                        "epoch": 4,
                        "loss": 3.6542721518987342,
                        "accuracy": 0.4673,
                        "precision": 0.6329263293017308,
                        "recall": 0.4673,
                        "f1_score": 0.37444311557554016
                    },
                    {
                        "epoch": 5,
                        "loss": 3.010185917721519,
                        "accuracy": 0.4587,
                        "precision": 0.7081986756071926,
                        "recall": 0.4587,
                        "f1_score": 0.3841942600395539
                    },
                    {
                        "epoch": 6,
                        "loss": 3.5843552215189876,
                        "accuracy": 0.4809,
                        "precision": 0.6745046041015683,
                        "recall": 0.4809,
                        "f1_score": 0.41187114620933024
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.49529905981196237,
                "precision": 0.5811651595715941,
                "recall": 0.49529905981196237,
                "f1_score": 0.4788696083911084
            },
            "confusion_matrix": [
                [
                    2695,
                    125,
                    513
                ],
                [
                    1786,
                    1066,
                    481
                ],
                [
                    1966,
                    175,
                    1191
                ]
            ],
            "best_epoch": 1,
            "time_train": 45.14504415194194
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.49529905981196237,
            "accuracy_std": 0.0,
            "precision_mean": 0.5811651595715941,
            "precision_std": 0.0,
            "recall_mean": 0.49529905981196237,
            "recall_std": 0.0,
            "f1_score_mean": 0.4788696083911084,
            "f1_score_std": 0.0,
            "time_train_mean": 45.14504415194194,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_113.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 114,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0001, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0.07\n)",
                "learning_rate": 0.0001,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 4,
                "lora_alpha": 32,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2068644001256281,
                        "accuracy": 0.6365725735164123
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6249263897613065,
                        "accuracy": 0.7664957667904218
                    },
                    {
                        "epoch": 3,
                        "loss": 0.49316896984924624,
                        "accuracy": 0.8106940106468659
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4812882773241206,
                        "accuracy": 0.8179032353114503
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4498468907035176,
                        "accuracy": 0.8273518376647613
                    },
                    {
                        "epoch": 6,
                        "loss": 0.43085544912060303,
                        "accuracy": 0.8333627988292376
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 4.8710443037974684,
                        "accuracy": 0.4415,
                        "precision": 0.3848263313924748,
                        "recall": 0.4415,
                        "f1_score": 0.34563775997450213
                    },
                    {
                        "epoch": 2,
                        "loss": 4.2662183544303796,
                        "accuracy": 0.4488,
                        "precision": 0.3887855163526769,
                        "recall": 0.4488,
                        "f1_score": 0.3534352887651031
                    },
                    {
                        "epoch": 3,
                        "loss": 4.0765427215189876,
                        "accuracy": 0.4573,
                        "precision": 0.3799242472617739,
                        "recall": 0.4573,
                        "f1_score": 0.3638349049827729
                    },
                    {
                        "epoch": 4,
                        "loss": 3.7369462025316458,
                        "accuracy": 0.4587,
                        "precision": 0.3760048241963772,
                        "recall": 0.4587,
                        "f1_score": 0.3641840927258447
                    },
                    {
                        "epoch": 5,
                        "loss": 3.352254746835443,
                        "accuracy": 0.4672,
                        "precision": 0.3533674704277125,
                        "recall": 0.4672,
                        "f1_score": 0.3739543796545094
                    },
                    {
                        "epoch": 6,
                        "loss": 3.445213607594937,
                        "accuracy": 0.4597,
                        "precision": 0.38061195054249436,
                        "recall": 0.4597,
                        "f1_score": 0.3650378028914748
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4589917983596719,
                "precision": 0.3450903338562449,
                "recall": 0.4589917983596719,
                "f1_score": 0.36640008404526697
            },
            "confusion_matrix": [
                [
                    2996,
                    337,
                    0
                ],
                [
                    1740,
                    1593,
                    0
                ],
                [
                    2754,
                    578,
                    0
                ]
            ],
            "best_epoch": 5,
            "time_train": 48.86853946050008
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4589917983596719,
            "accuracy_std": 0.0,
            "precision_mean": 0.3450903338562449,
            "precision_std": 0.0,
            "recall_mean": 0.4589917983596719,
            "recall_std": 0.0,
            "f1_score_mean": 0.36640008404526697,
            "f1_score_std": 0.0,
            "time_train_mean": 48.86853946050008,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_114.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 115,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=5e-05, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 5e-05\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 5e-05,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 16,
                "lora_alpha": 64,
                "lora_dropout": 0
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3465570037688441,
                        "accuracy": 0.6207004930559648
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7100149183417085,
                        "accuracy": 0.7400946824601725
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5668430040829145,
                        "accuracy": 0.7922878975386489
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4811459641959799,
                        "accuracy": 0.8171174887540024
                    },
                    {
                        "epoch": 5,
                        "loss": 0.45451868718592964,
                        "accuracy": 0.8235606105250751
                    },
                    {
                        "epoch": 6,
                        "loss": 0.43142960898241206,
                        "accuracy": 0.8313591451077454
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.668117088607595,
                        "accuracy": 0.4408,
                        "precision": 0.364387328902494,
                        "recall": 0.4408,
                        "f1_score": 0.34453972729288096
                    },
                    {
                        "epoch": 2,
                        "loss": 6.0988924050632916,
                        "accuracy": 0.4388,
                        "precision": 0.3917479617566195,
                        "recall": 0.4388,
                        "f1_score": 0.34020365767841015
                    },
                    {
                        "epoch": 3,
                        "loss": 6.5363924050632916,
                        "accuracy": 0.4257,
                        "precision": 0.4088557541383252,
                        "recall": 0.4257,
                        "f1_score": 0.32323966336283966
                    },
                    {
                        "epoch": 4,
                        "loss": 5.780854430379747,
                        "accuracy": 0.4534,
                        "precision": 0.37883379419698693,
                        "recall": 0.4534,
                        "f1_score": 0.35741879690597345
                    },
                    {
                        "epoch": 5,
                        "loss": 6.134098101265823,
                        "accuracy": 0.4468,
                        "precision": 0.4009560685516719,
                        "recall": 0.4468,
                        "f1_score": 0.34963198782594057
                    },
                    {
                        "epoch": 6,
                        "loss": 6.191851265822785,
                        "accuracy": 0.4577,
                        "precision": 0.37247972895040365,
                        "recall": 0.4577,
                        "f1_score": 0.3619150864338867
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4464892978595719,
                "precision": 0.3574480774871981,
                "recall": 0.4464892978595719,
                "f1_score": 0.35224437605803144
            },
            "confusion_matrix": [
                [
                    3118,
                    215,
                    0
                ],
                [
                    1987,
                    1346,
                    0
                ],
                [
                    2925,
                    407,
                    0
                ]
            ],
            "best_epoch": 6,
            "time_train": 34.91446069478989
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4464892978595719,
            "accuracy_std": 0.0,
            "precision_mean": 0.3574480774871981,
            "precision_std": 0.0,
            "recall_mean": 0.4464892978595719,
            "recall_std": 0.0,
            "f1_score_mean": 0.35224437605803144,
            "f1_score_std": 0.0,
            "time_train_mean": 34.91446069478989,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_115.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 116,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.001\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 16,
                "lora_dropout": 0.3
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2898967493718594,
                        "accuracy": 0.6110750977272281
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6756438442211056,
                        "accuracy": 0.7503486750348675
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5158212939698492,
                        "accuracy": 0.8136602039012316
                    },
                    {
                        "epoch": 4,
                        "loss": 0.46716492619346733,
                        "accuracy": 0.8251713909678433
                    },
                    {
                        "epoch": 5,
                        "loss": 0.45582404208542715,
                        "accuracy": 0.825839275541674
                    },
                    {
                        "epoch": 6,
                        "loss": 0.42890232412060303,
                        "accuracy": 0.8349146482801972
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.981012658227848,
                        "accuracy": 0.4354,
                        "precision": 0.3818657509278897,
                        "recall": 0.4354,
                        "f1_score": 0.33795746007275923
                    },
                    {
                        "epoch": 2,
                        "loss": 3.8208069620253164,
                        "accuracy": 0.4368,
                        "precision": 0.41071662888228677,
                        "recall": 0.4368,
                        "f1_score": 0.3375586707672094
                    },
                    {
                        "epoch": 3,
                        "loss": 3.1566455696202533,
                        "accuracy": 0.4226,
                        "precision": 0.4174959982166049,
                        "recall": 0.4226,
                        "f1_score": 0.31917089142122085
                    },
                    {
                        "epoch": 4,
                        "loss": 2.9434335443037973,
                        "accuracy": 0.4478,
                        "precision": 0.3981396654464636,
                        "recall": 0.4478,
                        "f1_score": 0.35160511891664203
                    },
                    {
                        "epoch": 5,
                        "loss": 2.6015625,
                        "accuracy": 0.4413,
                        "precision": 0.40413044139266896,
                        "recall": 0.4413,
                        "f1_score": 0.3432779931956382
                    },
                    {
                        "epoch": 6,
                        "loss": 3.5282832278481013,
                        "accuracy": 0.444,
                        "precision": 0.4051797787737867,
                        "recall": 0.444,
                        "f1_score": 0.3462846006001094
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4401880376075215,
                "precision": 0.3901103376901833,
                "recall": 0.4401880376075215,
                "f1_score": 0.3433112569846233
            },
            "confusion_matrix": [
                [
                    3240,
                    93,
                    0
                ],
                [
                    2172,
                    1161,
                    0
                ],
                [
                    3117,
                    215,
                    0
                ]
            ],
            "best_epoch": 4,
            "time_train": 46.20970991452535
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4401880376075215,
            "accuracy_std": 0.0,
            "precision_mean": 0.3901103376901833,
            "precision_std": 0.0,
            "recall_mean": 0.4401880376075215,
            "recall_std": 0.0,
            "f1_score_mean": 0.3433112569846233,
            "f1_score_std": 0.0,
            "time_train_mean": 46.20970991452535,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_116.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 117,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 0.0005\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 32,
                "lora_alpha": 64,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.1862535332914572,
                        "accuracy": 0.6240792032529907
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7240499371859297,
                        "accuracy": 0.7325515155086727
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5101533055904522,
                        "accuracy": 0.8079046103679258
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4615018451633166,
                        "accuracy": 0.8235213231972027
                    },
                    {
                        "epoch": 5,
                        "loss": 0.44889977229899497,
                        "accuracy": 0.8263892981318876
                    },
                    {
                        "epoch": 6,
                        "loss": 0.40901774497487436,
                        "accuracy": 0.8373111752804133
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.9657832278481013,
                        "accuracy": 0.4418,
                        "precision": 0.38453975389414646,
                        "recall": 0.4418,
                        "f1_score": 0.34587688140983597
                    },
                    {
                        "epoch": 2,
                        "loss": 4.688291139240507,
                        "accuracy": 0.4359,
                        "precision": 0.40695165791487,
                        "recall": 0.4359,
                        "f1_score": 0.33654822941893114
                    },
                    {
                        "epoch": 3,
                        "loss": 4.4760680379746836,
                        "accuracy": 0.4346,
                        "precision": 0.40946608602454254,
                        "recall": 0.4346,
                        "f1_score": 0.33539504769506756
                    },
                    {
                        "epoch": 4,
                        "loss": 3.4432357594936707,
                        "accuracy": 0.4441,
                        "precision": 0.4029220514950166,
                        "recall": 0.4441,
                        "f1_score": 0.3464883703679086
                    },
                    {
                        "epoch": 5,
                        "loss": 3.6507120253164556,
                        "accuracy": 0.4407,
                        "precision": 0.4125547637884765,
                        "recall": 0.4407,
                        "f1_score": 0.34257803318811914
                    },
                    {
                        "epoch": 6,
                        "loss": 3.5537974683544302,
                        "accuracy": 0.4463,
                        "precision": 0.40274488893322696,
                        "recall": 0.4463,
                        "f1_score": 0.34913167014014623
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.43958791758351673,
                "precision": 0.3859256253414331,
                "recall": 0.43958791758351673,
                "f1_score": 0.34198069539588916
            },
            "confusion_matrix": [
                [
                    3243,
                    90,
                    0
                ],
                [
                    2181,
                    1152,
                    0
                ],
                [
                    3091,
                    241,
                    0
                ]
            ],
            "best_epoch": 6,
            "time_train": 47.96985431909561
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.43958791758351673,
            "accuracy_std": 0.0,
            "precision_mean": 0.3859256253414331,
            "precision_std": 0.0,
            "recall_mean": 0.43958791758351673,
            "recall_std": 0.0,
            "f1_score_mean": 0.34198069539588916,
            "f1_score_std": 0.0,
            "time_train_mean": 47.96985431909561,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_117.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 118,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0001, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0.001\n)",
                "learning_rate": 0.0001,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 4,
                "lora_alpha": 32,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.203973971419598,
                        "accuracy": 0.6372797454181154
                    },
                    {
                        "epoch": 2,
                        "loss": 0.5877188677763819,
                        "accuracy": 0.7850786728740645
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5001668498743719,
                        "accuracy": 0.81289410100772
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4785450690954774,
                        "accuracy": 0.8187872001885792
                    },
                    {
                        "epoch": 5,
                        "loss": 0.44728034704773867,
                        "accuracy": 0.8256821262301844
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4218455559045226,
                        "accuracy": 0.8346396369850905
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 5.306170886075949,
                        "accuracy": 0.4304,
                        "precision": 0.40385730699364686,
                        "recall": 0.4304,
                        "f1_score": 0.33046429112271264
                    },
                    {
                        "epoch": 2,
                        "loss": 4.821400316455696,
                        "accuracy": 0.4626,
                        "precision": 0.32933957515698586,
                        "recall": 0.4626,
                        "f1_score": 0.37075069860189575
                    },
                    {
                        "epoch": 3,
                        "loss": 5.376977848101266,
                        "accuracy": 0.4565,
                        "precision": 0.37853463557779077,
                        "recall": 0.4565,
                        "f1_score": 0.3620794052117838
                    },
                    {
                        "epoch": 4,
                        "loss": 3.564280063291139,
                        "accuracy": 0.4506,
                        "precision": 0.3965348566996472,
                        "recall": 0.4506,
                        "f1_score": 0.3545857985383109
                    },
                    {
                        "epoch": 5,
                        "loss": 3.5650712025316458,
                        "accuracy": 0.4601,
                        "precision": 0.36437495008160065,
                        "recall": 0.4601,
                        "f1_score": 0.3659817764805696
                    },
                    {
                        "epoch": 6,
                        "loss": 3.7954905063291138,
                        "accuracy": 0.4587,
                        "precision": 0.38655783787136777,
                        "recall": 0.4587,
                        "f1_score": 0.3633996289869337
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4571914382876575,
                "precision": 0.3243871827355432,
                "recall": 0.4571914382876575,
                "f1_score": 0.3655303837533911
            },
            "confusion_matrix": [
                [
                    2806,
                    527,
                    0
                ],
                [
                    1568,
                    1765,
                    0
                ],
                [
                    2499,
                    833,
                    0
                ]
            ],
            "best_epoch": 2,
            "time_train": 47.061055302619934
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4571914382876575,
            "accuracy_std": 0.0,
            "precision_mean": 0.3243871827355432,
            "precision_std": 0.0,
            "recall_mean": 0.4571914382876575,
            "recall_std": 0.0,
            "f1_score_mean": 0.3655303837533911,
            "f1_score_std": 0.0,
            "time_train_mean": 47.061055302619934,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_118.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 119,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 16,
                "lora_alpha": 32,
                "lora_dropout": 0.3
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2716266881281406,
                        "accuracy": 0.621721963580647
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6516714431532663,
                        "accuracy": 0.7520773174612528
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5223137170226131,
                        "accuracy": 0.8039169465888778
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4705362751256281,
                        "accuracy": 0.8208104975740075
                    },
                    {
                        "epoch": 5,
                        "loss": 0.45699689855527637,
                        "accuracy": 0.8256624825662483
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4305561008165829,
                        "accuracy": 0.8329306382226412
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.8392009493670884,
                        "accuracy": 0.4533,
                        "precision": 0.31474245300725895,
                        "recall": 0.4533,
                        "f1_score": 0.36276169682190057
                    },
                    {
                        "epoch": 2,
                        "loss": 5.5508306962025316,
                        "accuracy": 0.4353,
                        "precision": 0.40234552919906535,
                        "recall": 0.4353,
                        "f1_score": 0.3355461217256647
                    },
                    {
                        "epoch": 3,
                        "loss": 5.506329113924051,
                        "accuracy": 0.4344,
                        "precision": 0.4079699265237622,
                        "recall": 0.4344,
                        "f1_score": 0.3345962583142301
                    },
                    {
                        "epoch": 4,
                        "loss": 4.9794303797468356,
                        "accuracy": 0.4446,
                        "precision": 0.4025178837209302,
                        "recall": 0.4446,
                        "f1_score": 0.3465127428197109
                    },
                    {
                        "epoch": 5,
                        "loss": 4.8219936708860756,
                        "accuracy": 0.4505,
                        "precision": 0.39382797186814866,
                        "recall": 0.4505,
                        "f1_score": 0.35367809604277717
                    },
                    {
                        "epoch": 6,
                        "loss": 4.535799050632911,
                        "accuracy": 0.4572,
                        "precision": 0.38694283125991485,
                        "recall": 0.4572,
                        "f1_score": 0.3618448559697442
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4450890178035607,
                "precision": 0.3101334290923296,
                "recall": 0.4450890178035607,
                "f1_score": 0.3568050439070521
            },
            "confusion_matrix": [
                [
                    2611,
                    722,
                    0
                ],
                [
                    1494,
                    1839,
                    0
                ],
                [
                    2427,
                    905,
                    0
                ]
            ],
            "best_epoch": 1,
            "time_train": 45.04984631141027
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4450890178035607,
            "accuracy_std": 0.0,
            "precision_mean": 0.3101334290923296,
            "precision_std": 0.0,
            "recall_mean": 0.4450890178035607,
            "recall_std": 0.0,
            "f1_score_mean": 0.3568050439070521,
            "f1_score_std": 0.0,
            "time_train_mean": 45.04984631141027,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_119.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 122,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 16,
                "lora_alpha": 64,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2487829773869348,
                        "accuracy": 0.6462372561730214
                    },
                    {
                        "epoch": 2,
                        "loss": 0.573899772298995,
                        "accuracy": 0.7929754257764158
                    },
                    {
                        "epoch": 3,
                        "loss": 0.4864753454773869,
                        "accuracy": 0.813503054589742
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4515939070351759,
                        "accuracy": 0.8255642642465673
                    },
                    {
                        "epoch": 5,
                        "loss": 0.44035607726130654,
                        "accuracy": 0.8266446657630582
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4021057435615578,
                        "accuracy": 0.840866678452865
                    },
                    {
                        "epoch": 7,
                        "loss": 0.3886056257851759,
                        "accuracy": 0.8448936295597855
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.9040743670886076,
                        "accuracy": 0.4531,
                        "precision": 0.34737462196389524,
                        "recall": 0.4531,
                        "f1_score": 0.3584519966353158
                    },
                    {
                        "epoch": 2,
                        "loss": 4.921875,
                        "accuracy": 0.4327,
                        "precision": 0.4015979314285714,
                        "recall": 0.4327,
                        "f1_score": 0.3322460641231049
                    },
                    {
                        "epoch": 3,
                        "loss": 4.233583860759493,
                        "accuracy": 0.4328,
                        "precision": 0.41073843610348704,
                        "recall": 0.4328,
                        "f1_score": 0.3324964136719256
                    },
                    {
                        "epoch": 4,
                        "loss": 4.215387658227848,
                        "accuracy": 0.4536,
                        "precision": 0.38475814942466,
                        "recall": 0.4536,
                        "f1_score": 0.3574396817650303
                    },
                    {
                        "epoch": 5,
                        "loss": 3.71875,
                        "accuracy": 0.4587,
                        "precision": 0.37641119980353405,
                        "recall": 0.4587,
                        "f1_score": 0.362650515436944
                    },
                    {
                        "epoch": 6,
                        "loss": 3.6109572784810124,
                        "accuracy": 0.4637,
                        "precision": 0.36598894220892725,
                        "recall": 0.4637,
                        "f1_score": 0.3681365258959675
                    },
                    {
                        "epoch": 7,
                        "loss": 4.502373417721519,
                        "accuracy": 0.4567,
                        "precision": 0.37872496462147226,
                        "recall": 0.4567,
                        "f1_score": 0.3594804819021395
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.45299059811962394,
                "precision": 0.355481776816963,
                "recall": 0.45299059811962394,
                "f1_score": 0.3581948869921694
            },
            "confusion_matrix": [
                [
                    3119,
                    214,
                    0
                ],
                [
                    1923,
                    1410,
                    0
                ],
                [
                    2856,
                    476,
                    0
                ]
            ],
            "best_epoch": 6,
            "time_train": 55.26841479937236
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.45299059811962394,
            "accuracy_std": 0.0,
            "precision_mean": 0.355481776816963,
            "precision_std": 0.0,
            "recall_mean": 0.45299059811962394,
            "recall_std": 0.0,
            "f1_score_mean": 0.3581948869921694,
            "f1_score_std": 0.0,
            "time_train_mean": 55.26841479937236,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_122.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 123,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.7658409233668342,
                        "accuracy": 0.5185927279156108
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1168096341080402,
                        "accuracy": 0.5920993183648614
                    },
                    {
                        "epoch": 3,
                        "loss": 1.0918901146356783,
                        "accuracy": 0.6392048244838627
                    },
                    {
                        "epoch": 4,
                        "loss": 1.0364027167085428,
                        "accuracy": 0.6795725538727484
                    },
                    {
                        "epoch": 5,
                        "loss": 0.9029130025125628,
                        "accuracy": 0.7074469129982124
                    },
                    {
                        "epoch": 6,
                        "loss": 0.9051752905150754,
                        "accuracy": 0.7125346219576876
                    },
                    {
                        "epoch": 7,
                        "loss": 1.1306483589824121,
                        "accuracy": 0.706111143850551
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.8714893196202531,
                        "accuracy": 0.4747,
                        "precision": 0.32855014683103134,
                        "recall": 0.4747,
                        "f1_score": 0.3837251803307341
                    },
                    {
                        "epoch": 2,
                        "loss": 1.551325158227848,
                        "accuracy": 0.51,
                        "precision": 0.5653355707967895,
                        "recall": 0.51,
                        "f1_score": 0.5010263576712606
                    },
                    {
                        "epoch": 3,
                        "loss": 2.0882120253164556,
                        "accuracy": 0.5379,
                        "precision": 0.6443838914677049,
                        "recall": 0.5379,
                        "f1_score": 0.5064993394545764
                    },
                    {
                        "epoch": 4,
                        "loss": 1.5857397151898733,
                        "accuracy": 0.569,
                        "precision": 0.6283756288278503,
                        "recall": 0.569,
                        "f1_score": 0.560923409334272
                    },
                    {
                        "epoch": 5,
                        "loss": 2.7000098892405062,
                        "accuracy": 0.4729,
                        "precision": 0.5848375010080825,
                        "recall": 0.4729,
                        "f1_score": 0.42655836389992857
                    },
                    {
                        "epoch": 6,
                        "loss": 4.066554588607595,
                        "accuracy": 0.5971,
                        "precision": 0.6793201462528922,
                        "recall": 0.5971,
                        "f1_score": 0.5636212646965075
                    },
                    {
                        "epoch": 7,
                        "loss": 5.62920292721519,
                        "accuracy": 0.6,
                        "precision": 0.6956095156776777,
                        "recall": 0.6,
                        "f1_score": 0.5519354684626964
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.5958191638327666,
                "precision": 0.6770659298216289,
                "recall": 0.5958191638327666,
                "f1_score": 0.5571066419316282
            },
            "confusion_matrix": [
                [
                    2017,
                    52,
                    1264
                ],
                [
                    1313,
                    798,
                    1222
                ],
                [
                    146,
                    44,
                    3142
                ]
            ],
            "best_epoch": 6,
            "time_train": 56.457756606737775
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.5958191638327666,
            "accuracy_std": 0.0,
            "precision_mean": 0.6770659298216289,
            "precision_std": 0.0,
            "recall_mean": 0.5958191638327666,
            "recall_std": 0.0,
            "f1_score_mean": 0.5571066419316282,
            "f1_score_std": 0.0,
            "time_train_mean": 56.457756606737775,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_123.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 124,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2893324042085428,
                        "accuracy": 0.6404030879839707
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6933937264447236,
                        "accuracy": 0.7528630640187007
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6162452889447236,
                        "accuracy": 0.7754729212092639
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6078929805276382,
                        "accuracy": 0.7907753354155617
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5450175683103015,
                        "accuracy": 0.8031704873593023
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4899693781407035,
                        "accuracy": 0.8220087610741156
                    },
                    {
                        "epoch": 7,
                        "loss": 0.4882910646984925,
                        "accuracy": 0.817981809967195
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 10.875791139240507,
                        "accuracy": 0.4149,
                        "precision": 0.4048061514997458,
                        "recall": 0.4149,
                        "f1_score": 0.30944964478791537
                    },
                    {
                        "epoch": 2,
                        "loss": 13.223101265822784,
                        "accuracy": 0.3599,
                        "precision": 0.40749138602005686,
                        "recall": 0.3599,
                        "f1_score": 0.2196742596817277
                    },
                    {
                        "epoch": 3,
                        "loss": 18.18354430379747,
                        "accuracy": 0.3367,
                        "precision": 0.39484003012048186,
                        "recall": 0.3367,
                        "f1_score": 0.17385828988456462
                    },
                    {
                        "epoch": 4,
                        "loss": 14.166930379746836,
                        "accuracy": 0.4177,
                        "precision": 0.4168899877018038,
                        "recall": 0.4177,
                        "f1_score": 0.3125996517994192
                    },
                    {
                        "epoch": 5,
                        "loss": 14.867088607594937,
                        "accuracy": 0.4303,
                        "precision": 0.4105863770974721,
                        "recall": 0.4303,
                        "f1_score": 0.32965532202677134
                    },
                    {
                        "epoch": 6,
                        "loss": 15.479430379746836,
                        "accuracy": 0.4233,
                        "precision": 0.41448937988376927,
                        "recall": 0.4233,
                        "f1_score": 0.32029012483996927
                    },
                    {
                        "epoch": 7,
                        "loss": 15.010284810126583,
                        "accuracy": 0.4287,
                        "precision": 0.4119444653677082,
                        "recall": 0.4287,
                        "f1_score": 0.3272204224114473
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.42368473694738945,
                "precision": 0.40141753508677286,
                "recall": 0.42368473694738945,
                "f1_score": 0.3218414744116496
            },
            "confusion_matrix": [
                [
                    3279,
                    54,
                    0
                ],
                [
                    2376,
                    957,
                    0
                ],
                [
                    3195,
                    137,
                    0
                ]
            ],
            "best_epoch": 5,
            "time_train": 55.12262060642242
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.42368473694738945,
            "accuracy_std": 0.0,
            "precision_mean": 0.40141753508677286,
            "precision_std": 0.0,
            "recall_mean": 0.42368473694738945,
            "recall_std": 0.0,
            "f1_score_mean": 0.3218414744116496,
            "f1_score_std": 0.0,
            "time_train_mean": 55.12262060642242,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_124.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.48441425879397,
                        "accuracy": 0.5947119256683757
                    },
                    {
                        "epoch": 2,
                        "loss": 0.9150881359924623,
                        "accuracy": 0.6904747873573379
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6479418577261307,
                        "accuracy": 0.7629009762900977
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5372124293341709,
                        "accuracy": 0.7982792150391891
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5139540475816583,
                        "accuracy": 0.8088082189089909
                    },
                    {
                        "epoch": 6,
                        "loss": 0.518535058103015,
                        "accuracy": 0.8081796216630326
                    },
                    {
                        "epoch": 7,
                        "loss": 0.46008362123115576,
                        "accuracy": 0.8238749091480543
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.1969442246835442,
                        "accuracy": 0.5171,
                        "precision": 0.6377034045736706,
                        "recall": 0.5171,
                        "f1_score": 0.49605261429109787
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1126384493670887,
                        "accuracy": 0.6206,
                        "precision": 0.6588259016595713,
                        "recall": 0.6206,
                        "f1_score": 0.6059806210250417
                    },
                    {
                        "epoch": 3,
                        "loss": 1.4042721518987342,
                        "accuracy": 0.5367,
                        "precision": 0.664767897367043,
                        "recall": 0.5367,
                        "f1_score": 0.5163097595621734
                    },
                    {
                        "epoch": 4,
                        "loss": 2.702037183544304,
                        "accuracy": 0.47,
                        "precision": 0.6388078259501913,
                        "recall": 0.47,
                        "f1_score": 0.3876766831561144
                    },
                    {
                        "epoch": 5,
                        "loss": 2.9978243670886076,
                        "accuracy": 0.4512,
                        "precision": 0.7223340390723273,
                        "recall": 0.4512,
                        "f1_score": 0.3635221143081247
                    },
                    {
                        "epoch": 6,
                        "loss": 2.446400316455696,
                        "accuracy": 0.4597,
                        "precision": 0.7111329195461195,
                        "recall": 0.4597,
                        "f1_score": 0.3741183354093994
                    },
                    {
                        "epoch": 7,
                        "loss": 3.7711629746835444,
                        "accuracy": 0.4633,
                        "precision": 0.3235538747132338,
                        "recall": 0.4633,
                        "f1_score": 0.36342134712857305
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.6168233646729346,
                "precision": 0.6526326604508,
                "recall": 0.6168233646729346,
                "f1_score": 0.6021307399336339
            },
            "confusion_matrix": [
                [
                    2398,
                    200,
                    735
                ],
                [
                    1465,
                    1181,
                    687
                ],
                [
                    602,
                    142,
                    2588
                ]
            ],
            "best_epoch": 2,
            "time_train": 54.42423860232035
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.6168233646729346,
            "accuracy_std": 0.0,
            "precision_mean": 0.6526326604508,
            "precision_std": 0.0,
            "recall_mean": 0.6168233646729346,
            "recall_std": 0.0,
            "f1_score_mean": 0.6021307399336339,
            "f1_score_std": 0.0,
            "time_train_mean": 54.42423860232035,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 116,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.001\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 16,
                "lora_dropout": 0.3
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2755623822236182,
                        "accuracy": 0.6091500186614808
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7158939227386935,
                        "accuracy": 0.7338479973284617
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5284135521356784,
                        "accuracy": 0.8098296894336732
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4778727622487437,
                        "accuracy": 0.8163906731883631
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4594898319723618,
                        "accuracy": 0.8239927711316715
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4317485866834171,
                        "accuracy": 0.8336574537882806
                    },
                    {
                        "epoch": 7,
                        "loss": 0.42240499371859297,
                        "accuracy": 0.8375468992476477
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.8089398734177213,
                        "accuracy": 0.4315,
                        "precision": 0.3958877364861626,
                        "recall": 0.4315,
                        "f1_score": 0.3322314011664382
                    },
                    {
                        "epoch": 2,
                        "loss": 4.6511075949367084,
                        "accuracy": 0.4328,
                        "precision": 0.4148644841273835,
                        "recall": 0.4328,
                        "f1_score": 0.3329788816498814
                    },
                    {
                        "epoch": 3,
                        "loss": 4.596716772151899,
                        "accuracy": 0.444,
                        "precision": 0.40561425311609584,
                        "recall": 0.444,
                        "f1_score": 0.34736019360683557
                    },
                    {
                        "epoch": 4,
                        "loss": 3.5395569620253164,
                        "accuracy": 0.4456,
                        "precision": 0.40615396208930404,
                        "recall": 0.4456,
                        "f1_score": 0.348692659051807
                    },
                    {
                        "epoch": 5,
                        "loss": 3.6135284810126582,
                        "accuracy": 0.4558,
                        "precision": 0.39353502508170407,
                        "recall": 0.4558,
                        "f1_score": 0.36134326566610636
                    },
                    {
                        "epoch": 6,
                        "loss": 3.7507911392405062,
                        "accuracy": 0.4551,
                        "precision": 0.3955412009320714,
                        "recall": 0.4551,
                        "f1_score": 0.3597068671020709
                    },
                    {
                        "epoch": 7,
                        "loss": 3.700356012658228,
                        "accuracy": 0.4561,
                        "precision": 0.39781162032359585,
                        "recall": 0.4561,
                        "f1_score": 0.36080041271052715
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4473894778955791,
                "precision": 0.3837603735936221,
                "recall": 0.4473894778955791,
                "f1_score": 0.3522094238529393
            },
            "confusion_matrix": [
                [
                    3211,
                    122,
                    0
                ],
                [
                    2071,
                    1262,
                    0
                ],
                [
                    3070,
                    262,
                    0
                ]
            ],
            "best_epoch": 5,
            "time_train": 56.90543063879013
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4473894778955791,
            "accuracy_std": 0.0,
            "precision_mean": 0.3837603735936221,
            "precision_std": 0.0,
            "recall_mean": 0.4473894778955791,
            "recall_std": 0.0,
            "f1_score_mean": 0.3522094238529393,
            "f1_score_std": 0.0,
            "time_train_mean": 56.90543063879013,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_116.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 117,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 0.0005\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 32,
                "lora_alpha": 64,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.1793979663944723,
                        "accuracy": 0.6213683776297955
                    },
                    {
                        "epoch": 2,
                        "loss": 0.707242266017588,
                        "accuracy": 0.7387785569764472
                    },
                    {
                        "epoch": 3,
                        "loss": 0.4971782741834171,
                        "accuracy": 0.809318954171332
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4577869817839196,
                        "accuracy": 0.8238552654841181
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4397671953517588,
                        "accuracy": 0.828825112459976
                    },
                    {
                        "epoch": 6,
                        "loss": 0.40950357255025127,
                        "accuracy": 0.8379201288624354
                    },
                    {
                        "epoch": 7,
                        "loss": 0.39987780700376885,
                        "accuracy": 0.8409452531086098
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.5569620253164556,
                        "accuracy": 0.4484,
                        "precision": 0.3485631689507693,
                        "recall": 0.4484,
                        "f1_score": 0.35580980465704815
                    },
                    {
                        "epoch": 2,
                        "loss": 4.0573575949367084,
                        "accuracy": 0.4394,
                        "precision": 0.3982105043478261,
                        "recall": 0.4394,
                        "f1_score": 0.34117476612067466
                    },
                    {
                        "epoch": 3,
                        "loss": 3.5280854430379747,
                        "accuracy": 0.4443,
                        "precision": 0.3883119505984212,
                        "recall": 0.4443,
                        "f1_score": 0.3473241120590479
                    },
                    {
                        "epoch": 4,
                        "loss": 2.9661787974683542,
                        "accuracy": 0.4527,
                        "precision": 0.38071948178736575,
                        "recall": 0.4527,
                        "f1_score": 0.3570582595819441
                    },
                    {
                        "epoch": 5,
                        "loss": 3.449762658227848,
                        "accuracy": 0.4559,
                        "precision": 0.36867642910312304,
                        "recall": 0.4559,
                        "f1_score": 0.36113637387548525
                    },
                    {
                        "epoch": 6,
                        "loss": 3.727254746835443,
                        "accuracy": 0.4542,
                        "precision": 0.3809302665353825,
                        "recall": 0.4542,
                        "f1_score": 0.3593263241547888
                    },
                    {
                        "epoch": 7,
                        "loss": 3.2164754746835444,
                        "accuracy": 0.4494,
                        "precision": 0.3856331940004918,
                        "recall": 0.4494,
                        "f1_score": 0.3524391264367816
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4507901580316063,
                "precision": 0.36270786670253935,
                "recall": 0.4507901580316063,
                "f1_score": 0.35625575296632717
            },
            "confusion_matrix": [
                [
                    3141,
                    192,
                    0
                ],
                [
                    1967,
                    1366,
                    0
                ],
                [
                    2931,
                    401,
                    0
                ]
            ],
            "best_epoch": 5,
            "time_train": 56.755954241752626
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4507901580316063,
            "accuracy_std": 0.0,
            "precision_mean": 0.36270786670253935,
            "precision_std": 0.0,
            "recall_mean": 0.4507901580316063,
            "recall_std": 0.0,
            "f1_score_mean": 0.35625575296632717,
            "f1_score_std": 0.0,
            "time_train_mean": 56.755954241752626,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_117.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 118,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0001, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0.001\n)",
                "learning_rate": 0.0001,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 4,
                "lora_alpha": 32,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.18453105370603,
                        "accuracy": 0.640619168287269
                    },
                    {
                        "epoch": 2,
                        "loss": 0.5907221655150754,
                        "accuracy": 0.779755239947355
                    },
                    {
                        "epoch": 3,
                        "loss": 0.4896700298366834,
                        "accuracy": 0.8142691574832538
                    },
                    {
                        "epoch": 4,
                        "loss": 0.48048347204773867,
                        "accuracy": 0.8162728112047459
                    },
                    {
                        "epoch": 5,
                        "loss": 0.44771219378140703,
                        "accuracy": 0.8257214135580568
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4187784626256281,
                        "accuracy": 0.8377826232148821
                    },
                    {
                        "epoch": 7,
                        "loss": 0.40863497173366836,
                        "accuracy": 0.8383326458050956
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 4.522745253164557,
                        "accuracy": 0.4489,
                        "precision": 0.33804744809388987,
                        "recall": 0.4489,
                        "f1_score": 0.3582529489946963
                    },
                    {
                        "epoch": 2,
                        "loss": 4.546479430379747,
                        "accuracy": 0.4587,
                        "precision": 0.3545227275419619,
                        "recall": 0.4587,
                        "f1_score": 0.36668389403699747
                    },
                    {
                        "epoch": 3,
                        "loss": 4.548259493670886,
                        "accuracy": 0.4495,
                        "precision": 0.3875946951161964,
                        "recall": 0.4495,
                        "f1_score": 0.3539830261112273
                    },
                    {
                        "epoch": 4,
                        "loss": 4.44620253164557,
                        "accuracy": 0.4646,
                        "precision": 0.33123161138253526,
                        "recall": 0.4646,
                        "f1_score": 0.37308139846954264
                    },
                    {
                        "epoch": 5,
                        "loss": 4.640822784810126,
                        "accuracy": 0.4582,
                        "precision": 0.36528468467675895,
                        "recall": 0.4582,
                        "f1_score": 0.3640739208096694
                    },
                    {
                        "epoch": 6,
                        "loss": 4.073378164556962,
                        "accuracy": 0.4688,
                        "precision": 0.35057675208870986,
                        "recall": 0.4688,
                        "f1_score": 0.37538851767770903
                    },
                    {
                        "epoch": 7,
                        "loss": 4.269382911392405,
                        "accuracy": 0.4717,
                        "precision": 0.3472997850952031,
                        "recall": 0.4717,
                        "f1_score": 0.3782001613540029
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.46259251850370076,
                "precision": 0.3380872727258507,
                "recall": 0.46259251850370076,
                "f1_score": 0.37013345843190915
            },
            "confusion_matrix": [
                [
                    2922,
                    411,
                    0
                ],
                [
                    1630,
                    1703,
                    0
                ],
                [
                    2646,
                    686,
                    0
                ]
            ],
            "best_epoch": 7,
            "time_train": 57.02075004577637
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.46259251850370076,
            "accuracy_std": 0.0,
            "precision_mean": 0.3380872727258507,
            "precision_std": 0.0,
            "recall_mean": 0.46259251850370076,
            "recall_std": 0.0,
            "f1_score_mean": 0.37013345843190915,
            "f1_score_std": 0.0,
            "time_train_mean": 57.02075004577637,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_118.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 119,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 16,
                "lora_alpha": 32,
                "lora_dropout": 0.3
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3068418263190955,
                        "accuracy": 0.624707800498949
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7025066739949749,
                        "accuracy": 0.7419608305341112
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5146435301507538,
                        "accuracy": 0.807020645490797
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4709975659547739,
                        "accuracy": 0.8186300508770896
                    },
                    {
                        "epoch": 5,
                        "loss": 0.46135462468592964,
                        "accuracy": 0.8236391851808199
                    },
                    {
                        "epoch": 6,
                        "loss": 0.42790613222361806,
                        "accuracy": 0.8313002141159369
                    },
                    {
                        "epoch": 7,
                        "loss": 0.4246182082286432,
                        "accuracy": 0.83340208615711
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 4.499208860759493,
                        "accuracy": 0.4352,
                        "precision": 0.3924562907188746,
                        "recall": 0.4352,
                        "f1_score": 0.3355246324515343
                    },
                    {
                        "epoch": 2,
                        "loss": 5.803204113924051,
                        "accuracy": 0.4192,
                        "precision": 0.41348375973303675,
                        "recall": 0.4192,
                        "f1_score": 0.3143283925501379
                    },
                    {
                        "epoch": 3,
                        "loss": 5.0765427215189876,
                        "accuracy": 0.4334,
                        "precision": 0.4099985217613782,
                        "recall": 0.4334,
                        "f1_score": 0.3333948768147822
                    },
                    {
                        "epoch": 4,
                        "loss": 4.037974683544304,
                        "accuracy": 0.4664,
                        "precision": 0.33639126441971473,
                        "recall": 0.4664,
                        "f1_score": 0.37338434237750096
                    },
                    {
                        "epoch": 5,
                        "loss": 4.108188291139241,
                        "accuracy": 0.4687,
                        "precision": 0.3379046556129383,
                        "recall": 0.4687,
                        "f1_score": 0.3746000486571654
                    },
                    {
                        "epoch": 6,
                        "loss": 4.454113924050633,
                        "accuracy": 0.4526,
                        "precision": 0.3921632787651751,
                        "recall": 0.4526,
                        "f1_score": 0.3561171271170426
                    },
                    {
                        "epoch": 7,
                        "loss": 4.60185917721519,
                        "accuracy": 0.4529,
                        "precision": 0.39198632775512765,
                        "recall": 0.4529,
                        "f1_score": 0.35625014811889016
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.46129225845169036,
                "precision": 0.3320226952614176,
                "recall": 0.46129225845169036,
                "f1_score": 0.3688880461616627
            },
            "confusion_matrix": [
                [
                    2876,
                    457,
                    0
                ],
                [
                    1597,
                    1736,
                    0
                ],
                [
                    2571,
                    761,
                    0
                ]
            ],
            "best_epoch": 5,
            "time_train": 55.849951922893524
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.46129225845169036,
            "accuracy_std": 0.0,
            "precision_mean": 0.3320226952614176,
            "precision_std": 0.0,
            "recall_mean": 0.46129225845169036,
            "recall_std": 0.0,
            "f1_score_mean": 0.3688880461616627,
            "f1_score_std": 0.0,
            "time_train_mean": 55.849951922893524,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_119.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 127,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=5e-05, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 5e-05\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 5e-05,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2303706030150754,
                        "accuracy": 0.6182646787278763
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7145149576005025,
                        "accuracy": 0.7327086648201623
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5555462861180904,
                        "accuracy": 0.7972184571866344
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4986897377512563,
                        "accuracy": 0.8122851474256978
                    },
                    {
                        "epoch": 5,
                        "loss": 0.46847518844221103,
                        "accuracy": 0.8192193607951755
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4161064109610553,
                        "accuracy": 0.840061288231481
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 2.9485759493670884,
                        "accuracy": 0.4452,
                        "precision": 0.3618526219138341,
                        "recall": 0.4452,
                        "f1_score": 0.3493360222123059
                    },
                    {
                        "epoch": 2,
                        "loss": 3.9519382911392404,
                        "accuracy": 0.4275,
                        "precision": 0.40427165442137325,
                        "recall": 0.4275,
                        "f1_score": 0.32511848505224
                    },
                    {
                        "epoch": 3,
                        "loss": 5.020371835443038,
                        "accuracy": 0.4286,
                        "precision": 0.40828472218128226,
                        "recall": 0.4286,
                        "f1_score": 0.32651692097037033
                    },
                    {
                        "epoch": 4,
                        "loss": 4.282436708860759,
                        "accuracy": 0.438,
                        "precision": 0.4024316648951589,
                        "recall": 0.438,
                        "f1_score": 0.3384615989717031
                    },
                    {
                        "epoch": 5,
                        "loss": 4.243473101265823,
                        "accuracy": 0.459,
                        "precision": 0.3766943216899741,
                        "recall": 0.459,
                        "f1_score": 0.36294753854994344
                    },
                    {
                        "epoch": 6,
                        "loss": 4.6691060126582276,
                        "accuracy": 0.457,
                        "precision": 0.37597083625403055,
                        "recall": 0.457,
                        "f1_score": 0.36100976837691917
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4460892178435687,
                "precision": 0.36339218643192295,
                "recall": 0.4460892178435687,
                "f1_score": 0.3500627126821461
            },
            "confusion_matrix": [
                [
                    3173,
                    160,
                    0
                ],
                [
                    2046,
                    1287,
                    0
                ],
                [
                    2944,
                    388,
                    0
                ]
            ],
            "best_epoch": 5,
            "time_train": 47.339765751361846
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4460892178435687,
            "accuracy_std": 0.0,
            "precision_mean": 0.36339218643192295,
            "precision_std": 0.0,
            "recall_mean": 0.4460892178435687,
            "recall_std": 0.0,
            "f1_score_mean": 0.3500627126821461,
            "f1_score_std": 0.0,
            "time_train_mean": 47.339765751361846,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_127.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=2e-06, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 6,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 2e-06\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 2e-06,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.3
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 3.0598304020100504,
                        "accuracy": 0.5040367729388886
                    },
                    {
                        "epoch": 2,
                        "loss": 1.6485062028894473,
                        "accuracy": 0.5720038501581315
                    },
                    {
                        "epoch": 3,
                        "loss": 1.2205166457286432,
                        "accuracy": 0.6108786610878661
                    },
                    {
                        "epoch": 4,
                        "loss": 1.0481803548994975,
                        "accuracy": 0.6405995246233327
                    },
                    {
                        "epoch": 5,
                        "loss": 0.9461467493718593,
                        "accuracy": 0.6610092914530418
                    },
                    {
                        "epoch": 6,
                        "loss": 0.8947668027638191,
                        "accuracy": 0.669888227552203
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.834256329113924,
                        "accuracy": 0.3764,
                        "precision": 0.3912698089026936,
                        "recall": 0.3764,
                        "f1_score": 0.2862602127044251
                    },
                    {
                        "epoch": 2,
                        "loss": 3.0320411392405062,
                        "accuracy": 0.3821,
                        "precision": 0.42114843862005735,
                        "recall": 0.3821,
                        "f1_score": 0.27613420760961904
                    },
                    {
                        "epoch": 3,
                        "loss": 2.7390229430379747,
                        "accuracy": 0.3961,
                        "precision": 0.48649614639901284,
                        "recall": 0.3961,
                        "f1_score": 0.2904866290568649
                    },
                    {
                        "epoch": 4,
                        "loss": 2.9907041139240507,
                        "accuracy": 0.4021,
                        "precision": 0.5390902053137004,
                        "recall": 0.4021,
                        "f1_score": 0.29535707167925995
                    },
                    {
                        "epoch": 5,
                        "loss": 2.836036392405063,
                        "accuracy": 0.403,
                        "precision": 0.37812849357983963,
                        "recall": 0.403,
                        "f1_score": 0.294729948459187
                    },
                    {
                        "epoch": 6,
                        "loss": 2.964398734177215,
                        "accuracy": 0.4164,
                        "precision": 0.37273420963337583,
                        "recall": 0.4164,
                        "f1_score": 0.3139534773205347
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4118823764752951,
                "precision": 0.36512824139021105,
                "recall": 0.4118823764752951,
                "f1_score": 0.3086474575896749
            },
            "confusion_matrix": [
                [
                    3219,
                    114,
                    0
                ],
                [
                    2434,
                    899,
                    0
                ],
                [
                    3110,
                    222,
                    0
                ]
            ],
            "best_epoch": 6,
            "time_train": 48.6478203813235
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4118823764752951,
            "accuracy_std": 0.0,
            "precision_mean": 0.36512824139021105,
            "precision_std": 0.0,
            "recall_mean": 0.4118823764752951,
            "recall_std": 0.0,
            "f1_score_mean": 0.3086474575896749,
            "f1_score_std": 0.0,
            "time_train_mean": 48.6478203813235,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 5,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 7e-05\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.48441425879397,
                        "accuracy": 0.5947119256683757
                    },
                    {
                        "epoch": 2,
                        "loss": 0.9150881359924623,
                        "accuracy": 0.6904747873573379
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6479418577261307,
                        "accuracy": 0.7629009762900977
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5372124293341709,
                        "accuracy": 0.7982792150391891
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5139540475816583,
                        "accuracy": 0.8088082189089909
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.1969442246835442,
                        "accuracy": 0.5171,
                        "precision": 0.6377034045736706,
                        "recall": 0.5171,
                        "f1_score": 0.49605261429109787
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1126384493670887,
                        "accuracy": 0.6206,
                        "precision": 0.6588259016595713,
                        "recall": 0.6206,
                        "f1_score": 0.6059806210250417
                    },
                    {
                        "epoch": 3,
                        "loss": 1.4042721518987342,
                        "accuracy": 0.5367,
                        "precision": 0.664767897367043,
                        "recall": 0.5367,
                        "f1_score": 0.5163097595621734
                    },
                    {
                        "epoch": 4,
                        "loss": 2.702037183544304,
                        "accuracy": 0.47,
                        "precision": 0.6388078259501913,
                        "recall": 0.47,
                        "f1_score": 0.3876766831561144
                    },
                    {
                        "epoch": 5,
                        "loss": 2.9978243670886076,
                        "accuracy": 0.4512,
                        "precision": 0.7223340390723273,
                        "recall": 0.4512,
                        "f1_score": 0.3635221143081247
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.6045209041808361,
                "precision": 0.6425208678494998,
                "recall": 0.6045209041808361,
                "f1_score": 0.5891711155948574
            },
            "confusion_matrix": [
                [
                    2396,
                    194,
                    743
                ],
                [
                    1471,
                    1133,
                    729
                ],
                [
                    670,
                    147,
                    2515
                ]
            ],
            "best_epoch": 2,
            "time_train": 39.46012598673503
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.6045209041808361,
            "accuracy_std": 0.0,
            "precision_mean": 0.6425208678494998,
            "precision_std": 0.0,
            "recall_mean": 0.6045209041808361,
            "recall_std": 0.0,
            "f1_score_mean": 0.5891711155948574,
            "f1_score_std": 0.0,
            "time_train_mean": 39.46012598673503,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 5,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 0.0007\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.510850149183417,
                        "accuracy": 0.5860097825446402
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7819419362437185,
                        "accuracy": 0.7318443436069696
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5241686950376885,
                        "accuracy": 0.8077867483843086
                    },
                    {
                        "epoch": 4,
                        "loss": 0.4817103093592965,
                        "accuracy": 0.8221462667216689
                    },
                    {
                        "epoch": 5,
                        "loss": 0.46598225502512564,
                        "accuracy": 0.8217730371068812
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.0735759493670887,
                        "accuracy": 0.4883,
                        "precision": 0.593314542152818,
                        "recall": 0.4883,
                        "f1_score": 0.46513155665095074
                    },
                    {
                        "epoch": 2,
                        "loss": 2.0889042721518987,
                        "accuracy": 0.4447,
                        "precision": 0.6409240483520666,
                        "recall": 0.4447,
                        "f1_score": 0.3490890781221964
                    },
                    {
                        "epoch": 3,
                        "loss": 1.9984671677215189,
                        "accuracy": 0.4703,
                        "precision": 0.5945891687059237,
                        "recall": 0.4703,
                        "f1_score": 0.3849425137758923
                    },
                    {
                        "epoch": 4,
                        "loss": 1.6817642405063291,
                        "accuracy": 0.4509,
                        "precision": 0.7155006125358537,
                        "recall": 0.4509,
                        "f1_score": 0.3596606436509035
                    },
                    {
                        "epoch": 5,
                        "loss": 3.5684335443037973,
                        "accuracy": 0.435,
                        "precision": 0.4141194291033199,
                        "recall": 0.435,
                        "f1_score": 0.33543113713971745
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.46819363872774555,
                "precision": 0.563402708753592,
                "recall": 0.46819363872774555,
                "f1_score": 0.4400423576345318
            },
            "confusion_matrix": [
                [
                    2824,
                    104,
                    405
                ],
                [
                    1936,
                    1027,
                    370
                ],
                [
                    2305,
                    197,
                    830
                ]
            ],
            "best_epoch": 1,
            "time_train": 39.09752189715703
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.46819363872774555,
            "accuracy_std": 0.0,
            "precision_mean": 0.563402708753592,
            "precision_std": 0.0,
            "recall_mean": 0.46819363872774555,
            "recall_std": 0.0,
            "f1_score_mean": 0.4400423576345318,
            "f1_score_std": 0.0,
            "time_train_mean": 39.09752189715703,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=2e-07, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 5,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 2e-07\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 2e-07,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 6.089510050251256,
                        "accuracy": 0.5294753177362642
                    },
                    {
                        "epoch": 2,
                        "loss": 3.498979271356784,
                        "accuracy": 0.45755986406584553
                    },
                    {
                        "epoch": 3,
                        "loss": 3.1572510992462313,
                        "accuracy": 0.46502445636160056
                    },
                    {
                        "epoch": 4,
                        "loss": 2.892744974874372,
                        "accuracy": 0.4811715481171548
                    },
                    {
                        "epoch": 5,
                        "loss": 2.715570037688442,
                        "accuracy": 0.49527569882334455
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 6.1534810126582276,
                        "accuracy": 0.3223,
                        "precision": 0.2984819839257164,
                        "recall": 0.3223,
                        "f1_score": 0.2355438925890703
                    },
                    {
                        "epoch": 2,
                        "loss": 5.282634493670886,
                        "accuracy": 0.333,
                        "precision": 0.3161263583153072,
                        "recall": 0.333,
                        "f1_score": 0.26284002597770706
                    },
                    {
                        "epoch": 3,
                        "loss": 5.071004746835443,
                        "accuracy": 0.3443,
                        "precision": 0.33876899536196553,
                        "recall": 0.3443,
                        "f1_score": 0.270174775508431
                    },
                    {
                        "epoch": 4,
                        "loss": 4.658623417721519,
                        "accuracy": 0.3526,
                        "precision": 0.34456345874153194,
                        "recall": 0.3526,
                        "f1_score": 0.28031553817206606
                    },
                    {
                        "epoch": 5,
                        "loss": 4.502966772151899,
                        "accuracy": 0.3575,
                        "precision": 0.34866952801762424,
                        "recall": 0.3575,
                        "f1_score": 0.2798882054214777
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.3477695539107822,
                "precision": 0.33567332734357713,
                "recall": 0.3477695539107822,
                "f1_score": 0.27330532889611275
            },
            "confusion_matrix": [
                [
                    2693,
                    435,
                    205
                ],
                [
                    2469,
                    615,
                    249
                ],
                [
                    2638,
                    525,
                    169
                ]
            ],
            "best_epoch": 4,
            "time_train": 40.84272430340449
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.3477695539107822,
            "accuracy_std": 0.0,
            "precision_mean": 0.33567332734357713,
            "precision_std": 0.0,
            "recall_mean": 0.3477695539107822,
            "recall_std": 0.0,
            "f1_score_mean": 0.27330532889611275,
            "f1_score_std": 0.0,
            "time_train_mean": 40.84272430340449,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0004, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 5,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0004\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0004,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.7402441896984924,
                        "accuracy": 0.5564460683206631
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7845968121859297,
                        "accuracy": 0.7186830887697173
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6596557003768844,
                        "accuracy": 0.7703459249219164
                    },
                    {
                        "epoch": 4,
                        "loss": 1.0221517744974875,
                        "accuracy": 0.7519201681497633
                    },
                    {
                        "epoch": 5,
                        "loss": 0.918753925879397,
                        "accuracy": 0.7437091166244328
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.4901107594936709,
                        "accuracy": 0.5154,
                        "precision": 0.621583573423639,
                        "recall": 0.5154,
                        "f1_score": 0.4992556092763305
                    },
                    {
                        "epoch": 2,
                        "loss": 4.336357792721519,
                        "accuracy": 0.563,
                        "precision": 0.6401981343759977,
                        "recall": 0.563,
                        "f1_score": 0.5370941425682704
                    },
                    {
                        "epoch": 3,
                        "loss": 6.120475672468355,
                        "accuracy": 0.5586,
                        "precision": 0.562751868166885,
                        "recall": 0.5586,
                        "f1_score": 0.5534929176352922
                    },
                    {
                        "epoch": 4,
                        "loss": 10.232199367088608,
                        "accuracy": 0.5233,
                        "precision": 0.5940600108710848,
                        "recall": 0.5233,
                        "f1_score": 0.457690287448528
                    },
                    {
                        "epoch": 5,
                        "loss": 1.4438291139240507,
                        "accuracy": 0.517,
                        "precision": 0.5640554656791438,
                        "recall": 0.517,
                        "f1_score": 0.4905445897385514
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.5618123624724946,
                "precision": 0.5612957562606108,
                "recall": 0.5618123624724946,
                "f1_score": 0.5577035266713977
            },
            "confusion_matrix": [
                [
                    1781,
                    659,
                    893
                ],
                [
                    896,
                    1521,
                    916
                ],
                [
                    368,
                    649,
                    2315
                ]
            ],
            "best_epoch": 3,
            "time_train": 40.35840135018031
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.5618123624724946,
            "accuracy_std": 0.0,
            "precision_mean": 0.5612957562606108,
            "precision_std": 0.0,
            "recall_mean": 0.5618123624724946,
            "recall_std": 0.0,
            "f1_score_mean": 0.5577035266713977,
            "f1_score_std": 0.0,
            "time_train_mean": 40.35840135018031,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0006, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 5,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0006\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0006,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.8142568310301508,
                        "accuracy": 0.5143496965053922
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7795422424623115,
                        "accuracy": 0.7134578741626888
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6396533448492462,
                        "accuracy": 0.7804624118490581
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6200092258165829,
                        "accuracy": 0.7829768008328913
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5863448099874372,
                        "accuracy": 0.7919146679238611
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 0.944620253164557,
                        "accuracy": 0.4697,
                        "precision": 0.5963687314433201,
                        "recall": 0.4697,
                        "f1_score": 0.4709693462466859
                    },
                    {
                        "epoch": 2,
                        "loss": 0.8424643987341772,
                        "accuracy": 0.6873,
                        "precision": 0.7803164261182055,
                        "recall": 0.6873,
                        "f1_score": 0.6449651982120591
                    },
                    {
                        "epoch": 3,
                        "loss": 0.7453520569620253,
                        "accuracy": 0.6964,
                        "precision": 0.7492798785653374,
                        "recall": 0.6964,
                        "f1_score": 0.6757954431536016
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6745945411392406,
                        "accuracy": 0.7155,
                        "precision": 0.779527546520934,
                        "recall": 0.7155,
                        "f1_score": 0.682119561535676
                    },
                    {
                        "epoch": 5,
                        "loss": 0.7138548259493671,
                        "accuracy": 0.7284,
                        "precision": 0.765315018644402,
                        "recall": 0.7284,
                        "f1_score": 0.7091122266177836
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7048409681936387,
                "precision": 0.7392931201365749,
                "recall": 0.7048409681936387,
                "f1_score": 0.6859193210179826
            },
            "confusion_matrix": [
                [
                    2843,
                    177,
                    313
                ],
                [
                    1831,
                    1224,
                    278
                ],
                [
                    230,
                    122,
                    2980
                ]
            ],
            "best_epoch": 5,
            "time_train": 41.94089856147766
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7048409681936387,
            "accuracy_std": 0.0,
            "precision_mean": 0.7392931201365749,
            "precision_std": 0.0,
            "recall_mean": 0.7048409681936387,
            "recall_std": 0.0,
            "f1_score_mean": 0.6859193210179826,
            "f1_score_std": 0.0,
            "time_train_mean": 41.94089856147766,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 5,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.7, 0.75)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3055413787688441,
                        "accuracy": 0.6518553440587739
                    },
                    {
                        "epoch": 2,
                        "loss": 0.5693604742462312,
                        "accuracy": 0.7851965348576817
                    },
                    {
                        "epoch": 3,
                        "loss": 0.49472950690954776,
                        "accuracy": 0.8098493330976093
                    },
                    {
                        "epoch": 4,
                        "loss": 0.45070567682160806,
                        "accuracy": 0.8239927711316715
                    },
                    {
                        "epoch": 5,
                        "loss": 0.42264300015703515,
                        "accuracy": 0.8334217298210462
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.9481803797468353,
                        "accuracy": 0.4299,
                        "precision": 0.6993093901146767,
                        "recall": 0.4299,
                        "f1_score": 0.3367363002542189
                    },
                    {
                        "epoch": 2,
                        "loss": 1.6413172468354431,
                        "accuracy": 0.4704,
                        "precision": 0.6450573021193502,
                        "recall": 0.4704,
                        "f1_score": 0.3832521632187373
                    },
                    {
                        "epoch": 3,
                        "loss": 1.8840981012658229,
                        "accuracy": 0.4836,
                        "precision": 0.6385707384802805,
                        "recall": 0.4836,
                        "f1_score": 0.39368242709488876
                    },
                    {
                        "epoch": 4,
                        "loss": 1.3455300632911393,
                        "accuracy": 0.5172,
                        "precision": 0.6970797196412696,
                        "recall": 0.5172,
                        "f1_score": 0.47100555479591166
                    },
                    {
                        "epoch": 5,
                        "loss": 1.1111550632911393,
                        "accuracy": 0.6131,
                        "precision": 0.7571713659082643,
                        "recall": 0.6131,
                        "f1_score": 0.5993928245250817
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.5882176435287058,
                "precision": 0.7320247458066055,
                "recall": 0.5882176435287058,
                "f1_score": 0.5714302694671115
            },
            "confusion_matrix": [
                [
                    3198,
                    51,
                    84
                ],
                [
                    2231,
                    1023,
                    79
                ],
                [
                    1505,
                    167,
                    1660
                ]
            ],
            "best_epoch": 5,
            "time_train": 41.677318183581036
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.5882176435287058,
            "accuracy_std": 0.0,
            "precision_mean": 0.7320247458066055,
            "precision_std": 0.0,
            "recall_mean": 0.5882176435287058,
            "recall_std": 0.0,
            "f1_score_mean": 0.5714302694671115,
            "f1_score_std": 0.0,
            "time_train_mean": 41.677318183581036,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 5,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.48441425879397,
                        "accuracy": 0.5947119256683757
                    },
                    {
                        "epoch": 2,
                        "loss": 0.9150881359924623,
                        "accuracy": 0.6904747873573379
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6479418577261307,
                        "accuracy": 0.7629009762900977
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5372124293341709,
                        "accuracy": 0.7982792150391891
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5139540475816583,
                        "accuracy": 0.8088082189089909
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.1969442246835442,
                        "accuracy": 0.5171,
                        "precision": 0.6377034045736706,
                        "recall": 0.5171,
                        "f1_score": 0.49605261429109787
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1126384493670887,
                        "accuracy": 0.6206,
                        "precision": 0.6588259016595713,
                        "recall": 0.6206,
                        "f1_score": 0.6059806210250417
                    },
                    {
                        "epoch": 3,
                        "loss": 1.4042721518987342,
                        "accuracy": 0.5367,
                        "precision": 0.664767897367043,
                        "recall": 0.5367,
                        "f1_score": 0.5163097595621734
                    },
                    {
                        "epoch": 4,
                        "loss": 2.702037183544304,
                        "accuracy": 0.47,
                        "precision": 0.6388078259501913,
                        "recall": 0.47,
                        "f1_score": 0.3876766831561144
                    },
                    {
                        "epoch": 5,
                        "loss": 2.9978243670886076,
                        "accuracy": 0.4512,
                        "precision": 0.7223340390723273,
                        "recall": 0.4512,
                        "f1_score": 0.3635221143081247
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.6045209041808361,
                "precision": 0.6425208678494998,
                "recall": 0.6045209041808361,
                "f1_score": 0.5891711155948574
            },
            "confusion_matrix": [
                [
                    2396,
                    194,
                    743
                ],
                [
                    1471,
                    1133,
                    729
                ],
                [
                    670,
                    147,
                    2515
                ]
            ],
            "best_epoch": 2,
            "time_train": 39.741429297129315
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.6045209041808361,
            "accuracy_std": 0.0,
            "precision_mean": 0.6425208678494998,
            "precision_std": 0.0,
            "recall_mean": 0.6045209041808361,
            "recall_std": 0.0,
            "f1_score_mean": 0.5891711155948574,
            "f1_score_std": 0.0,
            "time_train_mean": 39.741429297129315,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0002, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 5,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0002,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.48441425879397,
                        "accuracy": 0.5947119256683757
                    },
                    {
                        "epoch": 2,
                        "loss": 0.9150881359924623,
                        "accuracy": 0.6904747873573379
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6479418577261307,
                        "accuracy": 0.7629009762900977
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5372124293341709,
                        "accuracy": 0.7982792150391891
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5139540475816583,
                        "accuracy": 0.8088082189089909
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.1969442246835442,
                        "accuracy": 0.5171,
                        "precision": 0.6377034045736706,
                        "recall": 0.5171,
                        "f1_score": 0.49605261429109787
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1126384493670887,
                        "accuracy": 0.6206,
                        "precision": 0.6588259016595713,
                        "recall": 0.6206,
                        "f1_score": 0.6059806210250417
                    },
                    {
                        "epoch": 3,
                        "loss": 1.4042721518987342,
                        "accuracy": 0.5367,
                        "precision": 0.664767897367043,
                        "recall": 0.5367,
                        "f1_score": 0.5163097595621734
                    },
                    {
                        "epoch": 4,
                        "loss": 2.702037183544304,
                        "accuracy": 0.47,
                        "precision": 0.6388078259501913,
                        "recall": 0.47,
                        "f1_score": 0.3876766831561144
                    },
                    {
                        "epoch": 5,
                        "loss": 2.9978243670886076,
                        "accuracy": 0.4512,
                        "precision": 0.7223340390723273,
                        "recall": 0.4512,
                        "f1_score": 0.3635221143081247
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.6045209041808361,
                "precision": 0.6425208678494998,
                "recall": 0.6045209041808361,
                "f1_score": 0.5891711155948574
            },
            "confusion_matrix": [
                [
                    2396,
                    194,
                    743
                ],
                [
                    1471,
                    1133,
                    729
                ],
                [
                    670,
                    147,
                    2515
                ]
            ],
            "best_epoch": 2,
            "time_train": 39.65165910720825
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.6045209041808361,
            "accuracy_std": 0.0,
            "precision_mean": 0.6425208678494998,
            "precision_std": 0.0,
            "recall_mean": 0.6045209041808361,
            "recall_std": 0.0,
            "f1_score_mean": 0.5891711155948574,
            "f1_score_std": 0.0,
            "time_train_mean": 39.65165910720825,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=2e-07, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 2e-07\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 2e-07,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 6.089510050251256,
                        "accuracy": 0.5294753177362642
                    },
                    {
                        "epoch": 2,
                        "loss": 3.498979271356784,
                        "accuracy": 0.45755986406584553
                    },
                    {
                        "epoch": 3,
                        "loss": 3.1572510992462313,
                        "accuracy": 0.46502445636160056
                    },
                    {
                        "epoch": 4,
                        "loss": 2.892744974874372,
                        "accuracy": 0.4811715481171548
                    },
                    {
                        "epoch": 5,
                        "loss": 2.715570037688442,
                        "accuracy": 0.49527569882334455
                    },
                    {
                        "epoch": 6,
                        "loss": 2.5985592022613067,
                        "accuracy": 0.5046260828569745
                    },
                    {
                        "epoch": 7,
                        "loss": 2.471674780150754,
                        "accuracy": 0.5144872021529455
                    },
                    {
                        "epoch": 8,
                        "loss": 2.3441229585427137,
                        "accuracy": 0.5210088985797631
                    },
                    {
                        "epoch": 9,
                        "loss": 2.2558004868090453,
                        "accuracy": 0.5252519299899817
                    },
                    {
                        "epoch": 10,
                        "loss": 2.1595673680904524,
                        "accuracy": 0.533050464572652
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 6.1534810126582276,
                        "accuracy": 0.3223,
                        "precision": 0.2984819839257164,
                        "recall": 0.3223,
                        "f1_score": 0.2355438925890703
                    },
                    {
                        "epoch": 2,
                        "loss": 5.282634493670886,
                        "accuracy": 0.333,
                        "precision": 0.3161263583153072,
                        "recall": 0.333,
                        "f1_score": 0.26284002597770706
                    },
                    {
                        "epoch": 3,
                        "loss": 5.071004746835443,
                        "accuracy": 0.3443,
                        "precision": 0.33876899536196553,
                        "recall": 0.3443,
                        "f1_score": 0.270174775508431
                    },
                    {
                        "epoch": 4,
                        "loss": 4.658623417721519,
                        "accuracy": 0.3526,
                        "precision": 0.34456345874153194,
                        "recall": 0.3526,
                        "f1_score": 0.28031553817206606
                    },
                    {
                        "epoch": 5,
                        "loss": 4.502966772151899,
                        "accuracy": 0.3575,
                        "precision": 0.34866952801762424,
                        "recall": 0.3575,
                        "f1_score": 0.2798882054214777
                    },
                    {
                        "epoch": 6,
                        "loss": 4.290545886075949,
                        "accuracy": 0.3639,
                        "precision": 0.36199447878404384,
                        "recall": 0.3639,
                        "f1_score": 0.2863794442775045
                    },
                    {
                        "epoch": 7,
                        "loss": 4.188488924050633,
                        "accuracy": 0.3669,
                        "precision": 0.3665015218966377,
                        "recall": 0.3669,
                        "f1_score": 0.28703311853319674
                    },
                    {
                        "epoch": 8,
                        "loss": 4.206685126582278,
                        "accuracy": 0.3675,
                        "precision": 0.36198240912024343,
                        "recall": 0.3675,
                        "f1_score": 0.2845175592886521
                    },
                    {
                        "epoch": 9,
                        "loss": 3.9040743670886076,
                        "accuracy": 0.3712,
                        "precision": 0.36817444024671087,
                        "recall": 0.3712,
                        "f1_score": 0.2877391886866314
                    },
                    {
                        "epoch": 10,
                        "loss": 3.7943037974683542,
                        "accuracy": 0.3739,
                        "precision": 0.3699215354133618,
                        "recall": 0.3739,
                        "f1_score": 0.29048042211815184
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.3726745349069814,
                "precision": 0.3744258677107165,
                "recall": 0.3726745349069814,
                "f1_score": 0.2903752935073414
            },
            "confusion_matrix": [
                [
                    2806,
                    439,
                    88
                ],
                [
                    2406,
                    825,
                    102
                ],
                [
                    2582,
                    655,
                    95
                ]
            ],
            "best_epoch": 10,
            "time_train": 82.40261558294296
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.3726745349069814,
            "accuracy_std": 0.0,
            "precision_mean": 0.3744258677107165,
            "precision_std": 0.0,
            "recall_mean": 0.3726745349069814,
            "recall_std": 0.0,
            "f1_score_mean": 0.2903752935073414,
            "f1_score_std": 0.0,
            "time_train_mean": 82.40261558294296,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0006, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0006\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0006,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.8142568310301508,
                        "accuracy": 0.5143496965053922
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7795422424623115,
                        "accuracy": 0.7134578741626888
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6396533448492462,
                        "accuracy": 0.7804624118490581
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6200092258165829,
                        "accuracy": 0.7829768008328913
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5863448099874372,
                        "accuracy": 0.7919146679238611
                    },
                    {
                        "epoch": 6,
                        "loss": 0.5699493561557789,
                        "accuracy": 0.7971988135226983
                    },
                    {
                        "epoch": 7,
                        "loss": 0.529998625942211,
                        "accuracy": 0.8102618500402695
                    },
                    {
                        "epoch": 8,
                        "loss": 0.5119690248115578,
                        "accuracy": 0.8153692026636808
                    },
                    {
                        "epoch": 9,
                        "loss": 0.4959269001256281,
                        "accuracy": 0.8186300508770896
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4869268216080402,
                        "accuracy": 0.8210855088691142
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 0.944620253164557,
                        "accuracy": 0.4697,
                        "precision": 0.5963687314433201,
                        "recall": 0.4697,
                        "f1_score": 0.4709693462466859
                    },
                    {
                        "epoch": 2,
                        "loss": 0.8424643987341772,
                        "accuracy": 0.6873,
                        "precision": 0.7803164261182055,
                        "recall": 0.6873,
                        "f1_score": 0.6449651982120591
                    },
                    {
                        "epoch": 3,
                        "loss": 0.7453520569620253,
                        "accuracy": 0.6964,
                        "precision": 0.7492798785653374,
                        "recall": 0.6964,
                        "f1_score": 0.6757954431536016
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6745945411392406,
                        "accuracy": 0.7155,
                        "precision": 0.779527546520934,
                        "recall": 0.7155,
                        "f1_score": 0.682119561535676
                    },
                    {
                        "epoch": 5,
                        "loss": 0.7138548259493671,
                        "accuracy": 0.7284,
                        "precision": 0.765315018644402,
                        "recall": 0.7284,
                        "f1_score": 0.7091122266177836
                    },
                    {
                        "epoch": 6,
                        "loss": 0.8735166139240507,
                        "accuracy": 0.6845,
                        "precision": 0.7561430817229436,
                        "recall": 0.6845,
                        "f1_score": 0.6703978745485104
                    },
                    {
                        "epoch": 7,
                        "loss": 0.8443433544303798,
                        "accuracy": 0.6727,
                        "precision": 0.7655399577826613,
                        "recall": 0.6727,
                        "f1_score": 0.6504581915834136
                    },
                    {
                        "epoch": 8,
                        "loss": 0.7093057753164557,
                        "accuracy": 0.7183,
                        "precision": 0.7883843507097775,
                        "recall": 0.7183,
                        "f1_score": 0.6883460016818904
                    },
                    {
                        "epoch": 9,
                        "loss": 0.7490605221518988,
                        "accuracy": 0.6809,
                        "precision": 0.7721795018731556,
                        "recall": 0.6809,
                        "f1_score": 0.6693546429318754
                    },
                    {
                        "epoch": 10,
                        "loss": 0.6742978639240507,
                        "accuracy": 0.721,
                        "precision": 0.7517897172328459,
                        "recall": 0.721,
                        "f1_score": 0.7093678184788054
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7016403280656132,
                "precision": 0.7317029867283175,
                "recall": 0.7016403280656132,
                "f1_score": 0.6905125940412278
            },
            "confusion_matrix": [
                [
                    2839,
                    221,
                    273
                ],
                [
                    1776,
                    1372,
                    185
                ],
                [
                    315,
                    213,
                    2804
                ]
            ],
            "best_epoch": 10,
            "time_train": 80.92233745654424
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7016403280656132,
            "accuracy_std": 0.0,
            "precision_mean": 0.7317029867283175,
            "precision_std": 0.0,
            "recall_mean": 0.7016403280656132,
            "recall_std": 0.0,
            "f1_score_mean": 0.6905125940412278,
            "f1_score_std": 0.0,
            "time_train_mean": 80.92233745654424,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0007, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0007\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0007,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.6771454930904524,
                        "accuracy": 0.5232482762684896
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7500098146984925,
                        "accuracy": 0.7041074901290588
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5712448963567839,
                        "accuracy": 0.7890859803170487
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5210770650125628,
                        "accuracy": 0.8101832753845247
                    },
                    {
                        "epoch": 5,
                        "loss": 0.48072883951005024,
                        "accuracy": 0.8232855992299684
                    },
                    {
                        "epoch": 6,
                        "loss": 0.5129946608040201,
                        "accuracy": 0.8149566857210206
                    },
                    {
                        "epoch": 7,
                        "loss": 0.47015840923366836,
                        "accuracy": 0.8248178050169918
                    },
                    {
                        "epoch": 8,
                        "loss": 0.43954636463567837,
                        "accuracy": 0.8339913960751959
                    },
                    {
                        "epoch": 9,
                        "loss": 0.4448904679648241,
                        "accuracy": 0.8324788339521088
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4362535332914573,
                        "accuracy": 0.8348557172883886
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.4729034810126582,
                        "accuracy": 0.362,
                        "precision": 0.4266584367906516,
                        "recall": 0.362,
                        "f1_score": 0.2241668483686879
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1377571202531647,
                        "accuracy": 0.4083,
                        "precision": 0.7027508338544387,
                        "recall": 0.4083,
                        "f1_score": 0.30588834988106756
                    },
                    {
                        "epoch": 3,
                        "loss": 1.159612341772152,
                        "accuracy": 0.4432,
                        "precision": 0.7046758251214505,
                        "recall": 0.4432,
                        "f1_score": 0.35504415252875804
                    },
                    {
                        "epoch": 4,
                        "loss": 2.1750395569620253,
                        "accuracy": 0.4584,
                        "precision": 0.7089349369461223,
                        "recall": 0.4584,
                        "f1_score": 0.36520421013488674
                    },
                    {
                        "epoch": 5,
                        "loss": 2.556368670886076,
                        "accuracy": 0.4555,
                        "precision": 0.7133514086221501,
                        "recall": 0.4555,
                        "f1_score": 0.3623719188788685
                    },
                    {
                        "epoch": 6,
                        "loss": 3.037974683544304,
                        "accuracy": 0.4336,
                        "precision": 0.4089074682989375,
                        "recall": 0.4336,
                        "f1_score": 0.33312001648921996
                    },
                    {
                        "epoch": 7,
                        "loss": 2.4138647151898733,
                        "accuracy": 0.4502,
                        "precision": 0.7350144014328235,
                        "recall": 0.4502,
                        "f1_score": 0.3542578957644899
                    },
                    {
                        "epoch": 8,
                        "loss": 3.4318631329113924,
                        "accuracy": 0.4486,
                        "precision": 0.3983454028554037,
                        "recall": 0.4486,
                        "f1_score": 0.35168082359413927
                    },
                    {
                        "epoch": 9,
                        "loss": 2.3961629746835444,
                        "accuracy": 0.4702,
                        "precision": 0.3471111343568602,
                        "recall": 0.4702,
                        "f1_score": 0.3748803915817579
                    },
                    {
                        "epoch": 10,
                        "loss": 2.9787381329113924,
                        "accuracy": 0.4733,
                        "precision": 0.6769151309755227,
                        "recall": 0.4733,
                        "f1_score": 0.3779875997070042
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.46129225845169036,
                "precision": 0.6292749996788726,
                "recall": 0.46129225845169036,
                "f1_score": 0.36794955862790385
            },
            "confusion_matrix": [
                [
                    2958,
                    374,
                    1
                ],
                [
                    1687,
                    1646,
                    0
                ],
                [
                    2542,
                    782,
                    8
                ]
            ],
            "best_epoch": 10,
            "time_train": 80.87376211881637
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.46129225845169036,
            "accuracy_std": 0.0,
            "precision_mean": 0.6292749996788726,
            "precision_std": 0.0,
            "recall_mean": 0.46129225845169036,
            "recall_std": 0.0,
            "f1_score_mean": 0.36794955862790385,
            "f1_score_std": 0.0,
            "time_train_mean": 80.87376211881637,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0005, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0005,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 6,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.5467228721733668,
                        "accuracy": 0.5762665252322863
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6345497016331658,
                        "accuracy": 0.7667511344215923
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5104624685929648,
                        "accuracy": 0.8011275463099378
                    },
                    {
                        "epoch": 4,
                        "loss": 0.48734885364321606,
                        "accuracy": 0.8131298249749543
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4776298484610553,
                        "accuracy": 0.8180210972950674
                    },
                    {
                        "epoch": 6,
                        "loss": 0.42454459798994976,
                        "accuracy": 0.8339521087473235
                    },
                    {
                        "epoch": 7,
                        "loss": 0.4028786510678392,
                        "accuracy": 0.8419667236332921
                    },
                    {
                        "epoch": 8,
                        "loss": 0.3928799269786432,
                        "accuracy": 0.842850688510421
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.1699960443037976,
                        "accuracy": 0.5743,
                        "precision": 0.7420253649922397,
                        "recall": 0.5743,
                        "f1_score": 0.5589018453478344
                    },
                    {
                        "epoch": 2,
                        "loss": 1.9245450949367089,
                        "accuracy": 0.4384,
                        "precision": 0.7513081947635519,
                        "recall": 0.4384,
                        "f1_score": 0.36170447832392444
                    },
                    {
                        "epoch": 3,
                        "loss": 0.8017701740506329,
                        "accuracy": 0.7234,
                        "precision": 0.7928089638229308,
                        "recall": 0.7234,
                        "f1_score": 0.7073929737179883
                    },
                    {
                        "epoch": 4,
                        "loss": 0.7077976661392406,
                        "accuracy": 0.7085,
                        "precision": 0.8033609222348138,
                        "recall": 0.7085,
                        "f1_score": 0.686074373988381
                    },
                    {
                        "epoch": 5,
                        "loss": 0.9363132911392406,
                        "accuracy": 0.6343,
                        "precision": 0.7471549836520655,
                        "recall": 0.6343,
                        "f1_score": 0.6324573002912722
                    },
                    {
                        "epoch": 6,
                        "loss": 0.9221222310126582,
                        "accuracy": 0.6166,
                        "precision": 0.761864317201765,
                        "recall": 0.6166,
                        "f1_score": 0.6049926269613798
                    },
                    {
                        "epoch": 7,
                        "loss": 1.4779964398734178,
                        "accuracy": 0.5042,
                        "precision": 0.71613507194686,
                        "recall": 0.5042,
                        "f1_score": 0.4509519793397687
                    },
                    {
                        "epoch": 8,
                        "loss": 0.8983386075949367,
                        "accuracy": 0.6498,
                        "precision": 0.7623466796258751,
                        "recall": 0.6498,
                        "f1_score": 0.6473629805257036
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.6990398079615923,
                "precision": 0.7678223770354463,
                "recall": 0.6990398079615923,
                "f1_score": 0.6829976543014531
            },
            "confusion_matrix": [
                [
                    3020,
                    112,
                    201
                ],
                [
                    1976,
                    1189,
                    168
                ],
                [
                    486,
                    66,
                    2780
                ]
            ],
            "best_epoch": 3,
            "time_train": 62.632736972967784
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.6990398079615923,
            "accuracy_std": 0.0,
            "precision_mean": 0.7678223770354463,
            "precision_std": 0.0,
            "recall_mean": 0.6990398079615923,
            "recall_std": 0.0,
            "f1_score_mean": 0.6829976543014531,
            "f1_score_std": 0.0,
            "time_train_mean": 62.632736972967784,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0006, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0006\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0006,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 10,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.7456324591708543,
                        "accuracy": 0.5032117390535683
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1945763976130652,
                        "accuracy": 0.6191093562771328
                    },
                    {
                        "epoch": 3,
                        "loss": 0.9733187421482412,
                        "accuracy": 0.6760759816921053
                    },
                    {
                        "epoch": 4,
                        "loss": 0.7154964274497487,
                        "accuracy": 0.7480503663543324
                    },
                    {
                        "epoch": 5,
                        "loss": 0.9369356548366834,
                        "accuracy": 0.6877639617341427
                    },
                    {
                        "epoch": 6,
                        "loss": 0.8244346733668342,
                        "accuracy": 0.731392539336437
                    },
                    {
                        "epoch": 7,
                        "loss": 0.5685556689698492,
                        "accuracy": 0.7925432651698194
                    },
                    {
                        "epoch": 8,
                        "loss": 0.5234522220477387,
                        "accuracy": 0.8073545877777123
                    },
                    {
                        "epoch": 9,
                        "loss": 0.5020218278894473,
                        "accuracy": 0.8132869742864439
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4882321765075377,
                        "accuracy": 0.816881764786768
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.1461629746835442,
                        "accuracy": 0.4359,
                        "precision": 0.5166646127895083,
                        "recall": 0.4359,
                        "f1_score": 0.39852346678543693
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1276206487341771,
                        "accuracy": 0.6178,
                        "precision": 0.6895791939449809,
                        "recall": 0.6178,
                        "f1_score": 0.5909974130936738
                    },
                    {
                        "epoch": 3,
                        "loss": 0.8671875,
                        "accuracy": 0.6302,
                        "precision": 0.7086963626658337,
                        "recall": 0.6302,
                        "f1_score": 0.6209216273198979
                    },
                    {
                        "epoch": 4,
                        "loss": 0.757120253164557,
                        "accuracy": 0.7194,
                        "precision": 0.7846978842303659,
                        "recall": 0.7194,
                        "f1_score": 0.6869751455809826
                    },
                    {
                        "epoch": 5,
                        "loss": 1.4844738924050633,
                        "accuracy": 0.4633,
                        "precision": 0.6023394211524404,
                        "recall": 0.4633,
                        "f1_score": 0.3698692385568858
                    },
                    {
                        "epoch": 6,
                        "loss": 0.6547913370253164,
                        "accuracy": 0.7187,
                        "precision": 0.735907763208921,
                        "recall": 0.7187,
                        "f1_score": 0.7175702179605316
                    },
                    {
                        "epoch": 7,
                        "loss": 0.7464151503164557,
                        "accuracy": 0.6944,
                        "precision": 0.7843418286418558,
                        "recall": 0.6944,
                        "f1_score": 0.6789735056226431
                    },
                    {
                        "epoch": 8,
                        "loss": 0.6527887658227848,
                        "accuracy": 0.7166,
                        "precision": 0.7891817163043576,
                        "recall": 0.7166,
                        "f1_score": 0.6974530470963152
                    },
                    {
                        "epoch": 9,
                        "loss": 0.6284612341772152,
                        "accuracy": 0.7316,
                        "precision": 0.7787758955539426,
                        "recall": 0.7316,
                        "f1_score": 0.7152605591176286
                    },
                    {
                        "epoch": 10,
                        "loss": 1.0141416139240507,
                        "accuracy": 0.539,
                        "precision": 0.7345270668955167,
                        "recall": 0.539,
                        "f1_score": 0.5108039803649651
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.6948389677935587,
                "precision": 0.7128592350633396,
                "recall": 0.6948389677935587,
                "f1_score": 0.6933054300442737
            },
            "confusion_matrix": [
                [
                    2563,
                    524,
                    246
                ],
                [
                    1462,
                    1681,
                    190
                ],
                [
                    448,
                    181,
                    2703
                ]
            ],
            "best_epoch": 6,
            "time_train": 79.02585374514261
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.6948389677935587,
            "accuracy_std": 0.0,
            "precision_mean": 0.7128592350633396,
            "precision_std": 0.0,
            "recall_mean": 0.6948389677935587,
            "recall_std": 0.0,
            "f1_score_mean": 0.6933054300442737,
            "f1_score_std": 0.0,
            "time_train_mean": 79.02585374514261,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 130,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0006, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0006\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0006,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 32,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.522441308103015,
                        "accuracy": 0.5697055414775964
                    },
                    {
                        "epoch": 2,
                        "loss": 0.6200926507537688,
                        "accuracy": 0.7739407154222405
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5113016253140703,
                        "accuracy": 0.8109886656059088
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6508077496859297,
                        "accuracy": 0.7631956312491406
                    },
                    {
                        "epoch": 5,
                        "loss": 1.3087900439698492,
                        "accuracy": 0.5914314337910307
                    },
                    {
                        "epoch": 6,
                        "loss": 1.1204312578517588,
                        "accuracy": 0.6793761172333864
                    },
                    {
                        "epoch": 7,
                        "loss": 0.539592493718593,
                        "accuracy": 0.7990846052605732
                    },
                    {
                        "epoch": 8,
                        "loss": 0.49111769786432163,
                        "accuracy": 0.8153299153358085
                    },
                    {
                        "epoch": 9,
                        "loss": 0.5013249842964824,
                        "accuracy": 0.8139548588602746
                    },
                    {
                        "epoch": 10,
                        "loss": 0.46688029993718594,
                        "accuracy": 0.8247588740251832
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.7790743670886076,
                        "accuracy": 0.39,
                        "precision": 0.39862924959879636,
                        "recall": 0.39,
                        "f1_score": 0.2711407921715082
                    },
                    {
                        "epoch": 2,
                        "loss": 3.5765427215189876,
                        "accuracy": 0.4144,
                        "precision": 0.4056780610962993,
                        "recall": 0.4144,
                        "f1_score": 0.3075004862917697
                    },
                    {
                        "epoch": 3,
                        "loss": 2.5056368670886076,
                        "accuracy": 0.4504,
                        "precision": 0.38657545249081365,
                        "recall": 0.4504,
                        "f1_score": 0.3533606309076611
                    },
                    {
                        "epoch": 4,
                        "loss": 1.1153085443037976,
                        "accuracy": 0.4355,
                        "precision": 0.5742697754375993,
                        "recall": 0.4355,
                        "f1_score": 0.3490311343035616
                    },
                    {
                        "epoch": 5,
                        "loss": 2.9244462025316458,
                        "accuracy": 0.4598,
                        "precision": 0.3785104896267683,
                        "recall": 0.4598,
                        "f1_score": 0.3670863266991525
                    },
                    {
                        "epoch": 6,
                        "loss": 3.5905854430379747,
                        "accuracy": 0.4621,
                        "precision": 0.36062049107829786,
                        "recall": 0.4621,
                        "f1_score": 0.36980167972797856
                    },
                    {
                        "epoch": 7,
                        "loss": 4.762460443037975,
                        "accuracy": 0.4626,
                        "precision": 0.35877674416361033,
                        "recall": 0.4626,
                        "f1_score": 0.37166337002282274
                    },
                    {
                        "epoch": 8,
                        "loss": 3.489814082278481,
                        "accuracy": 0.4482,
                        "precision": 0.4015792715121794,
                        "recall": 0.4482,
                        "f1_score": 0.3519665783977233
                    },
                    {
                        "epoch": 9,
                        "loss": 4.277689873417722,
                        "accuracy": 0.463,
                        "precision": 0.37152967304494033,
                        "recall": 0.463,
                        "f1_score": 0.36947823890394427
                    },
                    {
                        "epoch": 10,
                        "loss": 4.442840189873418,
                        "accuracy": 0.4528,
                        "precision": 0.3930824899111064,
                        "recall": 0.4528,
                        "f1_score": 0.3566215817335506
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.4558911782356471,
                "precision": 0.35121559302459066,
                "recall": 0.4558911782356471,
                "f1_score": 0.365294595147457
            },
            "confusion_matrix": [
                [
                    2987,
                    346,
                    0
                ],
                [
                    1762,
                    1571,
                    0
                ],
                [
                    2875,
                    457,
                    0
                ]
            ],
            "best_epoch": 7,
            "time_train": 80.62956929604212
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.4558911782356471,
            "accuracy_std": 0.0,
            "precision_mean": 0.35121559302459066,
            "precision_std": 0.0,
            "recall_mean": 0.4558911782356471,
            "recall_std": 0.0,
            "f1_score_mean": 0.365294595147457,
            "f1_score_std": 0.0,
            "time_train_mean": 80.62956929604212,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_130.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0006, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0006\n    maximize: False\n    weight_decay: 3e-05\n)",
                "learning_rate": 0.0006,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.8142568310301508,
                        "accuracy": 0.5143496965053922
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7795422424623115,
                        "accuracy": 0.7134578741626888
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6396533448492462,
                        "accuracy": 0.7804624118490581
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6200092258165829,
                        "accuracy": 0.7829768008328913
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5863448099874372,
                        "accuracy": 0.7919146679238611
                    },
                    {
                        "epoch": 6,
                        "loss": 0.5699493561557789,
                        "accuracy": 0.7971988135226983
                    },
                    {
                        "epoch": 7,
                        "loss": 0.529998625942211,
                        "accuracy": 0.8102618500402695
                    },
                    {
                        "epoch": 8,
                        "loss": 0.5119690248115578,
                        "accuracy": 0.8153692026636808
                    },
                    {
                        "epoch": 9,
                        "loss": 0.4959269001256281,
                        "accuracy": 0.8186300508770896
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4869268216080402,
                        "accuracy": 0.8210855088691142
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 0.944620253164557,
                        "accuracy": 0.4697,
                        "precision": 0.5963687314433201,
                        "recall": 0.4697,
                        "f1_score": 0.4709693462466859
                    },
                    {
                        "epoch": 2,
                        "loss": 0.8424643987341772,
                        "accuracy": 0.6873,
                        "precision": 0.7803164261182055,
                        "recall": 0.6873,
                        "f1_score": 0.6449651982120591
                    },
                    {
                        "epoch": 3,
                        "loss": 0.7453520569620253,
                        "accuracy": 0.6964,
                        "precision": 0.7492798785653374,
                        "recall": 0.6964,
                        "f1_score": 0.6757954431536016
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6745945411392406,
                        "accuracy": 0.7155,
                        "precision": 0.779527546520934,
                        "recall": 0.7155,
                        "f1_score": 0.682119561535676
                    },
                    {
                        "epoch": 5,
                        "loss": 0.7138548259493671,
                        "accuracy": 0.7284,
                        "precision": 0.765315018644402,
                        "recall": 0.7284,
                        "f1_score": 0.7091122266177836
                    },
                    {
                        "epoch": 6,
                        "loss": 0.8735166139240507,
                        "accuracy": 0.6845,
                        "precision": 0.7561430817229436,
                        "recall": 0.6845,
                        "f1_score": 0.6703978745485104
                    },
                    {
                        "epoch": 7,
                        "loss": 0.8443433544303798,
                        "accuracy": 0.6727,
                        "precision": 0.7655399577826613,
                        "recall": 0.6727,
                        "f1_score": 0.6504581915834136
                    },
                    {
                        "epoch": 8,
                        "loss": 0.7093057753164557,
                        "accuracy": 0.7183,
                        "precision": 0.7883843507097775,
                        "recall": 0.7183,
                        "f1_score": 0.6883460016818904
                    },
                    {
                        "epoch": 9,
                        "loss": 0.7490605221518988,
                        "accuracy": 0.6809,
                        "precision": 0.7721795018731556,
                        "recall": 0.6809,
                        "f1_score": 0.6693546429318754
                    },
                    {
                        "epoch": 10,
                        "loss": 0.6742978639240507,
                        "accuracy": 0.721,
                        "precision": 0.7517897172328459,
                        "recall": 0.721,
                        "f1_score": 0.7093678184788054
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7016403280656132,
                "precision": 0.7317029867283175,
                "recall": 0.7016403280656132,
                "f1_score": 0.6905125940412278
            },
            "confusion_matrix": [
                [
                    2839,
                    221,
                    273
                ],
                [
                    1776,
                    1372,
                    185
                ],
                [
                    315,
                    213,
                    2804
                ]
            ],
            "best_epoch": 10,
            "time_train": 80.78556125958761
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7016403280656132,
            "accuracy_std": 0.0,
            "precision_mean": 0.7317029867283175,
            "precision_std": 0.0,
            "recall_mean": 0.7016403280656132,
            "recall_std": 0.0,
            "f1_score_mean": 0.6905125940412278,
            "f1_score_std": 0.0,
            "time_train_mean": 80.78556125958761,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 125,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0006, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0006\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0006,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.7497251884422111,
                        "accuracy": 0.49132732237216886
                    },
                    {
                        "epoch": 2,
                        "loss": 1.3442554569723617,
                        "accuracy": 0.5981888541850826
                    },
                    {
                        "epoch": 3,
                        "loss": 1.0821931925251256,
                        "accuracy": 0.6380851356394995
                    },
                    {
                        "epoch": 4,
                        "loss": 0.9106322628768844,
                        "accuracy": 0.697742943013731
                    },
                    {
                        "epoch": 5,
                        "loss": 0.8584769550879398,
                        "accuracy": 0.7158740448268411
                    },
                    {
                        "epoch": 6,
                        "loss": 0.9666840059673367,
                        "accuracy": 0.6269078908598031
                    },
                    {
                        "epoch": 7,
                        "loss": 0.8013848539572864,
                        "accuracy": 0.6694364232816705
                    },
                    {
                        "epoch": 8,
                        "loss": 0.6551458464195979,
                        "accuracy": 0.7639224468147799
                    },
                    {
                        "epoch": 9,
                        "loss": 0.5912570665829145,
                        "accuracy": 0.7843715009723614
                    },
                    {
                        "epoch": 10,
                        "loss": 0.571544244660804,
                        "accuracy": 0.7947629991946098
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.5805478639240507,
                        "accuracy": 0.5255,
                        "precision": 0.34659547999981927,
                        "recall": 0.5255,
                        "f1_score": 0.4133055829129364
                    },
                    {
                        "epoch": 2,
                        "loss": 1.2114319620253164,
                        "accuracy": 0.5116,
                        "precision": 0.6661614468041657,
                        "recall": 0.5116,
                        "f1_score": 0.4846284653066602
                    },
                    {
                        "epoch": 3,
                        "loss": 0.8798951740506329,
                        "accuracy": 0.6156,
                        "precision": 0.6361907448385485,
                        "recall": 0.6156,
                        "f1_score": 0.6133072940994021
                    },
                    {
                        "epoch": 4,
                        "loss": 1.0157733386075949,
                        "accuracy": 0.6382,
                        "precision": 0.6394927378006987,
                        "recall": 0.6382,
                        "f1_score": 0.6238083783053869
                    },
                    {
                        "epoch": 5,
                        "loss": 0.825751582278481,
                        "accuracy": 0.6861,
                        "precision": 0.6819361141724919,
                        "recall": 0.6861,
                        "f1_score": 0.6818631283237732
                    },
                    {
                        "epoch": 6,
                        "loss": 0.9482298259493671,
                        "accuracy": 0.5637,
                        "precision": 0.6896764405786533,
                        "recall": 0.5637,
                        "f1_score": 0.5445985815706844
                    },
                    {
                        "epoch": 7,
                        "loss": 0.9362638449367089,
                        "accuracy": 0.615,
                        "precision": 0.7345369055390605,
                        "recall": 0.615,
                        "f1_score": 0.6053441776572489
                    },
                    {
                        "epoch": 8,
                        "loss": 0.8712420886075949,
                        "accuracy": 0.7201,
                        "precision": 0.7660645957975767,
                        "recall": 0.7201,
                        "f1_score": 0.6963481742992159
                    },
                    {
                        "epoch": 9,
                        "loss": 0.6995401503164557,
                        "accuracy": 0.7183,
                        "precision": 0.7725302181501771,
                        "recall": 0.7183,
                        "f1_score": 0.6977067242012593
                    },
                    {
                        "epoch": 10,
                        "loss": 0.7126433939873418,
                        "accuracy": 0.7254,
                        "precision": 0.7744431953157672,
                        "recall": 0.7254,
                        "f1_score": 0.6977190995294874
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7039407881576315,
                "precision": 0.7529717835362995,
                "recall": 0.7039407881576315,
                "f1_score": 0.6733576840485577
            },
            "confusion_matrix": [
                [
                    2770,
                    97,
                    466
                ],
                [
                    1827,
                    1059,
                    447
                ],
                [
                    88,
                    35,
                    3209
                ]
            ],
            "best_epoch": 10,
            "time_train": 81.99086016813914
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7039407881576315,
            "accuracy_std": 0.0,
            "precision_mean": 0.7529717835362995,
            "precision_std": 0.0,
            "recall_mean": 0.7039407881576315,
            "recall_std": 0.0,
            "f1_score_mean": 0.6733576840485577,
            "f1_score_std": 0.0,
            "time_train_mean": 81.99086016813914,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_125.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 135,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0006, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0006\n    maximize: False\n    weight_decay: 1e-06\n)",
                "learning_rate": 0.0006,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.8142568310301508,
                        "accuracy": 0.5143496965053922
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7795422424623115,
                        "accuracy": 0.7134578741626888
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6396533448492462,
                        "accuracy": 0.7804624118490581
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6200092258165829,
                        "accuracy": 0.7829768008328913
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5863448099874372,
                        "accuracy": 0.7919146679238611
                    },
                    {
                        "epoch": 6,
                        "loss": 0.5699493561557789,
                        "accuracy": 0.7971988135226983
                    },
                    {
                        "epoch": 7,
                        "loss": 0.529998625942211,
                        "accuracy": 0.8102618500402695
                    },
                    {
                        "epoch": 8,
                        "loss": 0.5119690248115578,
                        "accuracy": 0.8153692026636808
                    },
                    {
                        "epoch": 9,
                        "loss": 0.4959269001256281,
                        "accuracy": 0.8186300508770896
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4869268216080402,
                        "accuracy": 0.8210855088691142
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 0.944620253164557,
                        "accuracy": 0.4697,
                        "precision": 0.5963687314433201,
                        "recall": 0.4697,
                        "f1_score": 0.4709693462466859
                    },
                    {
                        "epoch": 2,
                        "loss": 0.8424643987341772,
                        "accuracy": 0.6873,
                        "precision": 0.7803164261182055,
                        "recall": 0.6873,
                        "f1_score": 0.6449651982120591
                    },
                    {
                        "epoch": 3,
                        "loss": 0.7453520569620253,
                        "accuracy": 0.6964,
                        "precision": 0.7492798785653374,
                        "recall": 0.6964,
                        "f1_score": 0.6757954431536016
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6745945411392406,
                        "accuracy": 0.7155,
                        "precision": 0.779527546520934,
                        "recall": 0.7155,
                        "f1_score": 0.682119561535676
                    },
                    {
                        "epoch": 5,
                        "loss": 0.7138548259493671,
                        "accuracy": 0.7284,
                        "precision": 0.765315018644402,
                        "recall": 0.7284,
                        "f1_score": 0.7091122266177836
                    },
                    {
                        "epoch": 6,
                        "loss": 0.8735166139240507,
                        "accuracy": 0.6845,
                        "precision": 0.7561430817229436,
                        "recall": 0.6845,
                        "f1_score": 0.6703978745485104
                    },
                    {
                        "epoch": 7,
                        "loss": 0.8443433544303798,
                        "accuracy": 0.6727,
                        "precision": 0.7655399577826613,
                        "recall": 0.6727,
                        "f1_score": 0.6504581915834136
                    },
                    {
                        "epoch": 8,
                        "loss": 0.7093057753164557,
                        "accuracy": 0.7183,
                        "precision": 0.7883843507097775,
                        "recall": 0.7183,
                        "f1_score": 0.6883460016818904
                    },
                    {
                        "epoch": 9,
                        "loss": 0.7490605221518988,
                        "accuracy": 0.6809,
                        "precision": 0.7721795018731556,
                        "recall": 0.6809,
                        "f1_score": 0.6693546429318754
                    },
                    {
                        "epoch": 10,
                        "loss": 0.6742978639240507,
                        "accuracy": 0.721,
                        "precision": 0.7517897172328459,
                        "recall": 0.721,
                        "f1_score": 0.7093678184788054
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7016403280656132,
                "precision": 0.7317029867283175,
                "recall": 0.7016403280656132,
                "f1_score": 0.6905125940412278
            },
            "confusion_matrix": [
                [
                    2839,
                    221,
                    273
                ],
                [
                    1776,
                    1372,
                    185
                ],
                [
                    315,
                    213,
                    2804
                ]
            ],
            "best_epoch": 10,
            "time_train": 80.07809558312098
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7016403280656132,
            "accuracy_std": 0.0,
            "precision_mean": 0.7317029867283175,
            "precision_std": 0.0,
            "recall_mean": 0.7016403280656132,
            "recall_std": 0.0,
            "f1_score_mean": 0.6905125940412278,
            "f1_score_std": 0.0,
            "time_train_mean": 80.07809558312098,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_135.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 136,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0006, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0006\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0006,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 2,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.6277873743718594,
                        "accuracy": 0.512542479423262
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7579597204773869,
                        "accuracy": 0.7107666922034298
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5914337311557789,
                        "accuracy": 0.7919343115877974
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5486907192211056,
                        "accuracy": 0.8047026931463257
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5445881752512562,
                        "accuracy": 0.804840198793879
                    },
                    {
                        "epoch": 6,
                        "loss": 0.5135590059673367,
                        "accuracy": 0.8144459504586795
                    },
                    {
                        "epoch": 7,
                        "loss": 0.5077536118090452,
                        "accuracy": 0.8171567760818748
                    },
                    {
                        "epoch": 8,
                        "loss": 0.5030082050879398,
                        "accuracy": 0.8191211424754945
                    },
                    {
                        "epoch": 9,
                        "loss": 0.5114292163944724,
                        "accuracy": 0.8131298249749543
                    },
                    {
                        "epoch": 10,
                        "loss": 0.5046423523869347,
                        "accuracy": 0.8170978450900662
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.1066060126582278,
                        "accuracy": 0.5235,
                        "precision": 0.3797824259939838,
                        "recall": 0.5235,
                        "f1_score": 0.42738774445547834
                    },
                    {
                        "epoch": 2,
                        "loss": 0.8412282436708861,
                        "accuracy": 0.642,
                        "precision": 0.7477588064245849,
                        "recall": 0.642,
                        "f1_score": 0.6281506207440525
                    },
                    {
                        "epoch": 3,
                        "loss": 0.7401602056962026,
                        "accuracy": 0.7135,
                        "precision": 0.7745694641133443,
                        "recall": 0.7135,
                        "f1_score": 0.6803151836190882
                    },
                    {
                        "epoch": 4,
                        "loss": 0.7471815664556962,
                        "accuracy": 0.7031,
                        "precision": 0.7768609503574356,
                        "recall": 0.7031,
                        "f1_score": 0.679948385297648
                    },
                    {
                        "epoch": 5,
                        "loss": 0.6395371835443038,
                        "accuracy": 0.7243,
                        "precision": 0.7785417341244296,
                        "recall": 0.7243,
                        "f1_score": 0.6934436866089246
                    },
                    {
                        "epoch": 6,
                        "loss": 0.7643888449367089,
                        "accuracy": 0.6912,
                        "precision": 0.767488271112476,
                        "recall": 0.6912,
                        "f1_score": 0.6751198227785852
                    },
                    {
                        "epoch": 7,
                        "loss": 0.952284414556962,
                        "accuracy": 0.5696,
                        "precision": 0.737782238085865,
                        "recall": 0.5696,
                        "f1_score": 0.552153810784837
                    },
                    {
                        "epoch": 8,
                        "loss": 0.8910205696202531,
                        "accuracy": 0.6217,
                        "precision": 0.7627957124138497,
                        "recall": 0.6217,
                        "f1_score": 0.606714989284089
                    },
                    {
                        "epoch": 9,
                        "loss": 1.0381230221518987,
                        "accuracy": 0.538,
                        "precision": 0.7354084903815759,
                        "recall": 0.538,
                        "f1_score": 0.5115868761420301
                    },
                    {
                        "epoch": 10,
                        "loss": 0.9715189873417721,
                        "accuracy": 0.6199,
                        "precision": 0.7505288560048804,
                        "recall": 0.6199,
                        "f1_score": 0.6076094828141851
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7060412082416483,
                "precision": 0.7544865053025959,
                "recall": 0.7060412082416483,
                "f1_score": 0.6737171315043426
            },
            "confusion_matrix": [
                [
                    2797,
                    93,
                    443
                ],
                [
                    1830,
                    1036,
                    467
                ],
                [
                    68,
                    38,
                    3226
                ]
            ],
            "best_epoch": 5,
            "time_train": 80.09372933308283
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7060412082416483,
            "accuracy_std": 0.0,
            "precision_mean": 0.7544865053025959,
            "precision_std": 0.0,
            "recall_mean": 0.7060412082416483,
            "recall_std": 0.0,
            "f1_score_mean": 0.6737171315043426,
            "f1_score_std": 0.0,
            "time_train_mean": 80.09372933308283,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_136.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 135,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0006, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0006\n    maximize: False\n    weight_decay: 1e-07\n)",
                "learning_rate": 0.0006,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.8142568310301508,
                        "accuracy": 0.5143496965053922
                    },
                    {
                        "epoch": 2,
                        "loss": 0.7795422424623115,
                        "accuracy": 0.7134578741626888
                    },
                    {
                        "epoch": 3,
                        "loss": 0.6396533448492462,
                        "accuracy": 0.7804624118490581
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6200092258165829,
                        "accuracy": 0.7829768008328913
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5863448099874372,
                        "accuracy": 0.7919146679238611
                    },
                    {
                        "epoch": 6,
                        "loss": 0.5699493561557789,
                        "accuracy": 0.7971988135226983
                    },
                    {
                        "epoch": 7,
                        "loss": 0.529998625942211,
                        "accuracy": 0.8102618500402695
                    },
                    {
                        "epoch": 8,
                        "loss": 0.5119690248115578,
                        "accuracy": 0.8153692026636808
                    },
                    {
                        "epoch": 9,
                        "loss": 0.4959269001256281,
                        "accuracy": 0.8186300508770896
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4869268216080402,
                        "accuracy": 0.8210855088691142
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 0.944620253164557,
                        "accuracy": 0.4697,
                        "precision": 0.5963687314433201,
                        "recall": 0.4697,
                        "f1_score": 0.4709693462466859
                    },
                    {
                        "epoch": 2,
                        "loss": 0.8424643987341772,
                        "accuracy": 0.6873,
                        "precision": 0.7803164261182055,
                        "recall": 0.6873,
                        "f1_score": 0.6449651982120591
                    },
                    {
                        "epoch": 3,
                        "loss": 0.7453520569620253,
                        "accuracy": 0.6964,
                        "precision": 0.7492798785653374,
                        "recall": 0.6964,
                        "f1_score": 0.6757954431536016
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6745945411392406,
                        "accuracy": 0.7155,
                        "precision": 0.779527546520934,
                        "recall": 0.7155,
                        "f1_score": 0.682119561535676
                    },
                    {
                        "epoch": 5,
                        "loss": 0.7138548259493671,
                        "accuracy": 0.7284,
                        "precision": 0.765315018644402,
                        "recall": 0.7284,
                        "f1_score": 0.7091122266177836
                    },
                    {
                        "epoch": 6,
                        "loss": 0.8735166139240507,
                        "accuracy": 0.6845,
                        "precision": 0.7561430817229436,
                        "recall": 0.6845,
                        "f1_score": 0.6703978745485104
                    },
                    {
                        "epoch": 7,
                        "loss": 0.8443433544303798,
                        "accuracy": 0.6727,
                        "precision": 0.7655399577826613,
                        "recall": 0.6727,
                        "f1_score": 0.6504581915834136
                    },
                    {
                        "epoch": 8,
                        "loss": 0.7093057753164557,
                        "accuracy": 0.7183,
                        "precision": 0.7883843507097775,
                        "recall": 0.7183,
                        "f1_score": 0.6883460016818904
                    },
                    {
                        "epoch": 9,
                        "loss": 0.7490605221518988,
                        "accuracy": 0.6809,
                        "precision": 0.7721795018731556,
                        "recall": 0.6809,
                        "f1_score": 0.6693546429318754
                    },
                    {
                        "epoch": 10,
                        "loss": 0.6742978639240507,
                        "accuracy": 0.721,
                        "precision": 0.7517897172328459,
                        "recall": 0.721,
                        "f1_score": 0.7093678184788054
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7016403280656132,
                "precision": 0.7317029867283175,
                "recall": 0.7016403280656132,
                "f1_score": 0.6905125940412278
            },
            "confusion_matrix": [
                [
                    2839,
                    221,
                    273
                ],
                [
                    1776,
                    1372,
                    185
                ],
                [
                    315,
                    213,
                    2804
                ]
            ],
            "best_epoch": 10,
            "time_train": 80.84794735511144
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7016403280656132,
            "accuracy_std": 0.0,
            "precision_mean": 0.7317029867283175,
            "precision_std": 0.0,
            "recall_mean": 0.7016403280656132,
            "recall_std": 0.0,
            "f1_score_mean": 0.6905125940412278,
            "f1_score_std": 0.0,
            "time_train_mean": 80.84794735511144,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_135.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 138,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0006, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0006\n    maximize: False\n    weight_decay: 1e-07\n)",
                "learning_rate": 0.0006,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 10,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.7456324591708543,
                        "accuracy": 0.5032117390535683
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1945763976130652,
                        "accuracy": 0.6191093562771328
                    },
                    {
                        "epoch": 3,
                        "loss": 0.9733187421482412,
                        "accuracy": 0.6760759816921053
                    },
                    {
                        "epoch": 4,
                        "loss": 0.7154964274497487,
                        "accuracy": 0.7480503663543324
                    },
                    {
                        "epoch": 5,
                        "loss": 0.9369356548366834,
                        "accuracy": 0.6877639617341427
                    },
                    {
                        "epoch": 6,
                        "loss": 0.8244346733668342,
                        "accuracy": 0.731392539336437
                    },
                    {
                        "epoch": 7,
                        "loss": 0.5685556689698492,
                        "accuracy": 0.7925432651698194
                    },
                    {
                        "epoch": 8,
                        "loss": 0.5234522220477387,
                        "accuracy": 0.8073545877777123
                    },
                    {
                        "epoch": 9,
                        "loss": 0.5020218278894473,
                        "accuracy": 0.8132869742864439
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4882321765075377,
                        "accuracy": 0.816881764786768
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.1461629746835442,
                        "accuracy": 0.4359,
                        "precision": 0.5166646127895083,
                        "recall": 0.4359,
                        "f1_score": 0.39852346678543693
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1276206487341771,
                        "accuracy": 0.6178,
                        "precision": 0.6895791939449809,
                        "recall": 0.6178,
                        "f1_score": 0.5909974130936738
                    },
                    {
                        "epoch": 3,
                        "loss": 0.8671875,
                        "accuracy": 0.6302,
                        "precision": 0.7086963626658337,
                        "recall": 0.6302,
                        "f1_score": 0.6209216273198979
                    },
                    {
                        "epoch": 4,
                        "loss": 0.757120253164557,
                        "accuracy": 0.7194,
                        "precision": 0.7846978842303659,
                        "recall": 0.7194,
                        "f1_score": 0.6869751455809826
                    },
                    {
                        "epoch": 5,
                        "loss": 1.4844738924050633,
                        "accuracy": 0.4633,
                        "precision": 0.6023394211524404,
                        "recall": 0.4633,
                        "f1_score": 0.3698692385568858
                    },
                    {
                        "epoch": 6,
                        "loss": 0.6547913370253164,
                        "accuracy": 0.7187,
                        "precision": 0.735907763208921,
                        "recall": 0.7187,
                        "f1_score": 0.7175702179605316
                    },
                    {
                        "epoch": 7,
                        "loss": 0.7464151503164557,
                        "accuracy": 0.6944,
                        "precision": 0.7843418286418558,
                        "recall": 0.6944,
                        "f1_score": 0.6789735056226431
                    },
                    {
                        "epoch": 8,
                        "loss": 0.6527887658227848,
                        "accuracy": 0.7166,
                        "precision": 0.7891817163043576,
                        "recall": 0.7166,
                        "f1_score": 0.6974530470963152
                    },
                    {
                        "epoch": 9,
                        "loss": 0.6284612341772152,
                        "accuracy": 0.7316,
                        "precision": 0.7787758955539426,
                        "recall": 0.7316,
                        "f1_score": 0.7152605591176286
                    },
                    {
                        "epoch": 10,
                        "loss": 1.0141416139240507,
                        "accuracy": 0.539,
                        "precision": 0.7345270668955167,
                        "recall": 0.539,
                        "f1_score": 0.5108039803649651
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.6948389677935587,
                "precision": 0.7128592350633396,
                "recall": 0.6948389677935587,
                "f1_score": 0.6933054300442737
            },
            "confusion_matrix": [
                [
                    2563,
                    524,
                    246
                ],
                [
                    1462,
                    1681,
                    190
                ],
                [
                    448,
                    181,
                    2703
                ]
            ],
            "best_epoch": 6,
            "time_train": 81.25359437863032
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.6948389677935587,
            "accuracy_std": 0.0,
            "precision_mean": 0.7128592350633396,
            "precision_std": 0.0,
            "recall_mean": 0.6948389677935587,
            "recall_std": 0.0,
            "f1_score_mean": 0.6933054300442737,
            "f1_score_std": 0.0,
            "time_train_mean": 81.25359437863032,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_138.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-1B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-1B-bnb-4bit",
        "best_experiment": {
            "id": 2,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-1B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 7,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.07\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 4,
                "lora_alpha": 16,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2973559202261307,
                        "accuracy": 0.6080106861531813
                    },
                    {
                        "epoch": 2,
                        "loss": 0.8289641567211056,
                        "accuracy": 0.7122006796707722
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5665829145728644,
                        "accuracy": 0.7838804093739564
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5066151067839196,
                        "accuracy": 0.809417172491013
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4652216158919598,
                        "accuracy": 0.8200247510165596
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4269835505653266,
                        "accuracy": 0.8333824424931738
                    },
                    {
                        "epoch": 7,
                        "loss": 0.40315591630025127,
                        "accuracy": 0.8388826683953091
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 2.4656843354430378,
                        "accuracy": 0.4408,
                        "precision": 0.3776695262293179,
                        "recall": 0.4408,
                        "f1_score": 0.34235797196277606
                    },
                    {
                        "epoch": 2,
                        "loss": 1.0880636867088607,
                        "accuracy": 0.6087,
                        "precision": 0.7459224270727842,
                        "recall": 0.6087,
                        "f1_score": 0.5965511804816899
                    },
                    {
                        "epoch": 3,
                        "loss": 1.2715585443037976,
                        "accuracy": 0.5327,
                        "precision": 0.7093064322806986,
                        "recall": 0.5327,
                        "f1_score": 0.5054230812335659
                    },
                    {
                        "epoch": 4,
                        "loss": 0.9642009493670886,
                        "accuracy": 0.6338,
                        "precision": 0.7209204497403422,
                        "recall": 0.6338,
                        "f1_score": 0.6332010633795564
                    },
                    {
                        "epoch": 5,
                        "loss": 0.7568235759493671,
                        "accuracy": 0.7084,
                        "precision": 0.7571980633263657,
                        "recall": 0.7084,
                        "f1_score": 0.7054965100113353
                    },
                    {
                        "epoch": 6,
                        "loss": 0.6712074762658228,
                        "accuracy": 0.7359,
                        "precision": 0.7740356678744512,
                        "recall": 0.7359,
                        "f1_score": 0.7306017938363407
                    },
                    {
                        "epoch": 7,
                        "loss": 0.8166040348101266,
                        "accuracy": 0.6782,
                        "precision": 0.7544630276282929,
                        "recall": 0.6782,
                        "f1_score": 0.6777561228496621
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7103420684136827,
                "precision": 0.7482116441313945,
                "recall": 0.7103420684136827,
                "f1_score": 0.7052226730296566
            },
            "confusion_matrix": [
                [
                    2834,
                    325,
                    174
                ],
                [
                    1644,
                    1524,
                    165
                ],
                [
                    495,
                    93,
                    2744
                ]
            ],
            "best_epoch": 6,
            "time_train": 24.7141575217247
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7103420684136827,
            "accuracy_std": 0.0,
            "precision_mean": 0.7482116441313945,
            "precision_std": 0.0,
            "recall_mean": 0.7103420684136827,
            "recall_std": 0.0,
            "f1_score_mean": 0.7052226730296566,
            "f1_score_std": 0.0,
            "time_train_mean": 24.7141575217247,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-1B-bnb-4bit)_LoRA_best_model_2.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-1B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-1B-bnb-4bit",
        "best_experiment": {
            "id": 200,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-1B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.07\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 4,
                "lora_alpha": 16,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.2973559202261307,
                        "accuracy": 0.6080106861531813
                    },
                    {
                        "epoch": 2,
                        "loss": 0.8289641567211056,
                        "accuracy": 0.7122006796707722
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5665829145728644,
                        "accuracy": 0.7838804093739564
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5066151067839196,
                        "accuracy": 0.809417172491013
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4652216158919598,
                        "accuracy": 0.8200247510165596
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4269835505653266,
                        "accuracy": 0.8333824424931738
                    },
                    {
                        "epoch": 7,
                        "loss": 0.40315591630025127,
                        "accuracy": 0.8388826683953091
                    },
                    {
                        "epoch": 8,
                        "loss": 0.3864660215138191,
                        "accuracy": 0.845836525428723
                    },
                    {
                        "epoch": 9,
                        "loss": 0.37415593592964824,
                        "accuracy": 0.8494313159290471
                    },
                    {
                        "epoch": 10,
                        "loss": 0.3515796757223618,
                        "accuracy": 0.8579370224134205
                    },
                    {
                        "epoch": 11,
                        "loss": 0.32203497958542715,
                        "accuracy": 0.8685642446029034
                    },
                    {
                        "epoch": 12,
                        "loss": 0.30557818388819097,
                        "accuracy": 0.8761074115544031
                    },
                    {
                        "epoch": 13,
                        "loss": 0.2944164180276382,
                        "accuracy": 0.8794468344235566
                    },
                    {
                        "epoch": 14,
                        "loss": 0.28319576397613067,
                        "accuracy": 0.8835916475140944
                    },
                    {
                        "epoch": 15,
                        "loss": 0.26776828478329145,
                        "accuracy": 0.8894651030310173
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 2.4656843354430378,
                        "accuracy": 0.4408,
                        "precision": 0.3776695262293179,
                        "recall": 0.4408,
                        "f1_score": 0.34235797196277606
                    },
                    {
                        "epoch": 2,
                        "loss": 1.0880636867088607,
                        "accuracy": 0.6087,
                        "precision": 0.7459224270727842,
                        "recall": 0.6087,
                        "f1_score": 0.5965511804816899
                    },
                    {
                        "epoch": 3,
                        "loss": 1.2715585443037976,
                        "accuracy": 0.5327,
                        "precision": 0.7093064322806986,
                        "recall": 0.5327,
                        "f1_score": 0.5054230812335659
                    },
                    {
                        "epoch": 4,
                        "loss": 0.9642009493670886,
                        "accuracy": 0.6338,
                        "precision": 0.7209204497403422,
                        "recall": 0.6338,
                        "f1_score": 0.6332010633795564
                    },
                    {
                        "epoch": 5,
                        "loss": 0.7568235759493671,
                        "accuracy": 0.7084,
                        "precision": 0.7571980633263657,
                        "recall": 0.7084,
                        "f1_score": 0.7054965100113353
                    },
                    {
                        "epoch": 6,
                        "loss": 0.6712074762658228,
                        "accuracy": 0.7359,
                        "precision": 0.7740356678744512,
                        "recall": 0.7359,
                        "f1_score": 0.7306017938363407
                    },
                    {
                        "epoch": 7,
                        "loss": 0.8166040348101266,
                        "accuracy": 0.6782,
                        "precision": 0.7544630276282929,
                        "recall": 0.6782,
                        "f1_score": 0.6777561228496621
                    },
                    {
                        "epoch": 8,
                        "loss": 0.6904173259493671,
                        "accuracy": 0.724,
                        "precision": 0.7519531247578649,
                        "recall": 0.724,
                        "f1_score": 0.726276012689492
                    },
                    {
                        "epoch": 9,
                        "loss": 0.6664606408227848,
                        "accuracy": 0.7359,
                        "precision": 0.7558936259765924,
                        "recall": 0.7359,
                        "f1_score": 0.7369226289137256
                    },
                    {
                        "epoch": 10,
                        "loss": 0.7286392405063291,
                        "accuracy": 0.7181,
                        "precision": 0.7646604698387408,
                        "recall": 0.7181,
                        "f1_score": 0.7168479316271226
                    },
                    {
                        "epoch": 11,
                        "loss": 0.741915545886076,
                        "accuracy": 0.7528,
                        "precision": 0.7695597830742154,
                        "recall": 0.7528,
                        "f1_score": 0.7509020928435968
                    },
                    {
                        "epoch": 12,
                        "loss": 0.8464695411392406,
                        "accuracy": 0.7205,
                        "precision": 0.7487656860555763,
                        "recall": 0.7205,
                        "f1_score": 0.7233613925010237
                    },
                    {
                        "epoch": 13,
                        "loss": 0.7986797863924051,
                        "accuracy": 0.7379,
                        "precision": 0.7641084979708873,
                        "recall": 0.7379,
                        "f1_score": 0.7367370568781664
                    },
                    {
                        "epoch": 14,
                        "loss": 0.9122329905063291,
                        "accuracy": 0.7292,
                        "precision": 0.7596795341005945,
                        "recall": 0.7292,
                        "f1_score": 0.7265783015545787
                    },
                    {
                        "epoch": 15,
                        "loss": 0.9028876582278481,
                        "accuracy": 0.7264,
                        "precision": 0.7478714522906621,
                        "recall": 0.7264,
                        "f1_score": 0.7274265920401279
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.735747149429886,
                "precision": 0.7502067935918274,
                "recall": 0.735747149429886,
                "f1_score": 0.7331230935301667
            },
            "confusion_matrix": [
                [
                    2662,
                    479,
                    192
                ],
                [
                    1353,
                    1796,
                    184
                ],
                [
                    318,
                    116,
                    2898
                ]
            ],
            "best_epoch": 11,
            "time_train": 52.38425313234329
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.735747149429886,
            "accuracy_std": 0.0,
            "precision_mean": 0.7502067935918274,
            "precision_std": 0.0,
            "recall_mean": 0.735747149429886,
            "recall_std": 0.0,
            "f1_score_mean": 0.7331230935301667,
            "f1_score_std": 0.0,
            "time_train_mean": 52.38425313234329,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-1B-bnb-4bit)_LoRA_best_model_200.pth"
    }
]