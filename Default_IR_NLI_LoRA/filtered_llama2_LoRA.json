[
    {
        "id_experiment": "experiment_Llama-3.2-1B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-1B-bnb-4bit",
        "best_experiment": {
            "id": 1,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-1B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.07\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 4,
                "lora_alpha": 16,
                "lora_dropout": 0.1
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.3007763426507537,
                        "accuracy": 0.5954190975700788
                    },
                    {
                        "epoch": 2,
                        "loss": 0.8453645179020101,
                        "accuracy": 0.7121613923428998
                    },
                    {
                        "epoch": 3,
                        "loss": 0.5956442368090452,
                        "accuracy": 0.7793820103325673
                    },
                    {
                        "epoch": 4,
                        "loss": 0.5015703517587939,
                        "accuracy": 0.8081992653269688
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4707325690954774,
                        "accuracy": 0.8169603394425128
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4350266959798995,
                        "accuracy": 0.8295715716895515
                    },
                    {
                        "epoch": 7,
                        "loss": 0.41249460191582915,
                        "accuracy": 0.8379594161903078
                    },
                    {
                        "epoch": 8,
                        "loss": 0.39868532113693467,
                        "accuracy": 0.8408470347889289
                    },
                    {
                        "epoch": 9,
                        "loss": 0.3805477583228643,
                        "accuracy": 0.8483705580764924
                    },
                    {
                        "epoch": 10,
                        "loss": 0.36609806846733667,
                        "accuracy": 0.8530653937572436
                    },
                    {
                        "epoch": 11,
                        "loss": 0.33715452261306533,
                        "accuracy": 0.8637122596106626
                    },
                    {
                        "epoch": 12,
                        "loss": 0.32722204773869346,
                        "accuracy": 0.8669534641601352
                    },
                    {
                        "epoch": 13,
                        "loss": 0.31372438363693467,
                        "accuracy": 0.8716286561769502
                    },
                    {
                        "epoch": 14,
                        "loss": 0.3016694802135678,
                        "accuracy": 0.876893158111851
                    },
                    {
                        "epoch": 15,
                        "loss": 0.2924510246545226,
                        "accuracy": 0.879878995030153
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 3.2678006329113924,
                        "accuracy": 0.4279,
                        "precision": 0.3973068773231589,
                        "recall": 0.4279,
                        "f1_score": 0.3263953205963696
                    },
                    {
                        "epoch": 2,
                        "loss": 1.0076641613924051,
                        "accuracy": 0.6199,
                        "precision": 0.7351109674159413,
                        "recall": 0.6199,
                        "f1_score": 0.6096844810324661
                    },
                    {
                        "epoch": 3,
                        "loss": 1.0864319620253164,
                        "accuracy": 0.5991,
                        "precision": 0.7279141028860893,
                        "recall": 0.5991,
                        "f1_score": 0.5920126625276979
                    },
                    {
                        "epoch": 4,
                        "loss": 0.8107199367088608,
                        "accuracy": 0.6761,
                        "precision": 0.743429469843816,
                        "recall": 0.6761,
                        "f1_score": 0.6735497455556919
                    },
                    {
                        "epoch": 5,
                        "loss": 0.9178698575949367,
                        "accuracy": 0.6611,
                        "precision": 0.7766067828617985,
                        "recall": 0.6611,
                        "f1_score": 0.6524130680052628
                    },
                    {
                        "epoch": 6,
                        "loss": 0.6993423655063291,
                        "accuracy": 0.7277,
                        "precision": 0.7833307725022354,
                        "recall": 0.7277,
                        "f1_score": 0.7187691831395846
                    },
                    {
                        "epoch": 7,
                        "loss": 0.8138844936708861,
                        "accuracy": 0.6858,
                        "precision": 0.7557341106813763,
                        "recall": 0.6858,
                        "f1_score": 0.6843015336977325
                    },
                    {
                        "epoch": 8,
                        "loss": 0.7482199367088608,
                        "accuracy": 0.7027,
                        "precision": 0.7614677521573603,
                        "recall": 0.7027,
                        "f1_score": 0.7009381549981097
                    },
                    {
                        "epoch": 9,
                        "loss": 0.7927956882911392,
                        "accuracy": 0.6987,
                        "precision": 0.746330161302617,
                        "recall": 0.6987,
                        "f1_score": 0.6992988446766368
                    },
                    {
                        "epoch": 10,
                        "loss": 0.7582575158227848,
                        "accuracy": 0.7241,
                        "precision": 0.7805700509891246,
                        "recall": 0.7241,
                        "f1_score": 0.718988786258642
                    },
                    {
                        "epoch": 11,
                        "loss": 0.7075009889240507,
                        "accuracy": 0.7505,
                        "precision": 0.7659109106168349,
                        "recall": 0.7505,
                        "f1_score": 0.7492979045099583
                    },
                    {
                        "epoch": 12,
                        "loss": 0.7722013449367089,
                        "accuracy": 0.7347,
                        "precision": 0.7662869080862803,
                        "recall": 0.7347,
                        "f1_score": 0.733057628758638
                    },
                    {
                        "epoch": 13,
                        "loss": 0.7598150712025317,
                        "accuracy": 0.7551,
                        "precision": 0.777837406956966,
                        "recall": 0.7551,
                        "f1_score": 0.7487876015248743
                    },
                    {
                        "epoch": 14,
                        "loss": 0.9343354430379747,
                        "accuracy": 0.7305,
                        "precision": 0.7713857759689545,
                        "recall": 0.7305,
                        "f1_score": 0.7258501382368182
                    },
                    {
                        "epoch": 15,
                        "loss": 0.8655557753164557,
                        "accuracy": 0.7408,
                        "precision": 0.7704844806452443,
                        "recall": 0.7408,
                        "f1_score": 0.7353435556679297
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7332466493298659,
                "precision": 0.7436809189685984,
                "recall": 0.7332466493298659,
                "f1_score": 0.7321963135993986
            },
            "confusion_matrix": [
                [
                    2557,
                    588,
                    188
                ],
                [
                    1286,
                    1877,
                    170
                ],
                [
                    315,
                    120,
                    2897
                ]
            ],
            "best_epoch": 11,
            "time_train": 39.36393165588379
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7332466493298659,
            "accuracy_std": 0.0,
            "precision_mean": 0.7436809189685984,
            "precision_std": 0.0,
            "recall_mean": 0.7332466493298659,
            "recall_std": 0.0,
            "f1_score_mean": 0.7321963135993986,
            "f1_score_std": 0.0,
            "time_train_mean": 39.36393165588379,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-1B-bnb-4bit)_LoRA_best_model_1.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.2-3B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.2-3B-bnb-4bit",
        "best_experiment": {
            "id": 5,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.2-3B-bnb-4bit - AdamW, lr=0.0003, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0.0001\n)",
                "learning_rate": 0.0003,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 8,
                "lora_alpha": 32,
                "lora_dropout": 0.2
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.4768569409547738,
                        "accuracy": 0.5452098925491583
                    },
                    {
                        "epoch": 2,
                        "loss": 1.7128415515075377,
                        "accuracy": 0.6185004026951106
                    },
                    {
                        "epoch": 3,
                        "loss": 1.0462223225502512,
                        "accuracy": 0.6890997308818041
                    },
                    {
                        "epoch": 4,
                        "loss": 0.564453125,
                        "accuracy": 0.7984560080146149
                    },
                    {
                        "epoch": 5,
                        "loss": 0.4854889682788945,
                        "accuracy": 0.8167246154752784
                    },
                    {
                        "epoch": 6,
                        "loss": 0.4523251020728643,
                        "accuracy": 0.8277054236156128
                    },
                    {
                        "epoch": 7,
                        "loss": 0.43607196136934673,
                        "accuracy": 0.8312019957962559
                    },
                    {
                        "epoch": 8,
                        "loss": 0.43492854899497485,
                        "accuracy": 0.8301412379437012
                    },
                    {
                        "epoch": 9,
                        "loss": 0.42428941582914576,
                        "accuracy": 0.8330288565423223
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4156230370603015,
                        "accuracy": 0.8352485905671125
                    },
                    {
                        "epoch": 11,
                        "loss": 0.4076485945351759,
                        "accuracy": 0.8387058754198833
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 4.544897151898734,
                        "accuracy": 0.4434,
                        "precision": 0.3628492021979584,
                        "recall": 0.4434,
                        "f1_score": 0.34904794322462823
                    },
                    {
                        "epoch": 2,
                        "loss": 6.025712025316456,
                        "accuracy": 0.4145,
                        "precision": 0.4178382238974214,
                        "recall": 0.4145,
                        "f1_score": 0.3083020447872544
                    },
                    {
                        "epoch": 3,
                        "loss": 0.8548753955696202,
                        "accuracy": 0.6622,
                        "precision": 0.7271439302684028,
                        "recall": 0.6622,
                        "f1_score": 0.6613242513817218
                    },
                    {
                        "epoch": 4,
                        "loss": 0.616767207278481,
                        "accuracy": 0.7398,
                        "precision": 0.7639042799176535,
                        "recall": 0.7398,
                        "f1_score": 0.7310448465403597
                    },
                    {
                        "epoch": 5,
                        "loss": 0.7316307357594937,
                        "accuracy": 0.7216,
                        "precision": 0.7813894977027072,
                        "recall": 0.7216,
                        "f1_score": 0.708675059583059
                    },
                    {
                        "epoch": 6,
                        "loss": 0.6061362737341772,
                        "accuracy": 0.7643,
                        "precision": 0.7725840523632694,
                        "recall": 0.7643,
                        "f1_score": 0.7578662895503739
                    },
                    {
                        "epoch": 7,
                        "loss": 0.8354183148734177,
                        "accuracy": 0.7341,
                        "precision": 0.7959211122071294,
                        "recall": 0.7341,
                        "f1_score": 0.7176206729702858
                    },
                    {
                        "epoch": 8,
                        "loss": 0.9404173259493671,
                        "accuracy": 0.7188,
                        "precision": 0.8000898406775986,
                        "recall": 0.7188,
                        "f1_score": 0.7011007746667115
                    },
                    {
                        "epoch": 9,
                        "loss": 0.6253214003164557,
                        "accuracy": 0.7599,
                        "precision": 0.7968858097572529,
                        "recall": 0.7599,
                        "f1_score": 0.7483080374253157
                    },
                    {
                        "epoch": 10,
                        "loss": 1.2909909018987342,
                        "accuracy": 0.6947,
                        "precision": 0.7500337265973438,
                        "recall": 0.6947,
                        "f1_score": 0.6946616312507312
                    },
                    {
                        "epoch": 11,
                        "loss": 2.3860759493670884,
                        "accuracy": 0.5816,
                        "precision": 0.7659651383013291,
                        "recall": 0.5816,
                        "f1_score": 0.5600300718522152
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7491498299659932,
                "precision": 0.756692155356922,
                "recall": 0.7491498299659932,
                "f1_score": 0.7421303080273558
            },
            "confusion_matrix": [
                [
                    2608,
                    462,
                    263
                ],
                [
                    1336,
                    1754,
                    243
                ],
                [
                    148,
                    56,
                    3128
                ]
            ],
            "best_epoch": 6,
            "time_train": 48.257619909445445
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7491498299659932,
            "accuracy_std": 0.0,
            "precision_mean": 0.756692155356922,
            "precision_std": 0.0,
            "recall_mean": 0.7491498299659932,
            "recall_std": 0.0,
            "f1_score_mean": 0.7421303080273558,
            "f1_score_std": 0.0,
            "time_train_mean": 48.257619909445445,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.2-3B-bnb-4bit)_LoRA_best_model_5.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 138,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0006, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 10,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0006\n    maximize: False\n    weight_decay: 1e-07\n)",
                "learning_rate": 0.0006,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 10,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.7456324591708543,
                        "accuracy": 0.5032117390535683
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1945763976130652,
                        "accuracy": 0.6191093562771328
                    },
                    {
                        "epoch": 3,
                        "loss": 0.9733187421482412,
                        "accuracy": 0.6760759816921053
                    },
                    {
                        "epoch": 4,
                        "loss": 0.7154964274497487,
                        "accuracy": 0.7480503663543324
                    },
                    {
                        "epoch": 5,
                        "loss": 0.9369356548366834,
                        "accuracy": 0.6877639617341427
                    },
                    {
                        "epoch": 6,
                        "loss": 0.8244346733668342,
                        "accuracy": 0.731392539336437
                    },
                    {
                        "epoch": 7,
                        "loss": 0.5685556689698492,
                        "accuracy": 0.7925432651698194
                    },
                    {
                        "epoch": 8,
                        "loss": 0.5234522220477387,
                        "accuracy": 0.8073545877777123
                    },
                    {
                        "epoch": 9,
                        "loss": 0.5020218278894473,
                        "accuracy": 0.8132869742864439
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4882321765075377,
                        "accuracy": 0.816881764786768
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.1461629746835442,
                        "accuracy": 0.4359,
                        "precision": 0.5166646127895083,
                        "recall": 0.4359,
                        "f1_score": 0.39852346678543693
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1276206487341771,
                        "accuracy": 0.6178,
                        "precision": 0.6895791939449809,
                        "recall": 0.6178,
                        "f1_score": 0.5909974130936738
                    },
                    {
                        "epoch": 3,
                        "loss": 0.8671875,
                        "accuracy": 0.6302,
                        "precision": 0.7086963626658337,
                        "recall": 0.6302,
                        "f1_score": 0.6209216273198979
                    },
                    {
                        "epoch": 4,
                        "loss": 0.757120253164557,
                        "accuracy": 0.7194,
                        "precision": 0.7846978842303659,
                        "recall": 0.7194,
                        "f1_score": 0.6869751455809826
                    },
                    {
                        "epoch": 5,
                        "loss": 1.4844738924050633,
                        "accuracy": 0.4633,
                        "precision": 0.6023394211524404,
                        "recall": 0.4633,
                        "f1_score": 0.3698692385568858
                    },
                    {
                        "epoch": 6,
                        "loss": 0.6547913370253164,
                        "accuracy": 0.7187,
                        "precision": 0.735907763208921,
                        "recall": 0.7187,
                        "f1_score": 0.7175702179605316
                    },
                    {
                        "epoch": 7,
                        "loss": 0.7464151503164557,
                        "accuracy": 0.6944,
                        "precision": 0.7843418286418558,
                        "recall": 0.6944,
                        "f1_score": 0.6789735056226431
                    },
                    {
                        "epoch": 8,
                        "loss": 0.6527887658227848,
                        "accuracy": 0.7166,
                        "precision": 0.7891817163043576,
                        "recall": 0.7166,
                        "f1_score": 0.6974530470963152
                    },
                    {
                        "epoch": 9,
                        "loss": 0.6284612341772152,
                        "accuracy": 0.7316,
                        "precision": 0.7787758955539426,
                        "recall": 0.7316,
                        "f1_score": 0.7152605591176286
                    },
                    {
                        "epoch": 10,
                        "loss": 1.0141416139240507,
                        "accuracy": 0.539,
                        "precision": 0.7345270668955167,
                        "recall": 0.539,
                        "f1_score": 0.5108039803649651
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.6948389677935587,
                "precision": 0.7128592350633396,
                "recall": 0.6948389677935587,
                "f1_score": 0.6933054300442737
            },
            "confusion_matrix": [
                [
                    2563,
                    524,
                    246
                ],
                [
                    1462,
                    1681,
                    190
                ],
                [
                    448,
                    181,
                    2703
                ]
            ],
            "best_epoch": 6,
            "time_train": 81.25359437863032
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.6948389677935587,
            "accuracy_std": 0.0,
            "precision_mean": 0.7128592350633396,
            "precision_std": 0.0,
            "recall_mean": 0.6948389677935587,
            "recall_std": 0.0,
            "f1_score_mean": 0.6933054300442737,
            "f1_score_std": 0.0,
            "time_train_mean": 81.25359437863032,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_138.pth"
    },
    {
        "id_experiment": "experiment_Llama-3.1-8B-bnb-4bit",
        "llm_name": "unsloth/Llama-3.1-8B-unsloth-bnb-4bit",
        "best_experiment": {
            "id": 150,
            "description": "Estudio de diferentes modelos Llama2 con LoRA. Experimento LoRA. Modelo: unsloth/Llama-3.1-8B-unsloth-bnb-4bit - AdamW, lr=0.0006, batch_size=128, n_experiments=1 | Run 1/1",
            "hyperparameters": {
                "epochs": 15,
                "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0006\n    maximize: False\n    weight_decay: 1e-05\n)",
                "learning_rate": 0.0006,
                "batch_size": 128,
                "dropout": 0.3,
                "patience": 5,
                "r": 10,
                "lora_alpha": 64,
                "lora_dropout": 0.05
            },
            "metrics": {
                "train": [
                    {
                        "epoch": 1,
                        "loss": 1.7139015389447236,
                        "accuracy": 0.5101852397509183
                    },
                    {
                        "epoch": 2,
                        "loss": 1.1409685144472361,
                        "accuracy": 0.6252185357612902
                    },
                    {
                        "epoch": 3,
                        "loss": 0.8511257459170855,
                        "accuracy": 0.7051878916455497
                    },
                    {
                        "epoch": 4,
                        "loss": 0.6624676114949749,
                        "accuracy": 0.7628616889622253
                    },
                    {
                        "epoch": 5,
                        "loss": 0.5927390860552764,
                        "accuracy": 0.7882805900956646
                    },
                    {
                        "epoch": 6,
                        "loss": 0.5325798916457286,
                        "accuracy": 0.8106547233189935
                    },
                    {
                        "epoch": 7,
                        "loss": 0.4800467179648241,
                        "accuracy": 0.8221462667216689
                    },
                    {
                        "epoch": 8,
                        "loss": 0.46099148084170855,
                        "accuracy": 0.8285697448288055
                    },
                    {
                        "epoch": 9,
                        "loss": 0.46955480527638194,
                        "accuracy": 0.8241892077710334
                    },
                    {
                        "epoch": 10,
                        "loss": 0.4444438991834171,
                        "accuracy": 0.8322823973127468
                    },
                    {
                        "epoch": 11,
                        "loss": 0.4187784626256281,
                        "accuracy": 0.8393934036576502
                    },
                    {
                        "epoch": 12,
                        "loss": 0.4260069880653266,
                        "accuracy": 0.8357003948376451
                    },
                    {
                        "epoch": 13,
                        "loss": 0.41600090295226133,
                        "accuracy": 0.839177323354352
                    }
                ],
                "val": [
                    {
                        "epoch": 1,
                        "loss": 1.5807950949367089,
                        "accuracy": 0.4339,
                        "precision": 0.6284089606428673,
                        "recall": 0.4339,
                        "f1_score": 0.34072557655265984
                    },
                    {
                        "epoch": 2,
                        "loss": 0.9061511075949367,
                        "accuracy": 0.6028,
                        "precision": 0.63300401886777,
                        "recall": 0.6028,
                        "f1_score": 0.5800923514118789
                    },
                    {
                        "epoch": 3,
                        "loss": 0.9196004746835443,
                        "accuracy": 0.6728,
                        "precision": 0.7706079854385651,
                        "recall": 0.6728,
                        "f1_score": 0.6299306036025755
                    },
                    {
                        "epoch": 4,
                        "loss": 0.7034216772151899,
                        "accuracy": 0.7201,
                        "precision": 0.7779437545601431,
                        "recall": 0.7201,
                        "f1_score": 0.6913235639081508
                    },
                    {
                        "epoch": 5,
                        "loss": 0.7491099683544303,
                        "accuracy": 0.7217,
                        "precision": 0.7965162220891454,
                        "recall": 0.7217,
                        "f1_score": 0.6863876282312352
                    },
                    {
                        "epoch": 6,
                        "loss": 0.590535996835443,
                        "accuracy": 0.7481,
                        "precision": 0.7919881591915017,
                        "recall": 0.7481,
                        "f1_score": 0.7287210546454292
                    },
                    {
                        "epoch": 7,
                        "loss": 0.7057456487341772,
                        "accuracy": 0.7308,
                        "precision": 0.7794498475243431,
                        "recall": 0.7308,
                        "f1_score": 0.7176878265145213
                    },
                    {
                        "epoch": 8,
                        "loss": 0.5389388844936709,
                        "accuracy": 0.7596,
                        "precision": 0.777057300294368,
                        "recall": 0.7596,
                        "f1_score": 0.7450690351325234
                    },
                    {
                        "epoch": 9,
                        "loss": 0.6330102848101266,
                        "accuracy": 0.7556,
                        "precision": 0.7972545730476917,
                        "recall": 0.7556,
                        "f1_score": 0.7319789405156872
                    },
                    {
                        "epoch": 10,
                        "loss": 0.6332080696202531,
                        "accuracy": 0.7539,
                        "precision": 0.8128390702523474,
                        "recall": 0.7539,
                        "f1_score": 0.7295088601601191
                    },
                    {
                        "epoch": 11,
                        "loss": 0.6442098496835443,
                        "accuracy": 0.7503,
                        "precision": 0.8171434628385279,
                        "recall": 0.7503,
                        "f1_score": 0.7237047988790098
                    },
                    {
                        "epoch": 12,
                        "loss": 0.5939477848101266,
                        "accuracy": 0.756,
                        "precision": 0.8113274246814101,
                        "recall": 0.756,
                        "f1_score": 0.7296145515326743
                    },
                    {
                        "epoch": 13,
                        "loss": 0.5868769778481012,
                        "accuracy": 0.7553,
                        "precision": 0.8144266217326837,
                        "recall": 0.7553,
                        "f1_score": 0.7292255617054217
                    }
                ]
            },
            "test_metrics": {
                "accuracy": 0.7444488897779555,
                "precision": 0.7622004493659158,
                "recall": 0.7444488897779555,
                "f1_score": 0.7278172165066585
            },
            "confusion_matrix": [
                [
                    2703,
                    303,
                    327
                ],
                [
                    1531,
                    1461,
                    341
                ],
                [
                    44,
                    9,
                    3279
                ]
            ],
            "best_epoch": 8,
            "time_train": 117.36428306897481
        },
        "aggregated_metrics": {
            "accuracy_mean": 0.7444488897779555,
            "accuracy_std": 0.0,
            "precision_mean": 0.7622004493659158,
            "precision_std": 0.0,
            "recall_mean": 0.7444488897779555,
            "recall_std": 0.0,
            "f1_score_mean": 0.7278172165066585,
            "f1_score_std": 0.0,
            "time_train_mean": 117.36428306897481,
            "time_train_std": 0.0
        },
        "best_model_path": "./Models/exp(Llama-3.1-8B-bnb-4bit)_LoRA_best_model_150_val_loss.pth"
    }
]